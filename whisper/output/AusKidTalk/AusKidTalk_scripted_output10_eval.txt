Sun Oct 8 20:17:52 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py
Started: 08/10/2023 20:17:53

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing num2words...
-->Importing string...
-->Importing Whisper Packages...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: whisper
dataset_name: AusKidTalk
experiment_id: whisper_small_eval_AusKidTalk_scripted_lowercase_20231008
cache_name: AusKidTalk-finetune
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_small_finetune_CU_lowercase_20231006
use_pretrained_tokenizer: True
pretrained_tokenizer: openai/whisper-small
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_small_finetune_CU_lowercase_20231006
baseline_model: openai/whisper-small
eval_baseline: True

------> TRAINING ARGUMENTS... ----------------------------------------

learning_rate: 1e-05
per_device_train_batch_size: 8
per_device_eval_batch_size: 32
seed: 42
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1e-08
lr_scheduler_type: linear
warmup_steps: 500
max_steps: 5500
gradient_accumulation_steps: 1
gradient_checkpointing: True
fp16: True
evaluation_strategy: steps
predict_with_generate: True
generation_max_length: 225
save_steps: 1000
eval_steps: 1000
logging_steps: 500
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/whisper/vocab/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/whisper/model/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008
--> baseline_results_fp: /srv/scratch/z5313567/thesis/whisper/baseline_result/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_small_finetune_CU_lowercase_20231006
--> pretrained_tokenizer: openai/whisper-small

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.32it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e5d8762d3a04d065.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a151348b46fbab52.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-d119b1142a2d91e1_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-570515b048477936_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-353842da29e79329_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-1fda0342634e3ec0_*_of_00004.arrow
/srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py:455: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6fd5ec163f2d0c4e.arrow
/home/z5313567/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f9487a4171a26289.arrow
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath transcription_clean
0  /srv/scratch/chacmod/auskidtalk_scripted_audio...                 yes
1  /srv/scratch/chacmod/auskidtalk_scripted_audio...               eight
2  /srv/scratch/chacmod/auskidtalk_scripted_audio...              sprout
3  /srv/scratch/chacmod/auskidtalk_scripted_audio...               tooth
4  /srv/scratch/chacmod/auskidtalk_scripted_audio...              sprout
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> Defining feature extractor... ---------------------------------------

SUCCESS: Feature extractor defined.

------> Defining tokenizer... ---------------------------------------

SUCCESS: Tokenizer defined.

------> Preparaing processor... ---------------------------------------

SUCCESS: Processor defined.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: seven
Input array shape: (8640,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...

------> Training finished... ------------------------------------------ 


------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.651
Fine-tuned Test CER: 0.348


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     breathe     breath
1      carpet     top of
2   australia  australia
3        pull       pull
4    cucumber   ki gamba
5       swing      swing
6     feather    feather
7      garden     garden
8      carpet     carpet
9       chair        kay
--> Taking a deeper look...
<|startoftranscript|> <|kn|> <|transcribe|> <|notimestamps|> bird <|endoftext|>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Map:   0%|          | 0/3968 [00:00<?, ? examples/s]                                                    Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py", line 651, in <module>
    results = results.map(post_process)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py", line 626, in post_process
    text = map_number_to_words(text)
  File "/srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py", line 617, in map_number_to_words
    for word in text.split():
AttributeError: 'LazyRow' object has no attribute 'split'
Sun Oct 8 20:25:02 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py
Started: 08/10/2023 20:25:02

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing num2words...
-->Importing string...
-->Importing Whisper Packages...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: whisper
dataset_name: AusKidTalk
experiment_id: whisper_small_eval_AusKidTalk_scripted_lowercase_20231008
cache_name: AusKidTalk-finetune
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_small_finetune_CU_lowercase_20231006
use_pretrained_tokenizer: True
pretrained_tokenizer: openai/whisper-small
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_small_finetune_CU_lowercase_20231006
baseline_model: openai/whisper-small
eval_baseline: True

------> TRAINING ARGUMENTS... ----------------------------------------

learning_rate: 1e-05
per_device_train_batch_size: 8
per_device_eval_batch_size: 32
seed: 42
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1e-08
lr_scheduler_type: linear
warmup_steps: 500
max_steps: 5500
gradient_accumulation_steps: 1
gradient_checkpointing: True
fp16: True
evaluation_strategy: steps
predict_with_generate: True
generation_max_length: 225
save_steps: 1000
eval_steps: 1000
logging_steps: 500
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/whisper/vocab/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/whisper/model/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008
--> baseline_results_fp: /srv/scratch/z5313567/thesis/whisper/baseline_result/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_small_finetune_CU_lowercase_20231006
--> pretrained_tokenizer: openai/whisper-small

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 589.25it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e5d8762d3a04d065.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a151348b46fbab52.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-d119b1142a2d91e1_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-570515b048477936_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-353842da29e79329_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-1fda0342634e3ec0_*_of_00004.arrow
/srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py:455: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6fd5ec163f2d0c4e.arrow
/home/z5313567/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f9487a4171a26289.arrow
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath transcription_clean
0  /srv/scratch/chacmod/auskidtalk_scripted_audio...       three o clock
1  /srv/scratch/chacmod/auskidtalk_scripted_audio...           crocodile
2  /srv/scratch/chacmod/auskidtalk_scripted_audio...                 cow
3  /srv/scratch/chacmod/auskidtalk_scripted_audio...                hair
4  /srv/scratch/chacmod/auskidtalk_scripted_audio...                foot
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> Defining feature extractor... ---------------------------------------

SUCCESS: Feature extractor defined.

------> Defining tokenizer... ---------------------------------------

SUCCESS: Tokenizer defined.

------> Preparaing processor... ---------------------------------------

SUCCESS: Processor defined.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: breathe
Input array shape: (10560,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...

------> Training finished... ------------------------------------------ 


------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.651
Fine-tuned Test CER: 0.348


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     breathe     breath
1      carpet     top of
2   australia  australia
3        pull       pull
4    cucumber   ki gamba
5       swing      swing
6     feather    feather
7      garden     garden
8      carpet     carpet
9       chair        kay
--> Taking a deeper look...
<|startoftranscript|> <|kn|> <|transcribe|> <|notimestamps|> bird <|endoftext|>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Map:   0%|          | 0/3968 [00:00<?, ? examples/s]                                                    Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py", line 652, in <module>
    results = results.map(post_process)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py", line 633, in post_process
    text = test.translate(str.maketrans('', '', string.punctuation))
NameError: name 'test' is not defined. Did you mean: 'text'?
Sun Oct 8 20:26:43 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py
Started: 08/10/2023 20:26:43

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing num2words...
-->Importing string...
-->Importing Whisper Packages...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: whisper
dataset_name: AusKidTalk
experiment_id: whisper_small_eval_AusKidTalk_scripted_lowercase_20231008
cache_name: AusKidTalk-finetune
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_small_finetune_CU_lowercase_20231006
use_pretrained_tokenizer: True
pretrained_tokenizer: openai/whisper-small
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_small_finetune_CU_lowercase_20231006
baseline_model: openai/whisper-small
eval_baseline: True

------> TRAINING ARGUMENTS... ----------------------------------------

learning_rate: 1e-05
per_device_train_batch_size: 8
per_device_eval_batch_size: 32
seed: 42
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1e-08
lr_scheduler_type: linear
warmup_steps: 500
max_steps: 5500
gradient_accumulation_steps: 1
gradient_checkpointing: True
fp16: True
evaluation_strategy: steps
predict_with_generate: True
generation_max_length: 225
save_steps: 1000
eval_steps: 1000
logging_steps: 500
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/whisper/vocab/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/whisper/model/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008
--> baseline_results_fp: /srv/scratch/z5313567/thesis/whisper/baseline_result/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_small_finetune_CU_lowercase_20231006
--> pretrained_tokenizer: openai/whisper-small

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 521.71it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e5d8762d3a04d065.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a151348b46fbab52.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-d119b1142a2d91e1_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-570515b048477936_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-353842da29e79329_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-1fda0342634e3ec0_*_of_00004.arrow
/srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py:455: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6fd5ec163f2d0c4e.arrow
/home/z5313567/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-finetune/csv/default-14d234269bc535e1/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f9487a4171a26289.arrow
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath transcription_clean
0  /srv/scratch/chacmod/auskidtalk_scripted_audio...              sprout
1  /srv/scratch/chacmod/auskidtalk_scripted_audio...              splash
2  /srv/scratch/chacmod/auskidtalk_scripted_audio...                 pie
3  /srv/scratch/chacmod/auskidtalk_scripted_audio...                head
4  /srv/scratch/chacmod/auskidtalk_scripted_audio...            vegemite
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> Defining feature extractor... ---------------------------------------

SUCCESS: Feature extractor defined.

------> Defining tokenizer... ---------------------------------------

SUCCESS: Tokenizer defined.

------> Preparaing processor... ---------------------------------------

SUCCESS: Processor defined.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: watermelon
Input array shape: (18748,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...

------> Training finished... ------------------------------------------ 


------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_small_eval_AusKidTalk_scripted_lowercase_20231008_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.651
Fine-tuned Test CER: 0.348


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     breathe     breath
1      carpet     top of
2   australia  australia
3        pull       pull
4    cucumber   ki gamba
5       swing      swing
6     feather    feather
7      garden     garden
8      carpet     carpet
9       chair        kay
--> Taking a deeper look...
<|startoftranscript|> <|kn|> <|transcribe|> <|notimestamps|> bird <|endoftext|>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Map:   0%|          | 0/3968 [00:00<?, ? examples/s]                                                    Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/whisper/code/whisper_eval_AusKidTalk_scripted.py", line 652, in <module>
    results = results.map(post_process)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3341, in apply_function_on_filtered_inputs
    validate_function_output(processed_inputs, indices)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3286, in validate_function_output
    raise TypeError(
TypeError: Provided `function` which is applied to all elements of table returns a variable of type <class 'str'>. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects.
