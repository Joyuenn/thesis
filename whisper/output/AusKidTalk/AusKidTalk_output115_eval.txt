Wed Nov 1 04:23:37 AEDT 2023
Wed Nov 1 08:20:34 AEDT 2023
Running:  /srv/scratch/z5313567/thesis/whisper/code/1_whisper_eval_AusKidTalk_scripted.py
Started: 01/11/2023 08:20:35

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing num2words...
-->Importing string...
-->Importing Whisper Packages...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: whisper
dataset_name: AusKidTalk
experiment_id: whisper_eval_AusKidTalk_spontaneous_full_20231101
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_medium_en_finetune_CU_lowercase_20231005
use_pretrained_tokenizer: True
pretrained_tokenizer: openai/whisper-medium
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_medium_en_finetune_CU_lowercase_20231005
baseline_model: openai/whisper-medium
eval_baseline: False

------> TRAINING ARGUMENTS... ----------------------------------------

learning_rate: 1e-05
per_device_train_batch_size: 8
per_device_eval_batch_size: 32
seed: 42
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1e-08
lr_scheduler_type: linear
warmup_steps: 500
max_steps: 5500
gradient_accumulation_steps: 1
gradient_checkpointing: True
fp16: True
evaluation_strategy: steps
predict_with_generate: True
generation_max_length: 225
save_steps: 1000
eval_steps: 1000
logging_steps: 500
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous_v2/AusKidTalk_spontaneous_dataframe_combined_only_transcription_filepath_v2.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/whisper/vocab/AusKidTalk/whisper_eval_AusKidTalk_spontaneous_full_20231101_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/whisper/model/AusKidTalk/whisper_eval_AusKidTalk_spontaneous_full_20231101
--> baseline_results_fp: /srv/scratch/z5313567/thesis/whisper/baseline_result/AusKidTalk/whisper_eval_AusKidTalk_spontaneous_full_20231101_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/whisper/baseline_result/AusKidTalk/whisper_eval_AusKidTalk_spontaneous_full_20231101_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_eval_AusKidTalk_spontaneous_full_20231101_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_eval_AusKidTalk_spontaneous_full_20231101_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/whisper/model/CU/whisper_medium_en_finetune_CU_lowercase_20231005
--> pretrained_tokenizer: openai/whisper-medium

------> PREPARING DATASET... ------------------------------------

Downloading and preparing dataset csv/default to /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-02e670ef97401bb4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...
Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 9565.12it/s]
Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 36.73it/s]
Generating train split: 0 examples [00:00, ? examples/s]                                                        Generating test split: 0 examples [00:00, ? examples/s]                                                       Dataset csv downloaded and prepared to /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-02e670ef97401bb4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.
  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 206.76it/s]
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 152
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
1  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
2  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
3  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
4  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------

Map:   0%|          | 0/10 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/152 [00:00<?, ? examples/s]                                                   
------> Defining feature extractor... ---------------------------------------

SUCCESS: Feature extractor defined.

------> Defining tokenizer... ---------------------------------------

SUCCESS: Tokenizer defined.

------> Preparaing processor... ---------------------------------------

SUCCESS: Processor defined.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Map (num_proc=4):   0%|          | 0/10 [00:00<?, ? examples/s]Map (num_proc=4):  10%|â–ˆ         | 1/10 [00:02<00:18,  2.07s/ examples]                                                                       Map (num_proc=4):   0%|          | 0/152 [00:00<?, ? examples/s]Map (num_proc=4):   1%|          | 1/152 [00:01<02:57,  1.18s/ examples]Map (num_proc=4):   8%|â–Š         | 12/152 [00:01<00:11, 12.54 examples/s]Map (num_proc=4):  25%|â–ˆâ–ˆâ–Œ       | 38/152 [00:01<00:02, 44.95 examples/s]Map (num_proc=4):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 58/152 [00:01<00:01, 69.12 examples/s]Map (num_proc=4):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/152 [00:01<00:00, 98.33 examples/s]Map (num_proc=4):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 107/152 [00:01<00:00, 128.56 examples/s]Map (num_proc=4):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 128/152 [00:01<00:00, 142.80 examples/s]Map (num_proc=4):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 149/152 [00:01<00:00, 143.16 examples/s]                                                                           --> Verifying data with a random sample...
Target text: bi bubbles big why are some small
Input array shape: (46881,)
Sampling rate: 16000
Map (num_proc=4):   0%|          | 0/10 [00:00<?, ? examples/s]Map (num_proc=4):  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:00<00:00,  8.97 examples/s]Map (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 27.06 examples/s]                                                                        Map (num_proc=4):   0%|          | 0/152 [00:00<?, ? examples/s]Map (num_proc=4):   5%|â–Œ         | 8/152 [00:00<00:13, 10.53 examples/s]Map (num_proc=4):  11%|â–ˆ         | 16/152 [00:00<00:07, 18.61 examples/s]Map (num_proc=4):  16%|â–ˆâ–Œ        | 24/152 [00:01<00:06, 20.98 examples/s]Map (num_proc=4):  21%|â–ˆâ–ˆ        | 32/152 [00:01<00:05, 21.12 examples/s]Map (num_proc=4):  26%|â–ˆâ–ˆâ–‹       | 40/152 [00:02<00:05, 20.63 examples/s]Map (num_proc=4):  32%|â–ˆâ–ˆâ–ˆâ–      | 48/152 [00:02<00:04, 25.51 examples/s]Map (num_proc=4):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 64/152 [00:02<00:02, 35.21 examples/s]Map (num_proc=4):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 72/152 [00:02<00:02, 31.53 examples/s]Map (num_proc=4):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 80/152 [00:03<00:02, 24.57 examples/s]Map (num_proc=4):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 88/152 [00:03<00:02, 30.41 examples/s]Map (num_proc=4):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 96/152 [00:03<00:01, 33.20 examples/s]Map (num_proc=4):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 104/152 [00:03<00:01, 33.97 examples/s]Map (num_proc=4):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 110/152 [00:04<00:01, 34.87 examples/s]Map (num_proc=4):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 116/152 [00:04<00:01, 20.95 examples/s]Map (num_proc=4):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 132/152 [00:04<00:00, 31.98 examples/s]Map (num_proc=4):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 138/152 [00:05<00:00, 28.71 examples/s]Map (num_proc=4):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 146/152 [00:05<00:00, 27.81 examples/s]Map (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:05<00:00, 23.11 examples/s]                                                                          /srv/scratch/z5313567/thesis/whisper/code/1_whisper_eval_AusKidTalk_scripted.py:464: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...

------> Training finished... ------------------------------------------ 


------> EVALUATING MODEL... ------------------------------------------ 

Map:   0%|          | 0/152 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
Map:   1%|          | 1/152 [00:11<27:42, 11.01s/ examples]Map:   1%|â–         | 2/152 [00:11<12:01,  4.81s/ examples]Map:   2%|â–         | 3/152 [00:11<06:51,  2.76s/ examples]Map:   3%|â–Ž         | 4/152 [00:12<04:25,  1.80s/ examples]Map:   3%|â–Ž         | 5/152 [00:12<03:04,  1.25s/ examples]Map:   4%|â–         | 6/152 [00:12<02:15,  1.08 examples/s]Map:   5%|â–         | 7/152 [00:13<01:47,  1.35 examples/s]Map:   5%|â–Œ         | 8/152 [00:13<01:29,  1.62 examples/s]Map:   6%|â–Œ         | 9/152 [00:13<01:15,  1.89 examples/s]Map:   7%|â–‹         | 10/152 [00:14<01:05,  2.16 examples/s]Map:   7%|â–‹         | 11/152 [00:14<00:59,  2.39 examples/s]Map:   8%|â–Š         | 12/152 [00:14<00:56,  2.47 examples/s]Map:   9%|â–Š         | 13/152 [00:15<00:58,  2.38 examples/s]Map:   9%|â–‰         | 14/152 [00:15<00:54,  2.55 examples/s]Map:  10%|â–‰         | 15/152 [00:15<00:53,  2.57 examples/s]Map:  11%|â–ˆ         | 16/152 [00:16<00:59,  2.28 examples/s]Map:  11%|â–ˆ         | 17/152 [00:16<00:59,  2.27 examples/s]Map:  12%|â–ˆâ–        | 18/152 [00:17<01:00,  2.20 examples/s]Map:  12%|â–ˆâ–Ž        | 19/152 [00:17<00:57,  2.32 examples/s]Map:  13%|â–ˆâ–Ž        | 20/152 [00:18<01:02,  2.11 examples/s]Map:  14%|â–ˆâ–        | 21/152 [00:18<00:58,  2.23 examples/s]Map:  14%|â–ˆâ–        | 22/152 [00:19<00:55,  2.36 examples/s]Map:  15%|â–ˆâ–Œ        | 23/152 [00:19<00:54,  2.35 examples/s]Map:  16%|â–ˆâ–Œ        | 24/152 [00:19<00:51,  2.46 examples/s]Map:  16%|â–ˆâ–‹        | 25/152 [00:20<00:49,  2.56 examples/s]Map:  17%|â–ˆâ–‹        | 26/152 [00:20<00:46,  2.73 examples/s]Map:  18%|â–ˆâ–Š        | 27/152 [00:20<00:45,  2.74 examples/s]Map:  18%|â–ˆâ–Š        | 28/152 [00:21<00:55,  2.22 examples/s]Map:  19%|â–ˆâ–‰        | 29/152 [00:21<00:53,  2.30 examples/s]Map:  20%|â–ˆâ–‰        | 30/152 [00:22<00:54,  2.23 examples/s]Map:  20%|â–ˆâ–ˆ        | 31/152 [00:22<00:52,  2.30 examples/s]Map:  21%|â–ˆâ–ˆ        | 32/152 [00:23<00:53,  2.25 examples/s]Map:  22%|â–ˆâ–ˆâ–       | 33/152 [00:23<00:49,  2.38 examples/s]Map:  22%|â–ˆâ–ˆâ–       | 34/152 [00:24<00:47,  2.50 examples/s]Map:  23%|â–ˆâ–ˆâ–Ž       | 35/152 [00:24<00:59,  1.97 examples/s]Map:  24%|â–ˆâ–ˆâ–Ž       | 36/152 [00:25<00:58,  1.97 examples/s]Map:  24%|â–ˆâ–ˆâ–       | 37/152 [00:25<00:49,  2.34 examples/s]Map:  25%|â–ˆâ–ˆâ–Œ       | 38/152 [00:26<00:53,  2.11 examples/s]Map:  26%|â–ˆâ–ˆâ–Œ       | 39/152 [00:26<00:45,  2.48 examples/s]Map:  26%|â–ˆâ–ˆâ–‹       | 40/152 [00:26<00:50,  2.21 examples/s]Map:  27%|â–ˆâ–ˆâ–‹       | 41/152 [00:27<00:50,  2.19 examples/s]Map:  28%|â–ˆâ–ˆâ–Š       | 42/152 [00:27<00:52,  2.08 examples/s]Map:  28%|â–ˆâ–ˆâ–Š       | 43/152 [00:28<00:52,  2.08 examples/s]Map:  29%|â–ˆâ–ˆâ–‰       | 44/152 [00:28<00:52,  2.06 examples/s]Map:  30%|â–ˆâ–ˆâ–‰       | 45/152 [00:29<00:52,  2.02 examples/s]Map:  30%|â–ˆâ–ˆâ–ˆ       | 46/152 [00:29<00:48,  2.20 examples/s]Map:  31%|â–ˆâ–ˆâ–ˆ       | 47/152 [00:30<00:48,  2.15 examples/s]Map:  32%|â–ˆâ–ˆâ–ˆâ–      | 48/152 [00:30<00:48,  2.15 examples/s]Map:  32%|â–ˆâ–ˆâ–ˆâ–      | 49/152 [00:31<00:48,  2.12 examples/s]Map:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 50/152 [00:31<00:42,  2.40 examples/s]Map:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 51/152 [00:31<00:42,  2.40 examples/s]Map:  34%|â–ˆâ–ˆâ–ˆâ–      | 52/152 [00:32<00:39,  2.55 examples/s]Map:  35%|â–ˆâ–ˆâ–ˆâ–      | 53/152 [00:32<00:38,  2.59 examples/s]Map:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 54/152 [00:33<00:41,  2.34 examples/s]Map:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 55/152 [00:33<00:45,  2.14 examples/s]Map:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 56/152 [00:34<00:46,  2.08 examples/s]Map:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 57/152 [00:34<00:46,  2.03 examples/s]Map:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 58/152 [00:35<00:49,  1.88 examples/s]Map:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 59/152 [00:35<00:50,  1.83 examples/s]Map:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 60/152 [00:36<00:50,  1.81 examples/s]Map:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 61/152 [00:36<00:45,  1.99 examples/s]Map:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 62/152 [00:37<00:42,  2.13 examples/s]Map:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 63/152 [00:37<00:40,  2.19 examples/s]Map:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 64/152 [00:38<00:40,  2.16 examples/s]Map:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 65/152 [00:38<00:40,  2.13 examples/s]Map:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 66/152 [00:39<00:41,  2.05 examples/s]Map:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/152 [00:39<00:36,  2.36 examples/s]Map:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 68/152 [00:39<00:33,  2.53 examples/s]Map:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 69/152 [00:40<00:32,  2.59 examples/s]Map:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 70/152 [00:40<00:30,  2.68 examples/s]Map:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 71/152 [00:40<00:28,  2.88 examples/s]Map:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 72/152 [00:41<00:28,  2.82 examples/s]Map:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 73/152 [00:41<00:28,  2.80 examples/s]Map:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 74/152 [00:41<00:26,  2.92 examples/s]Map:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 75/152 [00:42<00:27,  2.77 examples/s]Map:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 76/152 [00:42<00:26,  2.84 examples/s]Map:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 77/152 [00:42<00:25,  2.98 examples/s]Map:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 78/152 [00:43<00:24,  3.02 examples/s]Map:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 79/152 [00:43<00:24,  2.98 examples/s]Map:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 80/152 [00:43<00:23,  3.08 examples/s]Map:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 81/152 [00:44<00:23,  3.08 examples/s]Map:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/152 [00:44<00:22,  3.13 examples/s]Map:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 83/152 [00:44<00:21,  3.18 examples/s]Map:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 84/152 [00:45<00:20,  3.27 examples/s]Map:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 85/152 [00:45<00:20,  3.21 examples/s]Map:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 86/152 [00:45<00:20,  3.24 examples/s]Map:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 87/152 [00:46<00:20,  3.24 examples/s]Map:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 88/152 [00:46<00:18,  3.45 examples/s]Map:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 89/152 [00:46<00:17,  3.55 examples/s]Map:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 90/152 [00:46<00:19,  3.23 examples/s]Map:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 91/152 [00:47<00:19,  3.10 examples/s]Map:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 92/152 [00:47<00:19,  3.05 examples/s]Map:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 93/152 [00:47<00:18,  3.24 examples/s]Map:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 94/152 [00:48<00:17,  3.29 examples/s]Map:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 95/152 [00:48<00:17,  3.17 examples/s]Map:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 96/152 [00:48<00:17,  3.11 examples/s]Map:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 97/152 [00:49<00:17,  3.19 examples/s]Map:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 98/152 [00:49<00:17,  3.12 examples/s]Map:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 99/152 [00:49<00:17,  3.01 examples/s]Map:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 100/152 [00:50<00:16,  3.19 examples/s]Map:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 101/152 [00:50<00:15,  3.19 examples/s]Map:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 102/152 [00:50<00:16,  3.12 examples/s]Map:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 103/152 [00:51<00:16,  3.03 examples/s]Map:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 104/152 [00:51<00:15,  3.01 examples/s]Map:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 105/152 [00:51<00:15,  2.95 examples/s]Map:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 106/152 [00:52<00:15,  3.05 examples/s]Map:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 107/152 [00:52<00:14,  3.06 examples/s]Map:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 108/152 [00:52<00:15,  2.93 examples/s]Map:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 109/152 [00:53<00:14,  3.03 examples/s]Map:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 110/152 [00:53<00:14,  2.86 examples/s]Map:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 111/152 [00:53<00:14,  2.92 examples/s]Map:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 112/152 [00:54<00:13,  3.04 examples/s]Map:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 113/152 [00:54<00:12,  3.23 examples/s]Map:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 114/152 [00:54<00:12,  2.95 examples/s]Map:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 115/152 [00:55<00:12,  2.93 examples/s]Map:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 116/152 [00:55<00:13,  2.70 examples/s]Map:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 117/152 [00:55<00:12,  2.74 examples/s]Map:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 118/152 [00:56<00:12,  2.72 examples/s]Map:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 119/152 [00:56<00:12,  2.74 examples/s]Map:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 120/152 [00:57<00:12,  2.48 examples/s]Map:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 121/152 [00:57<00:13,  2.36 examples/s]Map:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 122/152 [00:57<00:12,  2.46 examples/s]Map:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 123/152 [00:58<00:11,  2.60 examples/s]Map:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 124/152 [00:58<00:10,  2.59 examples/s]Map:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 125/152 [00:59<00:10,  2.51 examples/s]Map:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 126/152 [00:59<00:10,  2.50 examples/s]Map:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 127/152 [00:59<00:08,  2.78 examples/s]Map:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 128/152 [01:00<00:08,  2.88 examples/s]Map:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 129/152 [01:00<00:09,  2.48 examples/s]Map:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 130/152 [01:00<00:08,  2.72 examples/s]Map:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 131/152 [01:01<00:07,  2.76 examples/s]Map:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 132/152 [01:01<00:06,  2.93 examples/s]Map:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 133/152 [01:02<00:07,  2.68 examples/s]Map:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 134/152 [01:02<00:06,  2.68 examples/s]Map:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 135/152 [01:02<00:06,  2.56 examples/s]Map:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 136/152 [01:03<00:06,  2.55 examples/s]Map:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 137/152 [01:03<00:06,  2.49 examples/s]Map:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 138/152 [01:03<00:05,  2.65 examples/s]Map:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 139/152 [01:04<00:05,  2.50 examples/s]Map:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 140/152 [01:04<00:05,  2.33 examples/s]Map:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 141/152 [01:05<00:04,  2.53 examples/s]Map:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 142/152 [01:05<00:03,  2.67 examples/s]Map:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 143/152 [01:05<00:03,  2.77 examples/s]Map:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 144/152 [01:06<00:02,  2.75 examples/s]Map:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 145/152 [01:06<00:02,  2.93 examples/s]Map:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 146/152 [01:06<00:02,  2.90 examples/s]Map:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 147/152 [01:07<00:01,  2.93 examples/s]Map:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 148/152 [01:07<00:01,  2.88 examples/s]Map:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 149/152 [01:08<00:01,  2.72 examples/s]Map:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 150/152 [01:08<00:00,  2.57 examples/s]Map:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 151/152 [01:08<00:00,  2.64 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [01:09<00:00,  2.61 examples/s]                                                             Map:   0%|          | 0/152 [00:00<?, ? examples/s]                                                   /home/z5313567/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
Saved results to: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_eval_AusKidTalk_spontaneous_full_20231101_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.140
Fine-tuned Test CER: 0.080


--> Getting finetuned alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/whisper/finetuned_result/AusKidTalk/whisper_eval_AusKidTalk_spontaneous_full_20231101_finetuned_result.txt


--> Showing some fine-tuned prediction errors...
                                         target_text                                           pred_str
0  and then the dinosaur just was hopped out of t...  and then the dinosaur just w hopped out of the...
1                                           he's sad                                                sad
2   laughing while the dinosuar is drinking the milk   laughing while the dinosaur is drinking the milk
3                              the dinosaur is upset                                 the dias was upset
4  while doing that the egg cracked open and he w...  uh while doing that the egg cracked open and h...
5                     the dinosaur lies on the floor                     the dinosaur lies on the floor
6                                 he's skateboarding                                  hes skateboarding
7                 the dinosaur was about to lick him                 the dinosaur was about to lick him
8  the green skined baby is bouncing off the dino...  the green skinned baby is bouncing off the din...
9  the green baby has second thoughts about playi...  the green baby has second thoughts about playi...
--> Taking a deeper look...
<|startoftranscript|> <|notimestamps|> Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm Ä h mm

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 01/11/2023 08:22:57
