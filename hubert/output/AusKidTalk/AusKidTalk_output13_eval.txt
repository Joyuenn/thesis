Wed Oct 11 17:16:17 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c64cb278d54fb682/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 17:16:17

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 468.93it/s]
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 1
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 330, in <module>
    show_random_elements(data["train"], num_examples=5)
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 321, in show_random_elements
    assert num_examples <= len(dataset), "Picking more elements than in dataset"
AssertionError: Picking more elements than in dataset
Wed Oct 11 17:17:48 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c64cb278d54fb682/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 17:17:48

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 467.07it/s]
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 1
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 330, in <module>
    show_random_elements(data["train"], num_examples=5)
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 321, in show_random_elements
    assert num_examples <= len(dataset), "Picking more elements than in dataset"
AssertionError: Picking more elements than in dataset
Wed Oct 11 17:19:20 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c64cb278d54fb682/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 17:19:20

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 477.74it/s]
Wed Oct 11 17:30:52 AEDT 2023
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 322
    picks = []
              ^
IndentationError: unindent does not match any outer indentation level
Wed Oct 11 19:23:57 AEDT 2023
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 19:23:58

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

Downloading and preparing dataset csv/default to /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...
Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 11881.88it/s]
Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 54.08it/s]
Generating train split: 0 examples [00:00, ? examples/s]                                                        Generating test split: 0 examples [00:00, ? examples/s]                                                       Dataset csv downloaded and prepared to /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 208.01it/s]
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------

Map:   0%|          | 0/10 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/3968 [00:00<?, ? examples/s]Map:  82%|████████▏ | 3251/3968 [00:00<00:00, 32350.76 examples/s]                                                                  Downloading (…)olve/main/vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 291/291 [00:00<00:00, 2.78MB/s]
Downloading (…)okenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 163/163 [00:00<00:00, 1.51MB/s]
Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 772kB/s]
Downloading (…)lve/main/config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 17.4MB/s]

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Map (num_proc=4):   0%|          | 0/10 [00:00<?, ? examples/s]Map (num_proc=4):  10%|█         | 1/10 [00:02<00:19,  2.14s/ examples]                                                                       Map (num_proc=4):   0%|          | 0/3968 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 1/3968 [00:01<1:22:28,  1.25s/ examples]Map (num_proc=4):   0%|          | 6/3968 [00:01<11:21,  5.81 examples/s]  Map (num_proc=4):   0%|          | 9/3968 [00:01<07:52,  8.38 examples/s]Map (num_proc=4):   0%|          | 15/3968 [00:01<04:10, 15.77 examples/s]Map (num_proc=4):   1%|          | 26/3968 [00:01<02:07, 31.03 examples/s]Map (num_proc=4):   1%|          | 39/3968 [00:01<01:20, 48.91 examples/s]Map (num_proc=4):   1%|▏         | 56/3968 [00:01<00:56, 69.03 examples/s]Map (num_proc=4):   2%|▏         | 66/3968 [00:02<00:54, 72.13 examples/s]Map (num_proc=4):   2%|▏         | 77/3968 [00:02<00:49, 78.25 examples/s]Map (num_proc=4):   2%|▏         | 88/3968 [00:02<00:46, 83.56 examples/s]Map (num_proc=4):   3%|▎         | 104/3968 [00:02<00:38, 99.42 examples/s]Map (num_proc=4):   3%|▎         | 123/3968 [00:02<00:32, 119.11 examples/s]Map (num_proc=4):   3%|▎         | 138/3968 [00:02<00:34, 109.88 examples/s]Map (num_proc=4):   4%|▍         | 151/3968 [00:02<00:37, 103.03 examples/s]Map (num_proc=4):   4%|▍         | 169/3968 [00:02<00:33, 113.24 examples/s]Map (num_proc=4):   5%|▍         | 187/3968 [00:03<00:29, 127.59 examples/s]Map (num_proc=4):   5%|▌         | 216/3968 [00:03<00:22, 165.42 examples/s]Map (num_proc=4):   6%|▌         | 236/3968 [00:03<00:21, 174.49 examples/s]Map (num_proc=4):   7%|▋         | 259/3968 [00:03<00:19, 188.72 examples/s]Map (num_proc=4):   7%|▋         | 297/3968 [00:03<00:15, 230.39 examples/s]Map (num_proc=4):   8%|▊         | 331/3968 [00:03<00:14, 248.94 examples/s]Map (num_proc=4):   9%|▉         | 362/3968 [00:03<00:14, 252.39 examples/s]Map (num_proc=4):  10%|█         | 399/3968 [00:03<00:12, 279.41 examples/s]Map (num_proc=4):  11%|█         | 441/3968 [00:03<00:11, 316.74 examples/s]Map (num_proc=4):  12%|█▏        | 477/3968 [00:04<00:10, 324.81 examples/s]Map (num_proc=4):  13%|█▎        | 515/3968 [00:04<00:10, 322.75 examples/s]Map (num_proc=4):  14%|█▍        | 549/3968 [00:04<00:11, 298.22 examples/s]Map (num_proc=4):  15%|█▌        | 596/3968 [00:04<00:09, 341.54 examples/s]Map (num_proc=4):  16%|█▌        | 634/3968 [00:04<00:09, 333.94 examples/s]Map (num_proc=4):  17%|█▋        | 687/3968 [00:04<00:09, 361.70 examples/s]Map (num_proc=4):  19%|█▊        | 739/3968 [00:04<00:08, 401.21 examples/s]Map (num_proc=4):  20%|█▉        | 785/3968 [00:04<00:07, 411.50 examples/s]Map (num_proc=4):  21%|██        | 832/3968 [00:04<00:07, 409.14 examples/s]Map (num_proc=4):  22%|██▏       | 889/3968 [00:05<00:06, 441.04 examples/s]Map (num_proc=4):  24%|██▍       | 967/3968 [00:05<00:05, 507.14 examples/s]Map (num_proc=4):  26%|██▌       | 1039/3968 [00:05<00:05, 562.37 examples/s]Map (num_proc=4):  28%|██▊       | 1113/3968 [00:05<00:04, 601.16 examples/s]Map (num_proc=4):  30%|██▉       | 1181/3968 [00:05<00:04, 615.52 examples/s]Map (num_proc=4):  31%|███▏      | 1248/3968 [00:05<00:04, 621.18 examples/s]Map (num_proc=4):  33%|███▎      | 1320/3968 [00:05<00:04, 618.50 examples/s]Map (num_proc=4):  35%|███▍      | 1388/3968 [00:05<00:04, 632.45 examples/s]Map (num_proc=4):  37%|███▋      | 1463/3968 [00:05<00:03, 652.99 examples/s]Map (num_proc=4):  39%|███▉      | 1545/3968 [00:06<00:03, 689.52 examples/s]Map (num_proc=4):  41%|████      | 1619/3968 [00:06<00:03, 691.36 examples/s]Map (num_proc=4):  43%|████▎     | 1700/3968 [00:06<00:03, 693.59 examples/s]Map (num_proc=4):  45%|████▍     | 1780/3968 [00:06<00:03, 716.13 examples/s]Map (num_proc=4):  47%|████▋     | 1861/3968 [00:06<00:02, 737.62 examples/s]Map (num_proc=4):  49%|████▉     | 1943/3968 [00:06<00:02, 752.29 examples/s]Map (num_proc=4):  51%|█████     | 2029/3968 [00:06<00:02, 776.77 examples/s]Map (num_proc=4):  53%|█████▎    | 2108/3968 [00:06<00:02, 766.33 examples/s]Map (num_proc=4):  55%|█████▌    | 2189/3968 [00:06<00:02, 765.86 examples/s]Map (num_proc=4):  57%|█████▋    | 2266/3968 [00:07<00:02, 759.70 examples/s]Map (num_proc=4):  59%|█████▉    | 2347/3968 [00:07<00:02, 765.75 examples/s]Map (num_proc=4):  61%|██████    | 2427/3968 [00:07<00:02, 762.66 examples/s]Map (num_proc=4):  63%|██████▎   | 2510/3968 [00:07<00:01, 756.56 examples/s]Map (num_proc=4):  65%|██████▌   | 2593/3968 [00:07<00:01, 771.52 examples/s]Map (num_proc=4):  67%|██████▋   | 2676/3968 [00:07<00:01, 780.14 examples/s]Map (num_proc=4):  70%|██████▉   | 2762/3968 [00:07<00:01, 786.78 examples/s]Map (num_proc=4):  72%|███████▏  | 2843/3968 [00:08<00:03, 319.68 examples/s]Map (num_proc=4):  73%|███████▎  | 2907/3968 [00:08<00:03, 328.03 examples/s]Map (num_proc=4):  75%|███████▍  | 2961/3968 [00:08<00:03, 289.06 examples/s]Map (num_proc=4):  76%|███████▌  | 3006/3968 [00:08<00:03, 308.38 examples/s]Map (num_proc=4):  77%|███████▋  | 3053/3968 [00:08<00:02, 317.28 examples/s]Map (num_proc=4):  78%|███████▊  | 3098/3968 [00:09<00:02, 332.64 examples/s]Map (num_proc=4):  80%|███████▉  | 3174/3968 [00:09<00:01, 418.36 examples/s]Map (num_proc=4):  82%|████████▏ | 3256/3968 [00:09<00:01, 503.36 examples/s]Map (num_proc=4):  84%|████████▍ | 3340/3968 [00:09<00:01, 576.76 examples/s]Map (num_proc=4):  86%|████████▌ | 3411/3968 [00:09<00:00, 582.44 examples/s]Map (num_proc=4):  88%|████████▊ | 3479/3968 [00:09<00:00, 605.24 examples/s]Map (num_proc=4):  90%|█████████ | 3579/3968 [00:09<00:00, 703.79 examples/s]Map (num_proc=4):  93%|█████████▎| 3676/3968 [00:09<00:00, 769.69 examples/s]Map (num_proc=4):  95%|█████████▍| 3761/3968 [00:09<00:00, 728.88 examples/s]Map (num_proc=4):  97%|█████████▋| 3848/3968 [00:10<00:00, 763.70 examples/s]Map (num_proc=4):  99%|█████████▉| 3927/3968 [00:10<00:00, 620.74 examples/s]                                                                             --> Verifying data with a random sample...
Target text: BI BUBBLES BIG WHY ARE SOME SMALL
Input array shape: (46881,)
Sampling rate: 16000
Map (num_proc=4):   0%|          | 0/10 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  40%|████      | 4/10 [00:00<00:00, 39.82 examples/s]                                                                       Map (num_proc=4):   0%|          | 0/3968 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):   1%|          | 24/3968 [00:00<00:16, 237.04 examples/s]Map (num_proc=4):   3%|▎         | 112/3968 [00:00<00:08, 476.27 examples/s]Map (num_proc=4):   6%|▌         | 240/3968 [00:00<00:05, 651.87 examples/s]Map (num_proc=4):   9%|▉         | 352/3968 [00:00<00:04, 794.01 examples/s]Map (num_proc=4):  11%|█▏        | 448/3968 [00:00<00:04, 792.85 examples/s]Map (num_proc=4):  14%|█▎        | 544/3968 [00:00<00:04, 796.51 examples/s]Map (num_proc=4):  16%|█▌        | 640/3968 [00:00<00:04, 827.58 examples/s]Map (num_proc=4):  19%|█▊        | 736/3968 [00:00<00:04, 793.52 examples/s]Map (num_proc=4):  21%|██▏       | 848/3968 [00:01<00:03, 815.10 examples/s]Map (num_proc=4):  24%|██▍       | 944/3968 [00:01<00:03, 821.94 examples/s]Map (num_proc=4):  26%|██▌       | 1040/3968 [00:01<00:03, 832.82 examples/s]Map (num_proc=4):  29%|██▊       | 1136/3968 [00:01<00:03, 814.88 examples/s]Map (num_proc=4):  31%|███       | 1232/3968 [00:01<00:03, 811.14 examples/s]Map (num_proc=4):  33%|███▎      | 1328/3968 [00:01<00:03, 774.58 examples/s]Map (num_proc=4):  36%|███▋      | 1440/3968 [00:01<00:03, 825.37 examples/s]Map (num_proc=4):  39%|███▊      | 1536/3968 [00:01<00:03, 798.32 examples/s]Map (num_proc=4):  41%|████      | 1632/3968 [00:02<00:02, 799.00 examples/s]Map (num_proc=4):  44%|████▎     | 1728/3968 [00:02<00:02, 824.45 examples/s]Map (num_proc=4):  46%|████▌     | 1832/3968 [00:02<00:02, 750.94 examples/s]Map (num_proc=4):  49%|████▉     | 1944/3968 [00:02<00:02, 758.79 examples/s]Map (num_proc=4):  52%|█████▏    | 2072/3968 [00:02<00:02, 771.22 examples/s]Map (num_proc=4):  55%|█████▌    | 2192/3968 [00:02<00:02, 797.92 examples/s]Map (num_proc=4):  58%|█████▊    | 2288/3968 [00:02<00:02, 815.15 examples/s]Map (num_proc=4):  60%|██████    | 2384/3968 [00:03<00:02, 778.26 examples/s]Map (num_proc=4):  63%|██████▎   | 2496/3968 [00:03<00:01, 802.13 examples/s]Map (num_proc=4):  65%|██████▌   | 2592/3968 [00:03<00:01, 816.26 examples/s]Map (num_proc=4):  68%|██████▊   | 2688/3968 [00:03<00:01, 789.72 examples/s]Map (num_proc=4):  70%|███████   | 2784/3968 [00:03<00:01, 831.72 examples/s]Map (num_proc=4):  73%|███████▎  | 2880/3968 [00:03<00:01, 777.41 examples/s]Map (num_proc=4):  75%|███████▌  | 2976/3968 [00:03<00:01, 813.71 examples/s]Map (num_proc=4):  77%|███████▋  | 3072/3968 [00:03<00:01, 802.97 examples/s]Map (num_proc=4):  80%|███████▉  | 3168/3968 [00:04<00:00, 820.24 examples/s]Map (num_proc=4):  82%|████████▏ | 3264/3968 [00:04<00:00, 806.52 examples/s]Map (num_proc=4):  85%|████████▍ | 3360/3968 [00:04<00:00, 775.50 examples/s]Map (num_proc=4):  87%|████████▋ | 3456/3968 [00:04<00:00, 815.30 examples/s]Map (num_proc=4):  89%|████████▉ | 3544/3968 [00:04<00:00, 750.42 examples/s]Map (num_proc=4):  92%|█████████▏| 3664/3968 [00:04<00:00, 766.73 examples/s]Map (num_proc=4):  95%|█████████▍| 3760/3968 [00:04<00:00, 813.82 examples/s]Map (num_proc=4):  97%|█████████▋| 3848/3968 [00:04<00:00, 716.49 examples/s]Map (num_proc=4):  99%|█████████▉| 3928/3968 [00:05<00:00, 643.31 examples/s]                                                                             /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py:554: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/hubert/modeling_hubert.py:1125: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Map:   0%|          | 0/3968 [00:00<?, ? examples/s]Map:   0%|          | 1/3968 [00:01<1:24:48,  1.28s/ examples]Map:   0%|          | 8/3968 [00:01<08:48,  7.49 examples/s]  Map:   0%|          | 15/3968 [00:01<04:31, 14.54 examples/s]Map:   1%|          | 21/3968 [00:01<03:11, 20.63 examples/s]Map:   1%|          | 27/3968 [00:01<02:27, 26.76 examples/s]Map:   1%|          | 34/3968 [00:01<01:56, 33.81 examples/s]Map:   1%|          | 41/3968 [00:02<01:39, 39.64 examples/s]Map:   1%|          | 49/3968 [00:02<01:24, 46.39 examples/s]Map:   1%|▏         | 57/3968 [00:02<01:16, 51.31 examples/s]Map:   2%|▏         | 64/3968 [00:02<01:13, 53.26 examples/s]Map:   2%|▏         | 71/3968 [00:02<01:11, 54.83 examples/s]Map:   2%|▏         | 78/3968 [00:02<01:08, 57.13 examples/s]Map:   2%|▏         | 87/3968 [00:02<01:01, 63.30 examples/s]Map:   2%|▏         | 95/3968 [00:02<00:59, 64.65 examples/s]Map:   3%|▎         | 102/3968 [00:02<01:00, 64.21 examples/s]Map:   3%|▎         | 110/3968 [00:03<00:57, 67.39 examples/s]Map:   3%|▎         | 118/3968 [00:03<00:56, 67.85 examples/s]Map:   3%|▎         | 125/3968 [00:03<01:00, 63.09 examples/s]Map:   3%|▎         | 134/3968 [00:03<00:57, 66.59 examples/s]Map:   4%|▎         | 142/3968 [00:03<00:56, 67.68 examples/s]Map:   4%|▍         | 150/3968 [00:03<00:56, 67.50 examples/s]Map:   4%|▍         | 157/3968 [00:03<00:56, 68.01 examples/s]Map:   4%|▍         | 164/3968 [00:03<00:58, 65.20 examples/s]Map:   4%|▍         | 172/3968 [00:03<00:57, 65.74 examples/s]Map:   5%|▍         | 179/3968 [00:04<00:58, 65.26 examples/s]Map:   5%|▍         | 187/3968 [00:04<00:57, 65.47 examples/s]Map:   5%|▍         | 194/3968 [00:04<00:57, 65.89 examples/s]Map:   5%|▌         | 202/3968 [00:04<00:54, 68.83 examples/s]Map:   5%|▌         | 210/3968 [00:04<00:54, 69.52 examples/s]Map:   5%|▌         | 218/3968 [00:04<00:54, 68.69 examples/s]Map:   6%|▌         | 226/3968 [00:04<00:54, 68.20 examples/s]Map:   6%|▌         | 235/3968 [00:04<00:53, 70.12 examples/s]Map:   6%|▌         | 243/3968 [00:05<00:54, 68.57 examples/s]Map:   6%|▋         | 251/3968 [00:05<00:55, 67.48 examples/s]Map:   7%|▋         | 259/3968 [00:05<00:54, 68.32 examples/s]Map:   7%|▋         | 266/3968 [00:05<00:55, 66.46 examples/s]Map:   7%|▋         | 274/3968 [00:05<00:55, 66.08 examples/s]Map:   7%|▋         | 284/3968 [00:05<00:53, 68.74 examples/s]Map:   7%|▋         | 292/3968 [00:05<00:53, 69.16 examples/s]Map:   8%|▊         | 299/3968 [00:05<00:56, 65.14 examples/s]Map:   8%|▊         | 306/3968 [00:05<00:56, 64.69 examples/s]Map:   8%|▊         | 315/3968 [00:06<00:55, 65.79 examples/s]Map:   8%|▊         | 322/3968 [00:06<00:55, 65.93 examples/s]Map:   8%|▊         | 330/3968 [00:06<00:54, 67.31 examples/s]Map:   9%|▊         | 338/3968 [00:06<00:54, 66.56 examples/s]Map:   9%|▊         | 346/3968 [00:06<00:53, 67.74 examples/s]Map:   9%|▉         | 353/3968 [00:06<00:54, 66.33 examples/s]Map:   9%|▉         | 361/3968 [00:06<00:53, 67.51 examples/s]Map:   9%|▉         | 368/3968 [00:06<00:53, 66.78 examples/s]Map:   9%|▉         | 376/3968 [00:07<00:52, 67.84 examples/s]Map:  10%|▉         | 385/3968 [00:07<00:51, 69.32 examples/s]Map:  10%|▉         | 393/3968 [00:07<00:52, 68.47 examples/s]Map:  10%|█         | 402/3968 [00:07<00:51, 69.20 examples/s]Map:  10%|█         | 410/3968 [00:07<00:51, 68.94 examples/s]Map:  11%|█         | 417/3968 [00:07<00:52, 67.83 examples/s]Map:  11%|█         | 425/3968 [00:07<00:50, 69.80 examples/s]Map:  11%|█         | 432/3968 [00:07<00:53, 66.60 examples/s]Map:  11%|█         | 441/3968 [00:07<00:52, 66.94 examples/s]Map:  11%|█▏        | 448/3968 [00:08<00:54, 64.33 examples/s]Map:  11%|█▏        | 455/3968 [00:08<00:54, 64.58 examples/s]Map:  12%|█▏        | 464/3968 [00:08<00:52, 67.27 examples/s]Map:  12%|█▏        | 471/3968 [00:08<00:53, 65.08 examples/s]Map:  12%|█▏        | 479/3968 [00:08<00:51, 68.37 examples/s]Map:  12%|█▏        | 487/3968 [00:08<00:49, 69.97 examples/s]Map:  12%|█▎        | 496/3968 [00:08<00:49, 70.07 examples/s]Map:  13%|█▎        | 504/3968 [00:08<00:48, 71.31 examples/s]Map:  13%|█▎        | 515/3968 [00:09<00:49, 69.88 examples/s]Map:  13%|█▎        | 523/3968 [00:09<00:49, 70.06 examples/s]Map:  13%|█▎        | 531/3968 [00:09<00:49, 69.73 examples/s]Map:  14%|█▎        | 540/3968 [00:09<00:53, 64.30 examples/s]Map:  14%|█▍        | 548/3968 [00:09<00:52, 65.05 examples/s]Map:  14%|█▍        | 556/3968 [00:09<00:51, 66.63 examples/s]Map:  14%|█▍        | 564/3968 [00:09<00:51, 66.49 examples/s]Map:  14%|█▍        | 573/3968 [00:09<00:48, 70.08 examples/s]Map:  15%|█▍        | 581/3968 [00:10<00:47, 71.47 examples/s]Map:  15%|█▍        | 589/3968 [00:10<00:48, 70.30 examples/s]Map:  15%|█▌        | 597/3968 [00:10<00:49, 68.59 examples/s]Map:  15%|█▌        | 605/3968 [00:10<00:47, 70.75 examples/s]Map:  15%|█▌        | 613/3968 [00:10<00:47, 70.40 examples/s]Map:  16%|█▌        | 621/3968 [00:10<00:48, 69.26 examples/s]Map:  16%|█▌        | 628/3968 [00:10<00:48, 68.49 examples/s]Map:  16%|█▌        | 636/3968 [00:10<00:49, 67.74 examples/s]Map:  16%|█▌        | 643/3968 [00:10<00:49, 67.02 examples/s]Map:  16%|█▋        | 652/3968 [00:11<00:49, 67.14 examples/s]Map:  17%|█▋        | 659/3968 [00:11<00:49, 66.26 examples/s]Map:  17%|█▋        | 667/3968 [00:11<00:48, 67.98 examples/s]Map:  17%|█▋        | 675/3968 [00:11<00:47, 68.71 examples/s]Map:  17%|█▋        | 682/3968 [00:11<00:48, 68.24 examples/s]Map:  17%|█▋        | 690/3968 [00:11<00:48, 67.27 examples/s]Map:  18%|█▊        | 698/3968 [00:11<00:48, 68.03 examples/s]Map:  18%|█▊        | 706/3968 [00:11<00:47, 68.11 examples/s]Map:  18%|█▊        | 715/3968 [00:11<00:46, 69.87 examples/s]Map:  18%|█▊        | 723/3968 [00:12<00:46, 69.58 examples/s]Map:  18%|█▊        | 732/3968 [00:12<00:45, 71.71 examples/s]Map:  19%|█▊        | 743/3968 [00:12<00:45, 71.39 examples/s]Map:  19%|█▉        | 751/3968 [00:12<00:44, 72.23 examples/s]Map:  19%|█▉        | 759/3968 [00:12<00:45, 70.96 examples/s]Map:  19%|█▉        | 767/3968 [00:12<00:45, 70.34 examples/s]Map:  20%|█▉        | 775/3968 [00:12<00:44, 72.24 examples/s]Map:  20%|█▉        | 783/3968 [00:12<00:45, 70.25 examples/s]Map:  20%|█▉        | 791/3968 [00:13<00:43, 72.76 examples/s]Map:  20%|██        | 802/3968 [00:13<00:48, 65.57 examples/s]Map:  20%|██        | 810/3968 [00:13<00:46, 68.41 examples/s]Map:  21%|██        | 819/3968 [00:13<00:45, 69.40 examples/s]Map:  21%|██        | 827/3968 [00:13<00:44, 71.21 examples/s]Map:  21%|██        | 836/3968 [00:13<00:44, 71.03 examples/s]Map:  21%|██▏       | 844/3968 [00:13<00:43, 71.88 examples/s]Map:  21%|██▏       | 852/3968 [00:13<00:43, 72.00 examples/s]Map:  22%|██▏       | 860/3968 [00:14<00:43, 71.18 examples/s]Map:  22%|██▏       | 869/3968 [00:14<00:42, 72.14 examples/s]Map:  22%|██▏       | 877/3968 [00:14<00:43, 71.29 examples/s]Map:  22%|██▏       | 888/3968 [00:14<00:46, 66.81 examples/s]Map:  23%|██▎       | 896/3968 [00:14<00:45, 67.41 examples/s]Map:  23%|██▎       | 904/3968 [00:14<00:45, 67.41 examples/s]Map:  23%|██▎       | 912/3968 [00:14<00:45, 67.25 examples/s]Map:  23%|██▎       | 920/3968 [00:14<00:44, 68.21 examples/s]Map:  23%|██▎       | 928/3968 [00:15<00:44, 69.09 examples/s]Map:  24%|██▎       | 938/3968 [00:15<00:46, 65.28 examples/s]Map:  24%|██▍       | 946/3968 [00:15<00:44, 67.39 examples/s]Map:  24%|██▍       | 954/3968 [00:15<00:43, 69.35 examples/s]Map:  24%|██▍       | 962/3968 [00:15<00:43, 68.32 examples/s]Map:  24%|██▍       | 971/3968 [00:15<00:42, 70.65 examples/s]Map:  25%|██▍       | 979/3968 [00:15<00:41, 71.78 examples/s]Map:  25%|██▍       | 990/3968 [00:15<00:43, 68.02 examples/s]Map:  25%|██▌       | 1000/3968 [00:16<01:48, 27.28 examples/s]Map:  25%|██▌       | 1008/3968 [00:16<01:30, 32.61 examples/s]Map:  26%|██▌       | 1016/3968 [00:16<01:17, 38.18 examples/s]Map:  26%|██▌       | 1025/3968 [00:17<01:05, 44.76 examples/s]Map:  26%|██▌       | 1034/3968 [00:17<00:58, 50.57 examples/s]Map:  26%|██▋       | 1042/3968 [00:17<00:54, 54.03 examples/s]Map:  26%|██▋       | 1050/3968 [00:17<00:49, 58.64 examples/s]Map:  27%|██▋       | 1058/3968 [00:17<00:47, 61.67 examples/s]Map:  27%|██▋       | 1067/3968 [00:17<00:43, 66.13 examples/s]Map:  27%|██▋       | 1076/3968 [00:17<00:42, 67.97 examples/s]Map:  27%|██▋       | 1084/3968 [00:17<00:41, 68.98 examples/s]Map:  28%|██▊       | 1093/3968 [00:18<00:39, 72.21 examples/s]Map:  28%|██▊       | 1101/3968 [00:18<00:39, 72.52 examples/s]Map:  28%|██▊       | 1110/3968 [00:18<00:38, 74.82 examples/s]Map:  28%|██▊       | 1118/3968 [00:18<00:39, 72.64 examples/s]Map:  28%|██▊       | 1126/3968 [00:18<00:39, 71.49 examples/s]Map:  29%|██▊       | 1134/3968 [00:18<00:39, 71.74 examples/s]Map:  29%|██▉       | 1142/3968 [00:18<00:40, 69.65 examples/s]Map:  29%|██▉       | 1150/3968 [00:18<00:39, 70.64 examples/s]Map:  29%|██▉       | 1158/3968 [00:18<00:39, 71.61 examples/s]Map:  29%|██▉       | 1166/3968 [00:19<00:38, 72.44 examples/s]Map:  30%|██▉       | 1174/3968 [00:19<00:37, 73.99 examples/s]Map:  30%|██▉       | 1182/3968 [00:19<00:38, 72.59 examples/s]Map:  30%|███       | 1194/3968 [00:19<00:39, 71.09 examples/s]Map:  30%|███       | 1202/3968 [00:19<00:38, 71.72 examples/s]Map:  30%|███       | 1210/3968 [00:19<00:38, 71.42 examples/s]Map:  31%|███       | 1218/3968 [00:19<00:38, 71.91 examples/s]Map:  31%|███       | 1226/3968 [00:19<00:37, 72.29 examples/s]Map:  31%|███       | 1235/3968 [00:20<00:37, 72.99 examples/s]Map:  31%|███▏      | 1243/3968 [00:20<00:38, 71.54 examples/s]Map:  32%|███▏      | 1251/3968 [00:20<00:37, 72.48 examples/s]Map:  32%|███▏      | 1259/3968 [00:20<00:37, 73.10 examples/s]Map:  32%|███▏      | 1267/3968 [00:20<00:36, 73.86 examples/s]Map:  32%|███▏      | 1275/3968 [00:20<00:38, 70.41 examples/s]Map:  32%|███▏      | 1283/3968 [00:20<00:39, 68.45 examples/s]Map:  33%|███▎      | 1291/3968 [00:20<00:39, 68.07 examples/s]Map:  33%|███▎      | 1299/3968 [00:20<00:38, 68.61 examples/s]Map:  33%|███▎      | 1308/3968 [00:21<00:37, 70.97 examples/s]Map:  33%|███▎      | 1319/3968 [00:21<00:38, 69.63 examples/s]Map:  33%|███▎      | 1327/3968 [00:21<00:38, 68.94 examples/s]Map:  34%|███▎      | 1335/3968 [00:21<00:37, 70.72 examples/s]Map:  34%|███▍      | 1344/3968 [00:21<00:36, 72.48 examples/s]Map:  34%|███▍      | 1352/3968 [00:21<00:36, 71.70 examples/s]Map:  34%|███▍      | 1360/3968 [00:21<00:36, 72.39 examples/s]Map:  34%|███▍      | 1368/3968 [00:21<00:36, 71.15 examples/s]Map:  35%|███▍      | 1376/3968 [00:22<00:36, 70.45 examples/s]Map:  35%|███▍      | 1384/3968 [00:22<00:37, 68.86 examples/s]Map:  35%|███▌      | 1392/3968 [00:22<00:36, 69.80 examples/s]Map:  35%|███▌      | 1400/3968 [00:22<00:36, 71.32 examples/s]Map:  35%|███▌      | 1408/3968 [00:22<00:35, 72.88 examples/s]Map:  36%|███▌      | 1419/3968 [00:22<00:36, 70.21 examples/s]Map:  36%|███▌      | 1427/3968 [00:22<00:36, 70.05 examples/s]Map:  36%|███▌      | 1435/3968 [00:22<00:37, 67.85 examples/s]Map:  36%|███▋      | 1443/3968 [00:22<00:36, 69.26 examples/s]Map:  37%|███▋      | 1452/3968 [00:23<00:35, 71.68 examples/s]Map:  37%|███▋      | 1460/3968 [00:23<00:35, 71.61 examples/s]Map:  37%|███▋      | 1468/3968 [00:23<00:36, 69.35 examples/s]Map:  37%|███▋      | 1476/3968 [00:23<00:35, 70.85 examples/s]Map:  37%|███▋      | 1484/3968 [00:23<00:35, 69.31 examples/s]Map:  38%|███▊      | 1492/3968 [00:23<00:35, 69.60 examples/s]Map:  38%|███▊      | 1500/3968 [00:23<00:35, 69.66 examples/s]Map:  38%|███▊      | 1508/3968 [00:23<00:35, 69.58 examples/s]Map:  38%|███▊      | 1516/3968 [00:24<00:34, 70.71 examples/s]Map:  38%|███▊      | 1524/3968 [00:24<00:34, 70.61 examples/s]Map:  39%|███▊      | 1532/3968 [00:24<00:34, 71.23 examples/s]Map:  39%|███▉      | 1543/3968 [00:24<00:35, 68.39 examples/s]Map:  39%|███▉      | 1553/3968 [00:24<00:38, 63.47 examples/s]Map:  39%|███▉      | 1561/3968 [00:24<00:37, 64.68 examples/s]Map:  40%|███▉      | 1569/3968 [00:24<00:36, 65.82 examples/s]Map:  40%|███▉      | 1577/3968 [00:24<00:35, 67.31 examples/s]Map:  40%|███▉      | 1587/3968 [00:25<00:37, 62.69 examples/s]Map:  40%|████      | 1595/3968 [00:25<00:36, 64.41 examples/s]Map:  40%|████      | 1602/3968 [00:25<00:36, 64.53 examples/s]Map:  41%|████      | 1610/3968 [00:25<00:34, 67.59 examples/s]Map:  41%|████      | 1618/3968 [00:25<00:34, 68.75 examples/s]Map:  41%|████      | 1626/3968 [00:25<00:34, 68.84 examples/s]Map:  41%|████      | 1634/3968 [00:25<00:33, 69.76 examples/s]Map:  41%|████▏     | 1642/3968 [00:25<00:33, 69.12 examples/s]Map:  42%|████▏     | 1650/3968 [00:26<00:33, 70.17 examples/s]Map:  42%|████▏     | 1658/3968 [00:26<00:32, 70.81 examples/s]Map:  42%|████▏     | 1666/3968 [00:26<00:32, 70.23 examples/s]Map:  42%|████▏     | 1674/3968 [00:26<00:32, 70.95 examples/s]Map:  42%|████▏     | 1682/3968 [00:26<00:32, 69.58 examples/s]Map:  43%|████▎     | 1690/3968 [00:26<00:33, 68.61 examples/s]Map:  43%|████▎     | 1698/3968 [00:26<00:32, 68.94 examples/s]Map:  43%|████▎     | 1705/3968 [00:26<00:33, 67.85 examples/s]Map:  43%|████▎     | 1713/3968 [00:26<00:33, 67.00 examples/s]Map:  43%|████▎     | 1721/3968 [00:27<00:33, 67.83 examples/s]Map:  44%|████▎     | 1729/3968 [00:27<00:32, 67.95 examples/s]Map:  44%|████▍     | 1737/3968 [00:27<00:32, 68.13 examples/s]Map:  44%|████▍     | 1746/3968 [00:27<00:31, 69.77 examples/s]Map:  44%|████▍     | 1754/3968 [00:27<00:31, 69.89 examples/s]Map:  44%|████▍     | 1762/3968 [00:27<00:31, 69.95 examples/s]Map:  45%|████▍     | 1770/3968 [00:27<00:31, 70.25 examples/s]Map:  45%|████▍     | 1778/3968 [00:27<00:31, 70.12 examples/s]Map:  45%|████▌     | 1786/3968 [00:27<00:30, 70.65 examples/s]Map:  45%|████▌     | 1794/3968 [00:28<00:30, 71.38 examples/s]Map:  45%|████▌     | 1802/3968 [00:28<00:31, 69.86 examples/s]Map:  46%|████▌     | 1810/3968 [00:28<00:31, 69.21 examples/s]Map:  46%|████▌     | 1818/3968 [00:28<00:31, 68.87 examples/s]Map:  46%|████▌     | 1825/3968 [00:28<00:31, 67.93 examples/s]Map:  46%|████▌     | 1833/3968 [00:28<00:31, 68.18 examples/s]Map:  46%|████▋     | 1840/3968 [00:28<00:32, 65.67 examples/s]Map:  47%|████▋     | 1847/3968 [00:28<00:33, 63.63 examples/s]Map:  47%|████▋     | 1855/3968 [00:29<00:32, 65.89 examples/s]Map:  47%|████▋     | 1864/3968 [00:29<00:30, 68.53 examples/s]Map:  47%|████▋     | 1872/3968 [00:29<00:30, 68.89 examples/s]Map:  47%|████▋     | 1880/3968 [00:29<00:29, 69.80 examples/s]Map:  48%|████▊     | 1888/3968 [00:29<00:29, 70.82 examples/s]Map:  48%|████▊     | 1896/3968 [00:29<00:29, 71.30 examples/s]Map:  48%|████▊     | 1906/3968 [00:29<00:31, 66.47 examples/s]Map:  48%|████▊     | 1913/3968 [00:29<00:30, 66.57 examples/s]Map:  48%|████▊     | 1921/3968 [00:29<00:30, 67.44 examples/s]Map:  49%|████▊     | 1929/3968 [00:30<00:29, 69.52 examples/s]Map:  49%|████▉     | 1937/3968 [00:30<00:29, 69.78 examples/s]Map:  49%|████▉     | 1945/3968 [00:30<00:28, 70.32 examples/s]Map:  49%|████▉     | 1956/3968 [00:30<00:29, 67.56 examples/s]Map:  49%|████▉     | 1963/3968 [00:30<00:31, 64.64 examples/s]Map:  50%|████▉     | 1971/3968 [00:30<00:29, 66.63 examples/s]Map:  50%|████▉     | 1979/3968 [00:30<00:29, 66.85 examples/s]Map:  50%|█████     | 1986/3968 [00:30<00:29, 66.85 examples/s]Map:  50%|█████     | 1994/3968 [00:31<00:28, 68.66 examples/s]Map:  51%|█████     | 2004/3968 [00:31<01:06, 29.63 examples/s]Map:  51%|█████     | 2012/3968 [00:31<00:54, 35.82 examples/s]Map:  51%|█████     | 2020/3968 [00:31<00:46, 41.72 examples/s]Map:  51%|█████     | 2028/3968 [00:32<00:40, 47.35 examples/s]Map:  51%|█████▏    | 2036/3968 [00:32<00:36, 52.95 examples/s]Map:  52%|█████▏    | 2044/3968 [00:32<00:33, 58.10 examples/s]Map:  52%|█████▏    | 2052/3968 [00:32<00:31, 61.54 examples/s]Map:  52%|█████▏    | 2060/3968 [00:32<00:29, 65.44 examples/s]Map:  52%|█████▏    | 2069/3968 [00:32<00:27, 67.91 examples/s]Map:  52%|█████▏    | 2077/3968 [00:32<00:26, 70.58 examples/s]Map:  53%|█████▎    | 2085/3968 [00:32<00:27, 69.60 examples/s]Map:  53%|█████▎    | 2093/3968 [00:32<00:26, 71.43 examples/s]Map:  53%|█████▎    | 2101/3968 [00:33<00:25, 72.22 examples/s]Map:  53%|█████▎    | 2109/3968 [00:33<00:25, 73.24 examples/s]Map:  53%|█████▎    | 2117/3968 [00:33<00:25, 72.26 examples/s]Map:  54%|█████▎    | 2125/3968 [00:33<00:26, 69.08 examples/s]Map:  54%|█████▍    | 2133/3968 [00:33<00:26, 68.62 examples/s]Map:  54%|█████▍    | 2141/3968 [00:33<00:25, 70.68 examples/s]Map:  54%|█████▍    | 2149/3968 [00:33<00:25, 70.20 examples/s]Map:  54%|█████▍    | 2157/3968 [00:33<00:25, 69.77 examples/s]Map:  55%|█████▍    | 2166/3968 [00:33<00:24, 72.25 examples/s]Map:  55%|█████▍    | 2177/3968 [00:34<00:26, 68.00 examples/s]Map:  55%|█████▌    | 2185/3968 [00:34<00:26, 67.90 examples/s]Map:  55%|█████▌    | 2193/3968 [00:34<00:25, 68.74 examples/s]Map:  55%|█████▌    | 2201/3968 [00:34<00:25, 70.68 examples/s]Map:  56%|█████▌    | 2209/3968 [00:34<00:24, 70.74 examples/s]Map:  56%|█████▌    | 2217/3968 [00:34<00:24, 70.93 examples/s]Map:  56%|█████▌    | 2225/3968 [00:34<00:24, 72.47 examples/s]Map:  56%|█████▋    | 2233/3968 [00:34<00:24, 70.78 examples/s]Map:  57%|█████▋    | 2243/3968 [00:35<00:25, 68.62 examples/s]Map:  57%|█████▋    | 2251/3968 [00:35<00:24, 70.74 examples/s]Map:  57%|█████▋    | 2259/3968 [00:35<00:24, 70.72 examples/s]Map:  57%|█████▋    | 2267/3968 [00:35<00:24, 70.20 examples/s]Map:  57%|█████▋    | 2275/3968 [00:35<00:24, 69.40 examples/s]Map:  58%|█████▊    | 2282/3968 [00:35<00:24, 68.75 examples/s]Map:  58%|█████▊    | 2289/3968 [00:35<00:24, 68.12 examples/s]Map:  58%|█████▊    | 2297/3968 [00:35<00:23, 70.30 examples/s]Map:  58%|█████▊    | 2305/3968 [00:35<00:23, 70.83 examples/s]Map:  58%|█████▊    | 2313/3968 [00:36<00:22, 72.40 examples/s]Map:  58%|█████▊    | 2321/3968 [00:36<00:22, 72.41 examples/s]Map:  59%|█████▉    | 2332/3968 [00:36<00:23, 70.18 examples/s]Map:  59%|█████▉    | 2340/3968 [00:36<00:23, 70.17 examples/s]Map:  59%|█████▉    | 2351/3968 [00:36<00:23, 68.16 examples/s]Map:  59%|█████▉    | 2359/3968 [00:36<00:23, 69.61 examples/s]Map:  60%|█████▉    | 2367/3968 [00:36<00:22, 70.00 examples/s]Map:  60%|█████▉    | 2378/3968 [00:37<00:23, 68.99 examples/s]Map:  60%|██████    | 2386/3968 [00:37<00:22, 70.62 examples/s]Map:  60%|██████    | 2397/3968 [00:37<00:22, 70.82 examples/s]Map:  61%|██████    | 2408/3968 [00:37<00:22, 70.26 examples/s]Map:  61%|██████    | 2417/3968 [00:37<00:21, 71.67 examples/s]Map:  61%|██████    | 2425/3968 [00:37<00:21, 72.40 examples/s]Map:  61%|██████▏   | 2433/3968 [00:37<00:21, 70.61 examples/s]Map:  62%|██████▏   | 2441/3968 [00:37<00:21, 71.50 examples/s]Map:  62%|██████▏   | 2449/3968 [00:38<00:21, 70.91 examples/s]Map:  62%|██████▏   | 2457/3968 [00:38<00:21, 71.04 examples/s]Map:  62%|██████▏   | 2465/3968 [00:38<00:21, 71.02 examples/s]Map:  62%|██████▏   | 2473/3968 [00:38<00:21, 68.82 examples/s]Map:  63%|██████▎   | 2481/3968 [00:38<00:21, 69.00 examples/s]Map:  63%|██████▎   | 2489/3968 [00:38<00:21, 70.07 examples/s]Map:  63%|██████▎   | 2497/3968 [00:38<00:20, 70.94 examples/s]Map:  63%|██████▎   | 2505/3968 [00:38<00:20, 71.26 examples/s]Map:  63%|██████▎   | 2513/3968 [00:38<00:20, 70.98 examples/s]Map:  64%|██████▎   | 2525/3968 [00:39<00:21, 66.95 examples/s]Map:  64%|██████▍   | 2533/3968 [00:39<00:21, 67.46 examples/s]Map:  64%|██████▍   | 2541/3968 [00:39<00:20, 68.40 examples/s]Map:  64%|██████▍   | 2550/3968 [00:39<00:19, 71.03 examples/s]Map:  64%|██████▍   | 2558/3968 [00:39<00:19, 72.16 examples/s]Map:  65%|██████▍   | 2566/3968 [00:39<00:19, 73.35 examples/s]Map:  65%|██████▍   | 2574/3968 [00:39<00:18, 74.25 examples/s]Map:  65%|██████▌   | 2582/3968 [00:39<00:18, 73.67 examples/s]Map:  65%|██████▌   | 2590/3968 [00:39<00:19, 71.88 examples/s]Map:  65%|██████▌   | 2598/3968 [00:40<00:19, 70.81 examples/s]Map:  66%|██████▌   | 2609/3968 [00:40<00:19, 70.02 examples/s]Map:  66%|██████▌   | 2617/3968 [00:40<00:19, 69.89 examples/s]Map:  66%|██████▌   | 2625/3968 [00:40<00:19, 69.13 examples/s]Map:  66%|██████▋   | 2634/3968 [00:40<00:18, 70.98 examples/s]Map:  67%|██████▋   | 2643/3968 [00:40<00:18, 72.74 examples/s]Map:  67%|██████▋   | 2651/3968 [00:40<00:18, 70.99 examples/s]Map:  67%|██████▋   | 2659/3968 [00:40<00:18, 71.66 examples/s]Map:  67%|██████▋   | 2667/3968 [00:41<00:18, 71.45 examples/s]Map:  67%|██████▋   | 2675/3968 [00:41<00:18, 69.72 examples/s]Map:  68%|██████▊   | 2683/3968 [00:41<00:18, 70.08 examples/s]Map:  68%|██████▊   | 2694/3968 [00:41<00:18, 69.23 examples/s]Map:  68%|██████▊   | 2702/3968 [00:41<00:17, 70.38 examples/s]Map:  68%|██████▊   | 2711/3968 [00:41<00:17, 71.45 examples/s]Map:  69%|██████▊   | 2720/3968 [00:41<00:17, 71.96 examples/s]Map:  69%|██████▉   | 2728/3968 [00:41<00:17, 70.85 examples/s]Map:  69%|██████▉   | 2737/3968 [00:42<00:16, 72.76 examples/s]Map:  69%|██████▉   | 2745/3968 [00:42<00:17, 71.21 examples/s]Map:  69%|██████▉   | 2753/3968 [00:42<00:17, 71.29 examples/s]Map:  70%|██████▉   | 2762/3968 [00:42<00:16, 73.75 examples/s]Map:  70%|██████▉   | 2770/3968 [00:42<00:16, 73.04 examples/s]Map:  70%|███████   | 2778/3968 [00:42<00:16, 71.33 examples/s]Map:  70%|███████   | 2787/3968 [00:42<00:16, 72.81 examples/s]Map:  70%|███████   | 2795/3968 [00:42<00:16, 71.78 examples/s]Map:  71%|███████   | 2803/3968 [00:42<00:16, 69.90 examples/s]Map:  71%|███████   | 2812/3968 [00:43<00:16, 70.09 examples/s]Map:  71%|███████   | 2820/3968 [00:43<00:16, 71.40 examples/s]Map:  71%|███████▏  | 2828/3968 [00:43<00:15, 73.35 examples/s]Map:  72%|███████▏  | 2839/3968 [00:43<00:16, 69.47 examples/s]Map:  72%|███████▏  | 2848/3968 [00:43<00:15, 72.05 examples/s]Map:  72%|███████▏  | 2856/3968 [00:43<00:15, 72.44 examples/s]Map:  72%|███████▏  | 2867/3968 [00:43<00:15, 70.05 examples/s]Map:  73%|███████▎  | 2878/3968 [00:44<00:15, 69.60 examples/s]Map:  73%|███████▎  | 2887/3968 [00:44<00:15, 70.29 examples/s]Map:  73%|███████▎  | 2895/3968 [00:44<00:15, 70.26 examples/s]Map:  73%|███████▎  | 2904/3968 [00:44<00:14, 71.99 examples/s]Map:  73%|███████▎  | 2912/3968 [00:44<00:14, 71.08 examples/s]Map:  74%|███████▎  | 2920/3968 [00:44<00:14, 71.04 examples/s]Map:  74%|███████▍  | 2928/3968 [00:44<00:14, 70.14 examples/s]Map:  74%|███████▍  | 2936/3968 [00:44<00:14, 69.93 examples/s]Map:  74%|███████▍  | 2944/3968 [00:44<00:14, 71.41 examples/s]Map:  74%|███████▍  | 2952/3968 [00:45<00:14, 69.80 examples/s]Map:  75%|███████▍  | 2960/3968 [00:45<00:14, 71.78 examples/s]Map:  75%|███████▍  | 2968/3968 [00:45<00:13, 72.18 examples/s]Map:  75%|███████▌  | 2976/3968 [00:45<00:13, 71.44 examples/s]Map:  75%|███████▌  | 2984/3968 [00:45<00:13, 70.71 examples/s]Map:  75%|███████▌  | 2992/3968 [00:45<00:13, 72.22 examples/s]Map:  76%|███████▌  | 3000/3968 [00:46<00:35, 27.05 examples/s]Map:  76%|███████▌  | 3008/3968 [00:46<00:29, 32.72 examples/s]Map:  76%|███████▌  | 3016/3968 [00:46<00:24, 39.36 examples/s]Map:  76%|███████▌  | 3024/3968 [00:46<00:20, 45.81 examples/s]Map:  76%|███████▋  | 3031/3968 [00:46<00:19, 49.07 examples/s]Map:  77%|███████▋  | 3040/3968 [00:46<00:16, 55.49 examples/s]Map:  77%|███████▋  | 3048/3968 [00:47<00:15, 60.35 examples/s]Map:  77%|███████▋  | 3056/3968 [00:47<00:14, 64.15 examples/s]Map:  77%|███████▋  | 3064/3968 [00:47<00:13, 66.15 examples/s]Map:  77%|███████▋  | 3072/3968 [00:47<00:12, 69.44 examples/s]Map:  78%|███████▊  | 3080/3968 [00:47<00:12, 70.92 examples/s]Map:  78%|███████▊  | 3088/3968 [00:47<00:12, 72.54 examples/s]Map:  78%|███████▊  | 3097/3968 [00:47<00:11, 73.58 examples/s]Map:  78%|███████▊  | 3105/3968 [00:47<00:11, 74.70 examples/s]Map:  78%|███████▊  | 3113/3968 [00:47<00:11, 73.92 examples/s]Map:  79%|███████▊  | 3122/3968 [00:48<00:11, 72.94 examples/s]Map:  79%|███████▉  | 3130/3968 [00:48<00:11, 73.48 examples/s]Map:  79%|███████▉  | 3138/3968 [00:48<00:11, 74.13 examples/s]Map:  79%|███████▉  | 3146/3968 [00:48<00:11, 71.54 examples/s]Map:  80%|███████▉  | 3155/3968 [00:48<00:10, 74.17 examples/s]Map:  80%|███████▉  | 3163/3968 [00:48<00:10, 74.35 examples/s]Map:  80%|███████▉  | 3172/3968 [00:48<00:10, 72.93 examples/s]Map:  80%|████████  | 3183/3968 [00:48<00:11, 70.67 examples/s]Map:  80%|████████  | 3191/3968 [00:49<00:10, 71.90 examples/s]Map:  81%|████████  | 3199/3968 [00:49<00:10, 72.42 examples/s]Map:  81%|████████  | 3207/3968 [00:49<00:10, 72.25 examples/s]Map:  81%|████████  | 3215/3968 [00:49<00:10, 72.24 examples/s]Map:  81%|████████  | 3223/3968 [00:49<00:10, 72.28 examples/s]Map:  81%|████████▏ | 3232/3968 [00:49<00:10, 73.09 examples/s]Map:  82%|████████▏ | 3243/3968 [00:49<00:10, 69.36 examples/s]Map:  82%|████████▏ | 3252/3968 [00:49<00:09, 72.16 examples/s]Map:  82%|████████▏ | 3260/3968 [00:49<00:09, 72.11 examples/s]Map:  82%|████████▏ | 3268/3968 [00:50<00:09, 72.40 examples/s]Map:  83%|████████▎ | 3279/3968 [00:50<00:09, 70.34 examples/s]Map:  83%|████████▎ | 3290/3968 [00:50<00:09, 69.43 examples/s]Map:  83%|████████▎ | 3298/3968 [00:50<00:09, 69.47 examples/s]Map:  83%|████████▎ | 3307/3968 [00:50<00:09, 69.97 examples/s]Map:  84%|████████▎ | 3315/3968 [00:50<00:09, 69.33 examples/s]Map:  84%|████████▎ | 3323/3968 [00:50<00:09, 69.42 examples/s]Map:  84%|████████▍ | 3331/3968 [00:50<00:08, 71.46 examples/s]Map:  84%|████████▍ | 3340/3968 [00:51<00:08, 73.22 examples/s]Map:  84%|████████▍ | 3351/3968 [00:51<00:08, 70.51 examples/s]Map:  85%|████████▍ | 3359/3968 [00:51<00:08, 71.33 examples/s]Map:  85%|████████▍ | 3367/3968 [00:51<00:08, 70.64 examples/s]Map:  85%|████████▌ | 3375/3968 [00:51<00:08, 70.92 examples/s]Map:  85%|████████▌ | 3386/3968 [00:51<00:08, 67.59 examples/s]Map:  86%|████████▌ | 3394/3968 [00:51<00:08, 69.49 examples/s]Map:  86%|████████▌ | 3402/3968 [00:51<00:08, 68.40 examples/s]Map:  86%|████████▌ | 3409/3968 [00:52<00:08, 65.87 examples/s]Map:  86%|████████▌ | 3417/3968 [00:52<00:08, 68.06 examples/s]Map:  86%|████████▋ | 3424/3968 [00:52<00:08, 66.59 examples/s]Map:  86%|████████▋ | 3431/3968 [00:52<00:08, 66.13 examples/s]Map:  87%|████████▋ | 3439/3968 [00:52<00:07, 67.63 examples/s]Map:  87%|████████▋ | 3447/3968 [00:52<00:07, 68.16 examples/s]Map:  87%|████████▋ | 3454/3968 [00:52<00:07, 65.81 examples/s]Map:  87%|████████▋ | 3461/3968 [00:52<00:07, 65.72 examples/s]Map:  87%|████████▋ | 3469/3968 [00:52<00:07, 69.00 examples/s]Map:  88%|████████▊ | 3477/3968 [00:53<00:06, 70.25 examples/s]Map:  88%|████████▊ | 3485/3968 [00:53<00:06, 70.86 examples/s]Map:  88%|████████▊ | 3494/3968 [00:53<00:06, 71.62 examples/s]Map:  88%|████████▊ | 3502/3968 [00:53<00:06, 72.13 examples/s]Map:  88%|████████▊ | 3510/3968 [00:53<00:06, 72.96 examples/s]Map:  89%|████████▊ | 3521/3968 [00:53<00:06, 70.16 examples/s]Map:  89%|████████▉ | 3529/3968 [00:53<00:06, 69.51 examples/s]Map:  89%|████████▉ | 3537/3968 [00:53<00:06, 70.81 examples/s]Map:  89%|████████▉ | 3545/3968 [00:54<00:05, 71.69 examples/s]Map:  90%|████████▉ | 3553/3968 [00:54<00:05, 71.51 examples/s]Map:  90%|████████▉ | 3561/3968 [00:54<00:05, 72.02 examples/s]Map:  90%|████████▉ | 3569/3968 [00:54<00:05, 73.28 examples/s]Map:  90%|█████████ | 3577/3968 [00:54<00:05, 72.58 examples/s]Map:  90%|█████████ | 3585/3968 [00:54<00:05, 73.57 examples/s]Map:  91%|█████████ | 3594/3968 [00:54<00:04, 75.01 examples/s]Map:  91%|█████████ | 3602/3968 [00:54<00:04, 74.34 examples/s]Map:  91%|█████████ | 3610/3968 [00:54<00:04, 74.48 examples/s]Map:  91%|█████████ | 3619/3968 [00:55<00:04, 75.46 examples/s]Map:  91%|█████████▏| 3627/3968 [00:55<00:04, 74.45 examples/s]Map:  92%|█████████▏| 3635/3968 [00:55<00:04, 72.74 examples/s]Map:  92%|█████████▏| 3643/3968 [00:55<00:04, 70.26 examples/s]Map:  92%|█████████▏| 3651/3968 [00:55<00:04, 71.37 examples/s]Map:  92%|█████████▏| 3659/3968 [00:55<00:04, 73.00 examples/s]Map:  92%|█████████▏| 3667/3968 [00:55<00:04, 73.80 examples/s]Map:  93%|█████████▎| 3675/3968 [00:55<00:04, 71.59 examples/s]Map:  93%|█████████▎| 3686/3968 [00:56<00:04, 69.36 examples/s]Map:  93%|█████████▎| 3697/3968 [00:56<00:03, 68.84 examples/s]Map:  93%|█████████▎| 3705/3968 [00:56<00:03, 69.11 examples/s]Map:  94%|█████████▎| 3713/3968 [00:56<00:03, 71.06 examples/s]Map:  94%|█████████▍| 3721/3968 [00:56<00:03, 71.70 examples/s]Map:  94%|█████████▍| 3729/3968 [00:56<00:03, 71.31 examples/s]Map:  94%|█████████▍| 3737/3968 [00:56<00:03, 71.35 examples/s]Map:  94%|█████████▍| 3745/3968 [00:56<00:03, 69.91 examples/s]Map:  95%|█████████▍| 3754/3968 [00:56<00:02, 71.40 examples/s]Map:  95%|█████████▍| 3762/3968 [00:57<00:02, 70.91 examples/s]Map:  95%|█████████▌| 3771/3968 [00:57<00:02, 72.01 examples/s]Map:  95%|█████████▌| 3780/3968 [00:57<00:02, 73.71 examples/s]Map:  95%|█████████▌| 3788/3968 [00:57<00:02, 74.86 examples/s]Map:  96%|█████████▌| 3796/3968 [00:57<00:02, 70.19 examples/s]Map:  96%|█████████▌| 3807/3968 [00:57<00:02, 69.66 examples/s]Map:  96%|█████████▌| 3819/3968 [00:57<00:02, 70.20 examples/s]Map:  96%|█████████▋| 3828/3968 [00:58<00:02, 69.66 examples/s]Map:  97%|█████████▋| 3836/3968 [00:58<00:01, 69.67 examples/s]Map:  97%|█████████▋| 3844/3968 [00:58<00:01, 71.45 examples/s]Map:  97%|█████████▋| 3852/3968 [00:58<00:01, 70.05 examples/s]Map:  97%|█████████▋| 3863/3968 [00:58<00:01, 67.80 examples/s]Map:  98%|█████████▊| 3872/3968 [00:58<00:01, 69.67 examples/s]Map:  98%|█████████▊| 3880/3968 [00:58<00:01, 70.02 examples/s]Map:  98%|█████████▊| 3888/3968 [00:58<00:01, 69.69 examples/s]Map:  98%|█████████▊| 3897/3968 [00:58<00:00, 71.02 examples/s]Map:  98%|█████████▊| 3905/3968 [00:59<00:00, 72.16 examples/s]Map:  99%|█████████▊| 3913/3968 [00:59<00:00, 71.54 examples/s]Map:  99%|█████████▉| 3921/3968 [00:59<00:00, 70.10 examples/s]Map:  99%|█████████▉| 3929/3968 [00:59<00:00, 69.43 examples/s]Map:  99%|█████████▉| 3937/3968 [00:59<00:00, 70.48 examples/s]Map:  99%|█████████▉| 3946/3968 [00:59<00:00, 71.79 examples/s]Map: 100%|█████████▉| 3957/3968 [00:59<00:00, 69.40 examples/s]Map: 100%|█████████▉| 3965/3968 [00:59<00:00, 70.01 examples/s]                                                               Saved results to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.810
Fine-tuned Test CER: 0.402


--> Getting finetuned alignment output...
Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 723, in <module>
    word_output = jiwer.process_words(results["target_text"], results["pred_str"])
NameError: name 'jiwer' is not defined. Did you mean: 'iter'?
Wed Oct 11 19:28:28 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 19:28:28

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 472.62it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ed4c3c62259f8860.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6a742c374d450edc.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-2a8d149b1580a6d7_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-64124eb72cd7ef7c_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-fae4936ac3f472aa_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f8ae5a66baaae03c_*_of_00004.arrow
/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py:557: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/hubert/modeling_hubert.py:1125: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-564c8a88509f2834.arrow
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: BI BUBBLES BIG WHY ARE SOME SMALL
Input array shape: (46881,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.810
Fine-tuned Test CER: 0.402


--> Getting finetuned alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     BREATHE    BREATHE
1      CARPET        OPA
2   AUSTRALIA  AUSTRALIA
3        PULL        PUL
4    CUCUMBER      TUCUM
5       SWING      SWING
6     FEATHER    FEATHER
7      GARDEN      GOTEN
8      CARPET    CARPRET
9       CHAIR           
--> Taking a deeper look...
<pad> <pad> <pad> B B <pad> I I <pad> <pad> <pad> <pad> <pad> <pad> R R <pad> <pad> <pad> <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Downloading (…)rocessor_config.json:   0%|          | 0.00/213 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|██████████| 213/213 [00:00<00:00, 1.59MB/s]
Downloading (…)lve/main/config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 1.39k/1.39k [00:00<00:00, 15.2MB/s]
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: 
  warnings.warn(
Traceback (most recent call last):
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 51, in from_pretrained
    return super().from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 184, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 228, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 693, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 756, in <module>
    processor = Wav2Vec2Processor.from_pretrained(baseline_model, cache_dir=model_cache_fp)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 63, in from_pretrained
    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.
Wed Oct 11 19:32:51 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 19:32:51

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 467.91it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ed4c3c62259f8860.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6a742c374d450edc.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-2a8d149b1580a6d7_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-64124eb72cd7ef7c_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-fae4936ac3f472aa_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f8ae5a66baaae03c_*_of_00004.arrow
/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py:557: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/hubert/modeling_hubert.py:1125: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-564c8a88509f2834.arrow
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: 
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: BI BUBBLES BIG WHY ARE SOME SMALL
Input array shape: (46881,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.810
Fine-tuned Test CER: 0.402


--> Getting finetuned alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     BREATHE    BREATHE
1      CARPET        OPA
2   AUSTRALIA  AUSTRALIA
3        PULL        PUL
4    CUCUMBER      TUCUM
5       SWING      SWING
6     FEATHER    FEATHER
7      GARDEN      GOTEN
8      CARPET    CARPRET
9       CHAIR           
--> Taking a deeper look...
<pad> <pad> <pad> B B <pad> I I <pad> <pad> <pad> <pad> <pad> <pad> R R <pad> <pad> <pad> <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Traceback (most recent call last):
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 51, in from_pretrained
    return super().from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 184, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 228, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 693, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 756, in <module>
    processor = Wav2Vec2Processor.from_pretrained(baseline_model, cache_dir=model_cache_fp)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 63, in from_pretrained
    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.
Wed Oct 11 19:37:49 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 19:37:49

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/hubert-base-ls960
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/hubert-base-ls960

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 383.92it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ed4c3c62259f8860.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6a742c374d450edc.arrow
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------

Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 388, in <module>
    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_tokenizer, cache_dir=model_cache_fp)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.
Wed Oct 11 19:59:11 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 19:59:11

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/hubert-base-ls960
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/hubert-base-ls960

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 59.61it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ed4c3c62259f8860.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6a742c374d450edc.arrow
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------

Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 388, in <module>
    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_tokenizer, cache_dir=model_cache_fp)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.
Wed Oct 11 20:27:45 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 20:27:46

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 32.45it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ed4c3c62259f8860.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6a742c374d450edc.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-2a8d149b1580a6d7_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-64124eb72cd7ef7c_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-fae4936ac3f472aa_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f8ae5a66baaae03c_*_of_00004.arrow
/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py:557: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/hubert/modeling_hubert.py:1125: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-564c8a88509f2834.arrow
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: 
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: BI BUBBLES BIG WHY ARE SOME SMALL
Input array shape: (46881,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.810
Fine-tuned Test CER: 0.402


--> Getting finetuned alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     BREATHE    BREATHE
1      CARPET        OPA
2   AUSTRALIA  AUSTRALIA
3        PULL        PUL
4    CUCUMBER      TUCUM
5       SWING      SWING
6     FEATHER    FEATHER
7      GARDEN      GOTEN
8      CARPET    CARPRET
9       CHAIR           
--> Taking a deeper look...
<pad> <pad> <pad> B B <pad> I I <pad> <pad> <pad> <pad> <pad> <pad> R R <pad> <pad> <pad> <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Traceback (most recent call last):
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 51, in from_pretrained
    return super().from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 184, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 228, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 693, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 756, in <module>
    processor = Wav2Vec2Processor.from_pretrained(baseline_model, cache_dir=model_cache_fp)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 63, in from_pretrained
    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.
Wed Oct 11 20:31:39 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 20:31:39

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 521.65it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ed4c3c62259f8860.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6a742c374d450edc.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-2a8d149b1580a6d7_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-64124eb72cd7ef7c_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-fae4936ac3f472aa_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f8ae5a66baaae03c_*_of_00004.arrow
/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py:557: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/hubert/modeling_hubert.py:1125: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-564c8a88509f2834.arrow
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: 
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: BI BUBBLES BIG WHY ARE SOME SMALL
Input array shape: (46881,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.810
Fine-tuned Test CER: 0.402


--> Getting finetuned alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     BREATHE    BREATHE
1      CARPET        OPA
2   AUSTRALIA  AUSTRALIA
3        PULL        PUL
4    CUCUMBER      TUCUM
5       SWING      SWING
6     FEATHER    FEATHER
7      GARDEN      GOTEN
8      CARPET    CARPRET
9       CHAIR           
--> Taking a deeper look...
<pad> <pad> <pad> B B <pad> I I <pad> <pad> <pad> <pad> <pad> <pad> R R <pad> <pad> <pad> <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Traceback (most recent call last):
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 51, in from_pretrained
    return super().from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 184, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 228, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 693, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 756, in <module>
    processor = Wav2Vec2Processor.from_pretrained(baseline_model, cache_dir=model_cache_fp)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 63, in from_pretrained
    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.
Wed Oct 11 20:35:53 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 20:35:53

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-base-ls960
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 408.03it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ed4c3c62259f8860.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6a742c374d450edc.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-2a8d149b1580a6d7_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-64124eb72cd7ef7c_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-fae4936ac3f472aa_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f8ae5a66baaae03c_*_of_00004.arrow
/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py:557: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/hubert/modeling_hubert.py:1125: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-564c8a88509f2834.arrow
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: 
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: BI BUBBLES BIG WHY ARE SOME SMALL
Input array shape: (46881,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.810
Fine-tuned Test CER: 0.402


--> Getting finetuned alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     BREATHE    BREATHE
1      CARPET        OPA
2   AUSTRALIA  AUSTRALIA
3        PULL        PUL
4    CUCUMBER      TUCUM
5       SWING      SWING
6     FEATHER    FEATHER
7      GARDEN      GOTEN
8      CARPET    CARPRET
9       CHAIR           
--> Taking a deeper look...
<pad> <pad> <pad> B B <pad> I I <pad> <pad> <pad> <pad> <pad> <pad> R R <pad> <pad> <pad> <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Traceback (most recent call last):
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 51, in from_pretrained
    return super().from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 184, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 228, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 693, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py", line 756, in <module>
    processor = Wav2Vec2Processor.from_pretrained(baseline_model, cache_dir=model_cache_fp)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 63, in from_pretrained
    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1796, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for 'facebook/hubert-base-ls960'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/hubert-base-ls960' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.
Wed Oct 11 20:46:33 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 20:46:33

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20230926_4
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-large-ls960-ft
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 422.51it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ed4c3c62259f8860.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6a742c374d450edc.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-2a8d149b1580a6d7_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-64124eb72cd7ef7c_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-fae4936ac3f472aa_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f8ae5a66baaae03c_*_of_00004.arrow
/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py:557: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/hubert/modeling_hubert.py:1125: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-564c8a88509f2834.arrow
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: BI BUBBLES BIG WHY ARE SOME SMALL
Input array shape: (46881,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.810
Fine-tuned Test CER: 0.402


--> Getting finetuned alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_finetuned_result.txt


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     BREATHE    BREATHE
1      CARPET        OPA
2   AUSTRALIA  AUSTRALIA
3        PULL        PUL
4    CUCUMBER      TUCUM
5       SWING      SWING
6     FEATHER    FEATHER
7      GARDEN      GOTEN
8      CARPET    CARPRET
9       CHAIR           
--> Taking a deeper look...
<pad> <pad> <pad> B B <pad> I I <pad> <pad> <pad> <pad> <pad> <pad> R R <pad> <pad> <pad> <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Downloading (…)rocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|██████████| 212/212 [00:00<00:00, 1.54MB/s]
Downloading (…)okenizer_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 138/138 [00:00<00:00, 1.48MB/s]
Downloading (…)lve/main/config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 1.38k/1.38k [00:00<00:00, 15.3MB/s]
Downloading (…)olve/main/vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 291/291 [00:00<00:00, 3.30MB/s]
Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 977kB/s]
Downloading pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|          | 10.5M/1.26G [00:01<02:40, 7.82MB/s]Downloading pytorch_model.bin:   2%|▏         | 21.0M/1.26G [00:02<01:54, 10.8MB/s]Downloading pytorch_model.bin:   2%|▏         | 31.5M/1.26G [00:02<01:24, 14.6MB/s]Downloading pytorch_model.bin:   3%|▎         | 41.9M/1.26G [00:02<01:07, 18.0MB/s]Downloading pytorch_model.bin:   4%|▍         | 52.4M/1.26G [00:03<00:57, 21.1MB/s]Downloading pytorch_model.bin:   5%|▍         | 62.9M/1.26G [00:03<00:50, 23.8MB/s]Downloading pytorch_model.bin:   6%|▌         | 73.4M/1.26G [00:03<00:45, 26.1MB/s]Downloading pytorch_model.bin:   7%|▋         | 83.9M/1.26G [00:04<00:41, 28.1MB/s]Downloading pytorch_model.bin:   7%|▋         | 94.4M/1.26G [00:04<00:39, 29.9MB/s]Downloading pytorch_model.bin:   8%|▊         | 105M/1.26G [00:04<00:42, 27.0MB/s] Downloading pytorch_model.bin:   9%|▉         | 115M/1.26G [00:05<00:44, 25.7MB/s]Downloading pytorch_model.bin:  10%|▉         | 126M/1.26G [00:05<00:41, 27.2MB/s]Downloading pytorch_model.bin:  11%|█         | 136M/1.26G [00:05<00:38, 29.6MB/s]Downloading pytorch_model.bin:  12%|█▏        | 147M/1.26G [00:06<00:40, 27.7MB/s]Downloading pytorch_model.bin:  12%|█▏        | 157M/1.26G [00:06<00:43, 25.2MB/s]Downloading pytorch_model.bin:  13%|█▎        | 168M/1.26G [00:07<00:41, 26.3MB/s]Downloading pytorch_model.bin:  14%|█▍        | 178M/1.26G [00:07<00:41, 26.2MB/s]Downloading pytorch_model.bin:  15%|█▍        | 189M/1.26G [00:08<00:39, 27.4MB/s]Downloading pytorch_model.bin:  16%|█▌        | 199M/1.26G [00:08<00:37, 28.1MB/s]Downloading pytorch_model.bin:  17%|█▋        | 210M/1.26G [00:08<00:37, 28.3MB/s]Downloading pytorch_model.bin:  17%|█▋        | 220M/1.26G [00:09<00:35, 29.3MB/s]Downloading pytorch_model.bin:  18%|█▊        | 231M/1.26G [00:09<00:34, 30.3MB/s]Downloading pytorch_model.bin:  19%|█▉        | 241M/1.26G [00:09<00:32, 31.2MB/s]Downloading pytorch_model.bin:  20%|█▉        | 252M/1.26G [00:10<00:31, 32.1MB/s]Downloading pytorch_model.bin:  21%|██        | 262M/1.26G [00:10<00:30, 32.9MB/s]Downloading pytorch_model.bin:  22%|██▏       | 273M/1.26G [00:10<00:29, 33.9MB/s]Downloading pytorch_model.bin:  22%|██▏       | 283M/1.26G [00:10<00:27, 35.6MB/s]Downloading pytorch_model.bin:  23%|██▎       | 294M/1.26G [00:11<00:36, 26.8MB/s]Downloading pytorch_model.bin:  24%|██▍       | 304M/1.26G [00:11<00:38, 24.7MB/s]Downloading pytorch_model.bin:  25%|██▍       | 315M/1.26G [00:12<00:36, 26.0MB/s]Downloading pytorch_model.bin:  26%|██▌       | 325M/1.26G [00:12<00:35, 26.3MB/s]Downloading pytorch_model.bin:  27%|██▋       | 336M/1.26G [00:13<00:33, 27.5MB/s]Downloading pytorch_model.bin:  27%|██▋       | 346M/1.26G [00:13<00:31, 28.7MB/s]Downloading pytorch_model.bin:  28%|██▊       | 357M/1.26G [00:13<00:30, 29.8MB/s]Downloading pytorch_model.bin:  29%|██▉       | 367M/1.26G [00:14<00:29, 30.8MB/s]Downloading pytorch_model.bin:  30%|██▉       | 377M/1.26G [00:14<00:27, 31.7MB/s]Downloading pytorch_model.bin:  31%|███       | 388M/1.26G [00:14<00:26, 32.5MB/s]Downloading pytorch_model.bin:  32%|███▏      | 398M/1.26G [00:15<00:27, 31.1MB/s]Downloading pytorch_model.bin:  32%|███▏      | 409M/1.26G [00:15<00:33, 25.1MB/s]Downloading pytorch_model.bin:  33%|███▎      | 419M/1.26G [00:15<00:31, 26.9MB/s]Downloading pytorch_model.bin:  34%|███▍      | 430M/1.26G [00:16<00:28, 29.1MB/s]Downloading pytorch_model.bin:  35%|███▍      | 440M/1.26G [00:16<00:30, 26.7MB/s]Downloading pytorch_model.bin:  36%|███▌      | 451M/1.26G [00:17<00:34, 23.3MB/s]Downloading pytorch_model.bin:  37%|███▋      | 461M/1.26G [00:17<00:33, 24.0MB/s]Downloading pytorch_model.bin:  37%|███▋      | 472M/1.26G [00:18<00:31, 25.5MB/s]Downloading pytorch_model.bin:  38%|███▊      | 482M/1.26G [00:18<00:29, 26.7MB/s]Downloading pytorch_model.bin:  39%|███▉      | 493M/1.26G [00:18<00:28, 26.9MB/s]Downloading pytorch_model.bin:  40%|███▉      | 503M/1.26G [00:19<00:26, 28.3MB/s]Downloading pytorch_model.bin:  41%|████      | 514M/1.26G [00:19<00:25, 29.5MB/s]Downloading pytorch_model.bin:  42%|████▏     | 524M/1.26G [00:19<00:24, 30.6MB/s]Downloading pytorch_model.bin:  42%|████▏     | 535M/1.26G [00:20<00:22, 31.8MB/s]Downloading pytorch_model.bin:  43%|████▎     | 545M/1.26G [00:20<00:21, 32.8MB/s]Downloading pytorch_model.bin:  44%|████▍     | 556M/1.26G [00:21<00:29, 23.8MB/s]Downloading pytorch_model.bin:  45%|████▍     | 566M/1.26G [00:21<00:26, 26.8MB/s]Downloading pytorch_model.bin:  46%|████▌     | 577M/1.26G [00:21<00:22, 30.1MB/s]Downloading pytorch_model.bin:  47%|████▋     | 587M/1.26G [00:21<00:20, 32.4MB/s]Downloading pytorch_model.bin:  47%|████▋     | 598M/1.26G [00:22<00:21, 31.4MB/s]Downloading pytorch_model.bin:  48%|████▊     | 608M/1.26G [00:22<00:24, 27.2MB/s]Downloading pytorch_model.bin:  49%|████▉     | 619M/1.26G [00:23<00:23, 27.9MB/s]Downloading pytorch_model.bin:  50%|████▉     | 629M/1.26G [00:23<00:22, 27.6MB/s]Downloading pytorch_model.bin:  51%|█████     | 640M/1.26G [00:23<00:21, 28.7MB/s]Downloading pytorch_model.bin:  52%|█████▏    | 650M/1.26G [00:24<00:24, 25.0MB/s]Downloading pytorch_model.bin:  52%|█████▏    | 661M/1.26G [00:24<00:23, 25.5MB/s]Downloading pytorch_model.bin:  53%|█████▎    | 671M/1.26G [00:25<00:21, 26.9MB/s]Downloading pytorch_model.bin:  54%|█████▍    | 682M/1.26G [00:25<00:20, 28.4MB/s]Downloading pytorch_model.bin:  55%|█████▍    | 692M/1.26G [00:25<00:19, 29.8MB/s]Downloading pytorch_model.bin:  56%|█████▌    | 703M/1.26G [00:26<00:21, 26.5MB/s]Downloading pytorch_model.bin:  56%|█████▋    | 713M/1.26G [00:26<00:20, 26.9MB/s]Downloading pytorch_model.bin:  57%|█████▋    | 724M/1.26G [00:26<00:18, 28.8MB/s]Downloading pytorch_model.bin:  58%|█████▊    | 734M/1.26G [00:27<00:17, 30.7MB/s]Downloading pytorch_model.bin:  59%|█████▉    | 744M/1.26G [00:27<00:15, 32.6MB/s]Downloading pytorch_model.bin:  60%|█████▉    | 755M/1.26G [00:27<00:14, 34.6MB/s]Downloading pytorch_model.bin:  61%|██████    | 765M/1.26G [00:27<00:13, 36.5MB/s]Downloading pytorch_model.bin:  61%|██████▏   | 776M/1.26G [00:28<00:14, 32.5MB/s]Downloading pytorch_model.bin:  62%|██████▏   | 786M/1.26G [00:28<00:17, 27.8MB/s]Downloading pytorch_model.bin:  63%|██████▎   | 797M/1.26G [00:29<00:16, 28.3MB/s]Downloading pytorch_model.bin:  64%|██████▍   | 807M/1.26G [00:29<00:16, 27.7MB/s]Downloading pytorch_model.bin:  65%|██████▍   | 818M/1.26G [00:29<00:15, 28.5MB/s]Downloading pytorch_model.bin:  66%|██████▌   | 828M/1.26G [00:30<00:15, 28.9MB/s]Downloading pytorch_model.bin:  66%|██████▋   | 839M/1.26G [00:30<00:14, 29.6MB/s]Downloading pytorch_model.bin:  67%|██████▋   | 849M/1.26G [00:30<00:13, 29.7MB/s]Downloading pytorch_model.bin:  68%|██████▊   | 860M/1.26G [00:31<00:14, 27.6MB/s]Downloading pytorch_model.bin:  69%|██████▉   | 870M/1.26G [00:31<00:14, 27.3MB/s]Downloading pytorch_model.bin:  70%|██████▉   | 881M/1.26G [00:32<00:15, 24.9MB/s]Downloading pytorch_model.bin:  71%|███████   | 891M/1.26G [00:32<00:14, 26.1MB/s]Downloading pytorch_model.bin:  71%|███████▏  | 902M/1.26G [00:33<00:14, 24.4MB/s]Downloading pytorch_model.bin:  72%|███████▏  | 912M/1.26G [00:33<00:15, 22.4MB/s]Downloading pytorch_model.bin:  73%|███████▎  | 923M/1.26G [00:34<00:13, 24.9MB/s]Downloading pytorch_model.bin:  74%|███████▍  | 933M/1.26G [00:34<00:11, 27.4MB/s]Downloading pytorch_model.bin:  75%|███████▍  | 944M/1.26G [00:34<00:10, 29.6MB/s]Downloading pytorch_model.bin:  76%|███████▌  | 954M/1.26G [00:35<00:10, 28.3MB/s]Downloading pytorch_model.bin:  76%|███████▋  | 965M/1.26G [00:36<00:15, 18.9MB/s]Downloading pytorch_model.bin:  77%|███████▋  | 975M/1.26G [00:36<00:13, 20.5MB/s]Downloading pytorch_model.bin:  78%|███████▊  | 986M/1.26G [00:37<00:15, 17.4MB/s]Downloading pytorch_model.bin:  79%|███████▉  | 996M/1.26G [00:37<00:13, 19.7MB/s]Downloading pytorch_model.bin:  80%|███████▉  | 1.01G/1.26G [00:37<00:11, 21.9MB/s]Downloading pytorch_model.bin:  81%|████████  | 1.02G/1.26G [00:38<00:11, 20.5MB/s]Downloading pytorch_model.bin:  81%|████████▏ | 1.03G/1.26G [00:38<00:10, 22.8MB/s]Downloading pytorch_model.bin:  82%|████████▏ | 1.04G/1.26G [00:39<00:09, 24.8MB/s]Downloading pytorch_model.bin:  83%|████████▎ | 1.05G/1.26G [00:39<00:09, 22.6MB/s]Downloading pytorch_model.bin:  84%|████████▍ | 1.06G/1.26G [00:40<00:08, 25.1MB/s]Downloading pytorch_model.bin:  85%|████████▍ | 1.07G/1.26G [00:40<00:07, 27.3MB/s]Downloading pytorch_model.bin:  86%|████████▌ | 1.08G/1.26G [00:40<00:06, 29.4MB/s]Downloading pytorch_model.bin:  86%|████████▋ | 1.09G/1.26G [00:40<00:05, 31.6MB/s]Downloading pytorch_model.bin:  87%|████████▋ | 1.10G/1.26G [00:41<00:04, 33.5MB/s]Downloading pytorch_model.bin:  88%|████████▊ | 1.11G/1.26G [00:41<00:04, 35.2MB/s]Downloading pytorch_model.bin:  89%|████████▉ | 1.12G/1.26G [00:41<00:03, 36.8MB/s]Downloading pytorch_model.bin:  90%|████████▉ | 1.13G/1.26G [00:42<00:04, 28.4MB/s]Downloading pytorch_model.bin:  91%|█████████ | 1.14G/1.26G [00:42<00:04, 28.5MB/s]Downloading pytorch_model.bin:  91%|█████████▏| 1.15G/1.26G [00:43<00:04, 26.1MB/s]Downloading pytorch_model.bin:  92%|█████████▏| 1.16G/1.26G [00:43<00:03, 24.9MB/s]Downloading pytorch_model.bin:  93%|█████████▎| 1.17G/1.26G [00:44<00:03, 24.2MB/s]Downloading pytorch_model.bin:  94%|█████████▍| 1.18G/1.26G [00:44<00:03, 23.6MB/s]Downloading pytorch_model.bin:  95%|█████████▍| 1.20G/1.26G [00:44<00:02, 25.4MB/s]Downloading pytorch_model.bin:  96%|█████████▌| 1.21G/1.26G [00:45<00:02, 26.9MB/s]Downloading pytorch_model.bin:  96%|█████████▋| 1.22G/1.26G [00:45<00:01, 28.2MB/s]Downloading pytorch_model.bin:  97%|█████████▋| 1.23G/1.26G [00:45<00:01, 29.6MB/s]Downloading pytorch_model.bin:  98%|█████████▊| 1.24G/1.26G [00:46<00:00, 29.1MB/s]Downloading pytorch_model.bin:  99%|█████████▉| 1.25G/1.26G [00:46<00:00, 26.2MB/s]Downloading pytorch_model.bin: 100%|█████████▉| 1.26G/1.26G [00:47<00:00, 28.2MB/s]Downloading pytorch_model.bin: 100%|██████████| 1.26G/1.26G [00:47<00:00, 29.0MB/s]Downloading pytorch_model.bin: 100%|██████████| 1.26G/1.26G [00:47<00:00, 26.8MB/s]
Map:   0%|          | 0/3968 [00:00<?, ? examples/s]Map:   0%|          | 1/3968 [00:00<21:50,  3.03 examples/s]Map:   0%|          | 6/3968 [00:00<04:11, 15.77 examples/s]Map:   0%|          | 11/3968 [00:00<02:48, 23.49 examples/s]Map:   0%|          | 16/3968 [00:00<02:15, 29.13 examples/s]Map:   1%|          | 20/3968 [00:00<02:07, 30.99 examples/s]Map:   1%|          | 26/3968 [00:00<01:54, 34.50 examples/s]Map:   1%|          | 32/3968 [00:01<01:44, 37.49 examples/s]Map:   1%|          | 38/3968 [00:01<01:41, 38.89 examples/s]Map:   1%|          | 44/3968 [00:01<01:35, 40.89 examples/s]Map:   1%|▏         | 50/3968 [00:01<01:33, 42.08 examples/s]Map:   1%|▏         | 55/3968 [00:01<01:34, 41.62 examples/s]Map:   2%|▏         | 61/3968 [00:01<01:31, 42.49 examples/s]Map:   2%|▏         | 67/3968 [00:01<01:30, 43.30 examples/s]Map:   2%|▏         | 72/3968 [00:02<01:30, 42.89 examples/s]Map:   2%|▏         | 78/3968 [00:02<01:29, 43.62 examples/s]Map:   2%|▏         | 84/3968 [00:02<01:25, 45.66 examples/s]Map:   2%|▏         | 90/3968 [00:02<01:23, 46.50 examples/s]Map:   2%|▏         | 96/3968 [00:02<01:23, 46.24 examples/s]Map:   3%|▎         | 101/3968 [00:02<01:25, 45.45 examples/s]Map:   3%|▎         | 107/3968 [00:02<01:21, 47.29 examples/s]Map:   3%|▎         | 113/3968 [00:02<01:22, 46.82 examples/s]Map:   3%|▎         | 119/3968 [00:03<01:21, 47.23 examples/s]Map:   3%|▎         | 124/3968 [00:03<01:25, 45.14 examples/s]Map:   3%|▎         | 130/3968 [00:03<01:23, 45.88 examples/s]Map:   3%|▎         | 136/3968 [00:03<01:21, 46.79 examples/s]Map:   4%|▎         | 142/3968 [00:03<01:22, 46.58 examples/s]Map:   4%|▎         | 148/3968 [00:03<01:22, 46.36 examples/s]Map:   4%|▍         | 153/3968 [00:03<01:23, 45.96 examples/s]Map:   4%|▍         | 159/3968 [00:03<01:22, 46.27 examples/s]Map:   4%|▍         | 165/3968 [00:04<01:22, 45.89 examples/s]Map:   4%|▍         | 171/3968 [00:04<01:23, 45.72 examples/s]Map:   4%|▍         | 177/3968 [00:04<01:22, 45.96 examples/s]Map:   5%|▍         | 183/3968 [00:04<01:24, 44.92 examples/s]Map:   5%|▍         | 189/3968 [00:04<01:22, 45.88 examples/s]Map:   5%|▍         | 195/3968 [00:04<01:23, 45.32 examples/s]Map:   5%|▌         | 201/3968 [00:04<01:20, 46.96 examples/s]Map:   5%|▌         | 207/3968 [00:04<01:19, 47.11 examples/s]Map:   5%|▌         | 213/3968 [00:05<01:18, 48.00 examples/s]Map:   6%|▌         | 219/3968 [00:05<01:20, 46.50 examples/s]Map:   6%|▌         | 225/3968 [00:05<01:18, 47.45 examples/s]Map:   6%|▌         | 231/3968 [00:05<01:20, 46.68 examples/s]Map:   6%|▌         | 237/3968 [00:05<01:17, 48.06 examples/s]Map:   6%|▌         | 243/3968 [00:05<01:20, 46.41 examples/s]Map:   6%|▋         | 249/3968 [00:05<01:19, 47.02 examples/s]Map:   6%|▋         | 255/3968 [00:05<01:18, 47.21 examples/s]Map:   7%|▋         | 260/3968 [00:06<01:20, 46.32 examples/s]Map:   7%|▋         | 266/3968 [00:06<01:21, 45.38 examples/s]Map:   7%|▋         | 271/3968 [00:06<01:22, 44.65 examples/s]Map:   7%|▋         | 277/3968 [00:06<01:22, 44.98 examples/s]Map:   7%|▋         | 282/3968 [00:06<01:21, 45.37 examples/s]Map:   7%|▋         | 288/3968 [00:06<01:18, 46.86 examples/s]Map:   7%|▋         | 294/3968 [00:06<01:21, 45.02 examples/s]Map:   8%|▊         | 300/3968 [00:06<01:21, 44.83 examples/s]Map:   8%|▊         | 306/3968 [00:07<01:22, 44.42 examples/s]Map:   8%|▊         | 311/3968 [00:07<01:23, 43.80 examples/s]Map:   8%|▊         | 317/3968 [00:07<01:20, 45.58 examples/s]Map:   8%|▊         | 323/3968 [00:07<01:19, 45.88 examples/s]Map:   8%|▊         | 328/3968 [00:07<01:19, 45.79 examples/s]Map:   8%|▊         | 334/3968 [00:07<01:20, 45.22 examples/s]Map:   9%|▊         | 340/3968 [00:07<01:17, 46.53 examples/s]Map:   9%|▊         | 346/3968 [00:07<01:17, 46.59 examples/s]Map:   9%|▉         | 351/3968 [00:08<01:18, 45.85 examples/s]Map:   9%|▉         | 357/3968 [00:08<01:17, 46.84 examples/s]Map:   9%|▉         | 363/3968 [00:08<01:17, 46.50 examples/s]Map:   9%|▉         | 369/3968 [00:08<01:17, 46.55 examples/s]Map:   9%|▉         | 375/3968 [00:08<01:16, 47.04 examples/s]Map:  10%|▉         | 381/3968 [00:08<01:15, 47.24 examples/s]Map:  10%|▉         | 387/3968 [00:08<01:14, 48.02 examples/s]Map:  10%|▉         | 393/3968 [00:08<01:16, 46.74 examples/s]Map:  10%|█         | 399/3968 [00:09<01:15, 47.47 examples/s]Map:  10%|█         | 405/3968 [00:09<01:16, 46.65 examples/s]Map:  10%|█         | 411/3968 [00:09<01:18, 45.27 examples/s]Map:  11%|█         | 417/3968 [00:09<01:17, 45.56 examples/s]Map:  11%|█         | 423/3968 [00:09<01:15, 46.72 examples/s]Map:  11%|█         | 428/3968 [00:09<01:17, 45.86 examples/s]Map:  11%|█         | 434/3968 [00:09<01:16, 46.04 examples/s]Map:  11%|█         | 440/3968 [00:09<01:16, 46.28 examples/s]Map:  11%|█         | 445/3968 [00:10<01:20, 43.75 examples/s]Map:  11%|█▏        | 451/3968 [00:10<01:17, 45.59 examples/s]Map:  12%|█▏        | 457/3968 [00:10<01:17, 45.10 examples/s]Map:  12%|█▏        | 463/3968 [00:10<01:15, 46.32 examples/s]Map:  12%|█▏        | 468/3968 [00:10<01:15, 46.10 examples/s]Map:  12%|█▏        | 474/3968 [00:10<01:16, 45.55 examples/s]Map:  12%|█▏        | 480/3968 [00:10<01:14, 46.69 examples/s]Map:  12%|█▏        | 486/3968 [00:10<01:13, 47.45 examples/s]Map:  12%|█▏        | 492/3968 [00:11<01:13, 47.54 examples/s]Map:  13%|█▎        | 498/3968 [00:11<01:13, 47.03 examples/s]Map:  13%|█▎        | 504/3968 [00:11<01:12, 47.66 examples/s]Map:  13%|█▎        | 510/3968 [00:11<01:14, 46.21 examples/s]Map:  13%|█▎        | 516/3968 [00:11<01:12, 47.42 examples/s]Map:  13%|█▎        | 522/3968 [00:11<01:12, 47.48 examples/s]Map:  13%|█▎        | 528/3968 [00:11<01:13, 46.71 examples/s]Map:  13%|█▎        | 533/3968 [00:11<01:14, 45.92 examples/s]Map:  14%|█▎        | 538/3968 [00:12<01:16, 44.71 examples/s]Map:  14%|█▎        | 543/3968 [00:12<01:17, 44.04 examples/s]Map:  14%|█▍        | 548/3968 [00:12<01:18, 43.60 examples/s]Map:  14%|█▍        | 554/3968 [00:12<01:15, 45.09 examples/s]Map:  14%|█▍        | 560/3968 [00:12<01:14, 45.76 examples/s]Map:  14%|█▍        | 565/3968 [00:12<01:15, 44.83 examples/s]Map:  14%|█▍        | 571/3968 [00:12<01:12, 46.94 examples/s]Map:  15%|█▍        | 577/3968 [00:12<01:10, 47.78 examples/s]Map:  15%|█▍        | 583/3968 [00:13<01:09, 48.46 examples/s]Map:  15%|█▍        | 589/3968 [00:13<01:10, 48.01 examples/s]Map:  15%|█▍        | 594/3968 [00:13<01:11, 46.86 examples/s]Map:  15%|█▌        | 600/3968 [00:13<01:10, 47.79 examples/s]Map:  15%|█▌        | 606/3968 [00:13<01:08, 48.79 examples/s]Map:  15%|█▌        | 612/3968 [00:13<01:09, 48.49 examples/s]Map:  16%|█▌        | 618/3968 [00:13<01:10, 47.28 examples/s]Map:  16%|█▌        | 624/3968 [00:13<01:10, 47.64 examples/s]Map:  16%|█▌        | 630/3968 [00:14<01:11, 46.98 examples/s]Map:  16%|█▌        | 636/3968 [00:14<01:12, 46.15 examples/s]Map:  16%|█▌        | 642/3968 [00:14<01:11, 46.36 examples/s]Map:  16%|█▋        | 647/3968 [00:14<01:14, 44.78 examples/s]Map:  16%|█▋        | 653/3968 [00:14<01:11, 46.53 examples/s]Map:  17%|█▋        | 659/3968 [00:14<01:10, 47.21 examples/s]Map:  17%|█▋        | 664/3968 [00:14<01:10, 46.92 examples/s]Map:  17%|█▋        | 670/3968 [00:14<01:09, 47.57 examples/s]Map:  17%|█▋        | 676/3968 [00:15<01:08, 48.07 examples/s]Map:  17%|█▋        | 683/3968 [00:15<01:30, 36.41 examples/s]Map:  17%|█▋        | 689/3968 [00:15<01:24, 38.59 examples/s]Map:  18%|█▊        | 695/3968 [00:15<01:20, 40.78 examples/s]Map:  18%|█▊        | 701/3968 [00:15<01:17, 42.03 examples/s]Map:  18%|█▊        | 707/3968 [00:15<01:15, 43.22 examples/s]Map:  18%|█▊        | 713/3968 [00:15<01:11, 45.41 examples/s]Map:  18%|█▊        | 719/3968 [00:16<01:10, 46.33 examples/s]Map:  18%|█▊        | 725/3968 [00:16<01:08, 47.34 examples/s]Map:  18%|█▊        | 731/3968 [00:16<01:07, 47.82 examples/s]Map:  19%|█▊        | 737/3968 [00:16<01:07, 48.11 examples/s]Map:  19%|█▊        | 742/3968 [00:16<01:08, 47.23 examples/s]Map:  19%|█▉        | 748/3968 [00:16<01:06, 48.38 examples/s]Map:  19%|█▉        | 754/3968 [00:16<01:07, 47.75 examples/s]Map:  19%|█▉        | 760/3968 [00:16<01:06, 48.39 examples/s]Map:  19%|█▉        | 766/3968 [00:17<01:07, 47.70 examples/s]Map:  19%|█▉        | 772/3968 [00:17<01:06, 48.34 examples/s]Map:  20%|█▉        | 778/3968 [00:17<01:07, 47.19 examples/s]Map:  20%|█▉        | 784/3968 [00:17<01:06, 47.68 examples/s]Map:  20%|█▉        | 790/3968 [00:17<01:05, 48.77 examples/s]Map:  20%|██        | 796/3968 [00:17<01:08, 46.54 examples/s]Map:  20%|██        | 802/3968 [00:17<01:07, 47.14 examples/s]Map:  20%|██        | 808/3968 [00:17<01:05, 48.38 examples/s]Map:  21%|██        | 814/3968 [00:18<01:08, 46.18 examples/s]Map:  21%|██        | 820/3968 [00:18<01:05, 47.72 examples/s]Map:  21%|██        | 826/3968 [00:18<01:04, 48.37 examples/s]Map:  21%|██        | 832/3968 [00:18<01:05, 47.56 examples/s]Map:  21%|██        | 838/3968 [00:18<01:04, 48.45 examples/s]Map:  21%|██▏       | 844/3968 [00:18<01:03, 48.86 examples/s]Map:  21%|██▏       | 850/3968 [00:18<01:04, 48.47 examples/s]Map:  22%|██▏       | 856/3968 [00:18<01:03, 48.96 examples/s]Map:  22%|██▏       | 862/3968 [00:19<01:03, 48.71 examples/s]Map:  22%|██▏       | 868/3968 [00:19<01:03, 49.11 examples/s]Map:  22%|██▏       | 874/3968 [00:19<01:03, 48.57 examples/s]Map:  22%|██▏       | 880/3968 [00:19<01:04, 47.90 examples/s]Map:  22%|██▏       | 886/3968 [00:19<01:06, 46.10 examples/s]Map:  22%|██▏       | 892/3968 [00:19<01:06, 46.11 examples/s]Map:  23%|██▎       | 898/3968 [00:19<01:06, 46.30 examples/s]Map:  23%|██▎       | 904/3968 [00:19<01:05, 46.84 examples/s]Map:  23%|██▎       | 910/3968 [00:20<01:05, 46.97 examples/s]Map:  23%|██▎       | 916/3968 [00:20<01:05, 46.74 examples/s]Map:  23%|██▎       | 922/3968 [00:20<01:04, 47.34 examples/s]Map:  23%|██▎       | 928/3968 [00:20<01:03, 47.76 examples/s]Map:  24%|██▎       | 934/3968 [00:20<01:05, 46.62 examples/s]Map:  24%|██▎       | 940/3968 [00:20<01:04, 46.74 examples/s]Map:  24%|██▍       | 946/3968 [00:20<01:03, 47.62 examples/s]Map:  24%|██▍       | 951/3968 [00:20<01:04, 46.71 examples/s]Map:  24%|██▍       | 957/3968 [00:21<01:04, 46.91 examples/s]Map:  24%|██▍       | 963/3968 [00:21<01:04, 46.90 examples/s]Map:  24%|██▍       | 969/3968 [00:21<01:02, 48.30 examples/s]Map:  25%|██▍       | 975/3968 [00:21<01:01, 48.57 examples/s]Map:  25%|██▍       | 980/3968 [00:21<01:04, 46.63 examples/s]Map:  25%|██▍       | 986/3968 [00:21<01:03, 47.21 examples/s]Map:  25%|██▍       | 991/3968 [00:21<01:04, 46.31 examples/s]Map:  25%|██▌       | 996/3968 [00:21<01:05, 45.72 examples/s]Map:  25%|██▌       | 1003/3968 [00:22<02:26, 20.23 examples/s]Map:  25%|██▌       | 1009/3968 [00:22<02:00, 24.59 examples/s]Map:  26%|██▌       | 1015/3968 [00:22<01:42, 28.76 examples/s]Map:  26%|██▌       | 1021/3968 [00:22<01:30, 32.72 examples/s]Map:  26%|██▌       | 1027/3968 [00:23<01:20, 36.49 examples/s]Map:  26%|██▌       | 1033/3968 [00:23<01:13, 39.80 examples/s]Map:  26%|██▌       | 1039/3968 [00:23<01:11, 40.82 examples/s]Map:  26%|██▋       | 1045/3968 [00:23<01:09, 42.27 examples/s]Map:  26%|██▋       | 1051/3968 [00:23<01:06, 44.13 examples/s]Map:  27%|██▋       | 1057/3968 [00:23<01:04, 45.14 examples/s]Map:  27%|██▋       | 1063/3968 [00:23<01:02, 46.17 examples/s]Map:  27%|██▋       | 1069/3968 [00:23<01:01, 47.19 examples/s]Map:  27%|██▋       | 1075/3968 [00:24<00:59, 48.50 examples/s]Map:  27%|██▋       | 1081/3968 [00:24<00:59, 48.43 examples/s]Map:  27%|██▋       | 1087/3968 [00:24<01:00, 47.88 examples/s]Map:  28%|██▊       | 1093/3968 [00:24<00:58, 49.33 examples/s]Map:  28%|██▊       | 1099/3968 [00:24<00:58, 49.32 examples/s]Map:  28%|██▊       | 1105/3968 [00:24<00:57, 49.90 examples/s]Map:  28%|██▊       | 1111/3968 [00:24<00:57, 49.42 examples/s]Map:  28%|██▊       | 1117/3968 [00:24<00:58, 48.86 examples/s]Map:  28%|██▊       | 1123/3968 [00:25<00:59, 47.69 examples/s]Map:  28%|██▊       | 1129/3968 [00:25<00:59, 47.32 examples/s]Map:  29%|██▊       | 1135/3968 [00:25<00:58, 48.62 examples/s]Map:  29%|██▊       | 1140/3968 [00:25<01:00, 46.89 examples/s]Map:  29%|██▉       | 1146/3968 [00:25<00:59, 47.80 examples/s]Map:  29%|██▉       | 1152/3968 [00:25<00:59, 47.40 examples/s]Map:  29%|██▉       | 1158/3968 [00:25<00:58, 48.07 examples/s]Map:  29%|██▉       | 1164/3968 [00:25<00:57, 48.59 examples/s]Map:  29%|██▉       | 1170/3968 [00:26<00:57, 48.83 examples/s]Map:  30%|██▉       | 1176/3968 [00:26<00:57, 48.74 examples/s]Map:  30%|██▉       | 1182/3968 [00:26<00:57, 48.59 examples/s]Map:  30%|██▉       | 1187/3968 [00:26<00:59, 46.63 examples/s]Map:  30%|███       | 1193/3968 [00:26<00:57, 47.93 examples/s]Map:  30%|███       | 1199/3968 [00:26<00:57, 48.19 examples/s]Map:  30%|███       | 1205/3968 [00:26<00:57, 48.28 examples/s]Map:  31%|███       | 1211/3968 [00:26<00:57, 47.95 examples/s]Map:  31%|███       | 1217/3968 [00:27<00:57, 48.19 examples/s]Map:  31%|███       | 1223/3968 [00:27<00:57, 48.04 examples/s]Map:  31%|███       | 1229/3968 [00:27<00:57, 47.75 examples/s]Map:  31%|███       | 1235/3968 [00:27<00:56, 48.66 examples/s]Map:  31%|███▏      | 1241/3968 [00:27<00:56, 48.24 examples/s]Map:  31%|███▏      | 1247/3968 [00:27<00:56, 48.28 examples/s]Map:  32%|███▏      | 1253/3968 [00:27<00:56, 48.22 examples/s]Map:  32%|███▏      | 1259/3968 [00:27<00:56, 48.33 examples/s]Map:  32%|███▏      | 1265/3968 [00:28<00:55, 48.34 examples/s]Map:  32%|███▏      | 1271/3968 [00:28<00:54, 49.13 examples/s]Map:  32%|███▏      | 1277/3968 [00:28<00:57, 46.62 examples/s]Map:  32%|███▏      | 1283/3968 [00:28<00:58, 45.82 examples/s]Map:  32%|███▏      | 1289/3968 [00:28<00:58, 46.07 examples/s]Map:  33%|███▎      | 1295/3968 [00:28<00:57, 46.32 examples/s]Map:  33%|███▎      | 1301/3968 [00:28<00:57, 46.59 examples/s]Map:  33%|███▎      | 1307/3968 [00:28<00:56, 47.41 examples/s]Map:  33%|███▎      | 1313/3968 [00:29<00:56, 46.59 examples/s]Map:  33%|███▎      | 1319/3968 [00:29<00:55, 47.37 examples/s]Map:  33%|███▎      | 1324/3968 [00:29<00:56, 46.97 examples/s]Map:  34%|███▎      | 1330/3968 [00:29<00:55, 47.24 examples/s]Map:  34%|███▎      | 1336/3968 [00:29<00:54, 48.34 examples/s]Map:  34%|███▍      | 1342/3968 [00:29<00:53, 48.89 examples/s]Map:  34%|███▍      | 1348/3968 [00:29<00:53, 48.93 examples/s]Map:  34%|███▍      | 1354/3968 [00:29<00:53, 48.50 examples/s]Map:  34%|███▍      | 1360/3968 [00:30<00:53, 48.80 examples/s]Map:  34%|███▍      | 1366/3968 [00:30<00:53, 48.58 examples/s]Map:  35%|███▍      | 1372/3968 [00:30<00:54, 47.43 examples/s]Map:  35%|███▍      | 1378/3968 [00:30<00:54, 47.71 examples/s]Map:  35%|███▍      | 1384/3968 [00:30<00:54, 47.22 examples/s]Map:  35%|███▌      | 1390/3968 [00:30<00:54, 47.36 examples/s]Map:  35%|███▌      | 1396/3968 [00:30<00:52, 48.67 examples/s]Map:  35%|███▌      | 1402/3968 [00:30<00:52, 48.80 examples/s]Map:  35%|███▌      | 1408/3968 [00:31<00:51, 49.31 examples/s]Map:  36%|███▌      | 1413/3968 [00:31<00:54, 47.00 examples/s]Map:  36%|███▌      | 1419/3968 [00:31<00:52, 48.12 examples/s]Map:  36%|███▌      | 1425/3968 [00:31<00:53, 47.62 examples/s]Map:  36%|███▌      | 1431/3968 [00:31<00:53, 47.78 examples/s]Map:  36%|███▌      | 1437/3968 [00:31<00:54, 46.74 examples/s]Map:  36%|███▋      | 1443/3968 [00:31<00:53, 47.41 examples/s]Map:  37%|███▋      | 1449/3968 [00:31<00:52, 48.20 examples/s]Map:  37%|███▋      | 1455/3968 [00:32<00:51, 48.36 examples/s]Map:  37%|███▋      | 1461/3968 [00:32<00:51, 48.55 examples/s]Map:  37%|███▋      | 1467/3968 [00:32<00:52, 47.72 examples/s]Map:  37%|███▋      | 1473/3968 [00:32<00:51, 48.45 examples/s]Map:  37%|███▋      | 1479/3968 [00:32<00:51, 48.40 examples/s]Map:  37%|███▋      | 1485/3968 [00:32<00:53, 46.83 examples/s]Map:  38%|███▊      | 1491/3968 [00:32<00:51, 47.86 examples/s]Map:  38%|███▊      | 1497/3968 [00:32<00:52, 46.87 examples/s]Map:  38%|███▊      | 1503/3968 [00:33<00:52, 46.83 examples/s]Map:  38%|███▊      | 1509/3968 [00:33<00:51, 47.40 examples/s]Map:  38%|███▊      | 1515/3968 [00:33<00:51, 47.84 examples/s]Map:  38%|███▊      | 1521/3968 [00:33<00:51, 47.82 examples/s]Map:  38%|███▊      | 1527/3968 [00:33<00:50, 48.21 examples/s]Map:  39%|███▊      | 1533/3968 [00:33<00:51, 47.58 examples/s]Map:  39%|███▉      | 1539/3968 [00:33<00:51, 47.35 examples/s]Map:  39%|███▉      | 1545/3968 [00:33<00:52, 45.80 examples/s]Map:  39%|███▉      | 1551/3968 [00:34<00:51, 47.14 examples/s]Map:  39%|███▉      | 1557/3968 [00:34<00:50, 47.52 examples/s]Map:  39%|███▉      | 1563/3968 [00:34<00:50, 47.80 examples/s]Map:  40%|███▉      | 1569/3968 [00:34<00:51, 46.92 examples/s]Map:  40%|███▉      | 1575/3968 [00:34<00:50, 47.24 examples/s]Map:  40%|███▉      | 1580/3968 [00:34<00:52, 45.35 examples/s]Map:  40%|███▉      | 1586/3968 [00:34<00:53, 44.31 examples/s]Map:  40%|████      | 1592/3968 [00:34<00:53, 44.65 examples/s]Map:  40%|████      | 1597/3968 [00:35<00:53, 44.23 examples/s]Map:  40%|████      | 1603/3968 [00:35<00:51, 46.22 examples/s]Map:  41%|████      | 1609/3968 [00:35<00:49, 47.43 examples/s]Map:  41%|████      | 1615/3968 [00:35<00:49, 47.91 examples/s]Map:  41%|████      | 1621/3968 [00:35<00:48, 48.02 examples/s]Map:  41%|████      | 1627/3968 [00:35<00:49, 47.77 examples/s]Map:  41%|████      | 1633/3968 [00:35<00:49, 47.65 examples/s]Map:  41%|████▏     | 1639/3968 [00:35<00:49, 47.31 examples/s]Map:  41%|████▏     | 1645/3968 [00:36<00:48, 48.15 examples/s]Map:  42%|████▏     | 1651/3968 [00:36<00:48, 48.01 examples/s]Map:  42%|████▏     | 1657/3968 [00:36<00:47, 48.71 examples/s]Map:  42%|████▏     | 1663/3968 [00:36<00:48, 47.36 examples/s]Map:  42%|████▏     | 1669/3968 [00:36<00:47, 48.17 examples/s]Map:  42%|████▏     | 1675/3968 [00:36<00:47, 48.58 examples/s]Map:  42%|████▏     | 1681/3968 [00:36<00:47, 48.41 examples/s]Map:  42%|████▏     | 1686/3968 [00:36<00:48, 46.73 examples/s]Map:  43%|████▎     | 1692/3968 [00:37<00:48, 47.03 examples/s]Map:  43%|████▎     | 1698/3968 [00:37<00:48, 47.06 examples/s]Map:  43%|████▎     | 1704/3968 [00:37<00:49, 46.18 examples/s]Map:  43%|████▎     | 1709/3968 [00:37<00:49, 45.58 examples/s]Map:  43%|████▎     | 1715/3968 [00:37<00:48, 46.09 examples/s]Map:  43%|████▎     | 1721/3968 [00:37<00:48, 46.59 examples/s]Map:  44%|████▎     | 1727/3968 [00:37<00:48, 46.21 examples/s]Map:  44%|████▎     | 1733/3968 [00:37<00:47, 47.12 examples/s]Map:  44%|████▍     | 1739/3968 [00:38<00:47, 46.86 examples/s]Map:  44%|████▍     | 1745/3968 [00:38<00:46, 47.79 examples/s]Map:  44%|████▍     | 1751/3968 [00:38<00:47, 47.05 examples/s]Map:  44%|████▍     | 1757/3968 [00:38<00:46, 47.45 examples/s]Map:  44%|████▍     | 1763/3968 [00:38<00:46, 47.80 examples/s]Map:  45%|████▍     | 1769/3968 [00:38<00:46, 47.63 examples/s]Map:  45%|████▍     | 1775/3968 [00:38<00:46, 47.45 examples/s]Map:  45%|████▍     | 1781/3968 [00:38<00:45, 48.22 examples/s]Map:  45%|████▌     | 1787/3968 [00:39<00:45, 48.05 examples/s]Map:  45%|████▌     | 1793/3968 [00:39<00:44, 48.39 examples/s]Map:  45%|████▌     | 1798/3968 [00:39<00:45, 47.23 examples/s]Map:  45%|████▌     | 1804/3968 [00:39<00:45, 47.68 examples/s]Map:  46%|████▌     | 1810/3968 [00:39<00:45, 46.94 examples/s]Map:  46%|████▌     | 1816/3968 [00:39<00:45, 46.93 examples/s]Map:  46%|████▌     | 1822/3968 [00:39<00:47, 45.62 examples/s]Map:  46%|████▌     | 1828/3968 [00:39<00:45, 46.72 examples/s]Map:  46%|████▌     | 1834/3968 [00:40<00:44, 47.56 examples/s]Map:  46%|████▋     | 1839/3968 [00:40<00:46, 45.63 examples/s]Map:  46%|████▋     | 1845/3968 [00:40<00:47, 44.88 examples/s]Map:  47%|████▋     | 1851/3968 [00:40<00:47, 44.87 examples/s]Map:  47%|████▋     | 1857/3968 [00:40<00:45, 46.63 examples/s]Map:  47%|████▋     | 1863/3968 [00:40<00:44, 47.14 examples/s]Map:  47%|████▋     | 1869/3968 [00:40<00:44, 47.62 examples/s]Map:  47%|████▋     | 1875/3968 [00:40<00:44, 47.03 examples/s]Map:  47%|████▋     | 1881/3968 [00:41<00:43, 47.59 examples/s]Map:  48%|████▊     | 1887/3968 [00:41<00:43, 47.70 examples/s]Map:  48%|████▊     | 1893/3968 [00:41<00:42, 48.70 examples/s]Map:  48%|████▊     | 1898/3968 [00:41<00:44, 46.90 examples/s]Map:  48%|████▊     | 1904/3968 [00:41<00:44, 46.53 examples/s]Map:  48%|████▊     | 1911/3968 [00:41<00:45, 45.23 examples/s]Map:  48%|████▊     | 1917/3968 [00:41<00:44, 45.77 examples/s]Map:  48%|████▊     | 1923/3968 [00:41<00:43, 46.53 examples/s]Map:  49%|████▊     | 1929/3968 [00:42<00:42, 47.62 examples/s]Map:  49%|████▉     | 1935/3968 [00:42<00:42, 47.44 examples/s]Map:  49%|████▉     | 1941/3968 [00:42<00:42, 47.96 examples/s]Map:  49%|████▉     | 1947/3968 [00:42<00:42, 47.82 examples/s]Map:  49%|████▉     | 1952/3968 [00:42<00:43, 46.47 examples/s]Map:  49%|████▉     | 1957/3968 [00:42<00:45, 44.37 examples/s]Map:  49%|████▉     | 1963/3968 [00:42<00:45, 44.42 examples/s]Map:  50%|████▉     | 1969/3968 [00:42<00:43, 45.62 examples/s]Map:  50%|████▉     | 1975/3968 [00:43<00:42, 46.43 examples/s]Map:  50%|████▉     | 1981/3968 [00:43<00:43, 46.19 examples/s]Map:  50%|█████     | 1987/3968 [00:43<00:43, 45.96 examples/s]Map:  50%|█████     | 1993/3968 [00:43<00:42, 46.48 examples/s]Map:  50%|█████     | 1999/3968 [00:43<00:41, 47.40 examples/s]Map:  51%|█████     | 2006/3968 [00:44<01:29, 21.98 examples/s]Map:  51%|█████     | 2012/3968 [00:44<01:14, 26.13 examples/s]Map:  51%|█████     | 2018/3968 [00:44<01:04, 30.14 examples/s]Map:  51%|█████     | 2024/3968 [00:44<00:57, 33.72 examples/s]Map:  51%|█████     | 2030/3968 [00:44<00:52, 37.16 examples/s]Map:  51%|█████▏    | 2036/3968 [00:44<00:48, 39.99 examples/s]Map:  51%|█████▏    | 2042/3968 [00:44<00:45, 42.62 examples/s]Map:  52%|█████▏    | 2048/3968 [00:45<00:43, 43.91 examples/s]Map:  52%|█████▏    | 2054/3968 [00:45<00:42, 45.50 examples/s]Map:  52%|█████▏    | 2060/3968 [00:45<00:40, 47.08 examples/s]Map:  52%|█████▏    | 2066/3968 [00:45<00:39, 47.89 examples/s]Map:  52%|█████▏    | 2072/3968 [00:45<00:39, 48.31 examples/s]Map:  52%|█████▏    | 2078/3968 [00:45<00:38, 48.92 examples/s]Map:  53%|█████▎    | 2084/3968 [00:45<00:38, 48.44 examples/s]Map:  53%|█████▎    | 2090/3968 [00:45<00:38, 48.29 examples/s]Map:  53%|█████▎    | 2096/3968 [00:46<00:38, 48.60 examples/s]Map:  53%|█████▎    | 2102/3968 [00:46<00:38, 48.38 examples/s]Map:  53%|█████▎    | 2108/3968 [00:46<00:38, 48.54 examples/s]Map:  53%|█████▎    | 2114/3968 [00:46<00:38, 48.08 examples/s]Map:  53%|█████▎    | 2120/3968 [00:46<00:38, 47.46 examples/s]Map:  54%|█████▎    | 2125/3968 [00:46<00:39, 46.19 examples/s]Map:  54%|█████▎    | 2131/3968 [00:46<00:40, 45.92 examples/s]Map:  54%|█████▍    | 2137/3968 [00:46<00:38, 47.07 examples/s]Map:  54%|█████▍    | 2143/3968 [00:47<00:38, 47.25 examples/s]Map:  54%|█████▍    | 2149/3968 [00:47<00:39, 46.55 examples/s]Map:  54%|█████▍    | 2155/3968 [00:47<00:38, 47.20 examples/s]Map:  54%|█████▍    | 2161/3968 [00:47<00:38, 47.39 examples/s]Map:  55%|█████▍    | 2167/3968 [00:47<00:37, 48.37 examples/s]Map:  55%|█████▍    | 2172/3968 [00:47<00:39, 45.50 examples/s]Map:  55%|█████▍    | 2177/3968 [00:47<00:40, 44.43 examples/s]Map:  55%|█████▌    | 2183/3968 [00:47<00:39, 44.66 examples/s]Map:  55%|█████▌    | 2189/3968 [00:48<00:38, 45.72 examples/s]Map:  55%|█████▌    | 2195/3968 [00:48<00:37, 46.74 examples/s]Map:  55%|█████▌    | 2201/3968 [00:48<00:37, 47.61 examples/s]Map:  56%|█████▌    | 2207/3968 [00:48<00:36, 47.99 examples/s]Map:  56%|█████▌    | 2213/3968 [00:48<00:36, 48.27 examples/s]Map:  56%|█████▌    | 2219/3968 [00:48<00:36, 47.62 examples/s]Map:  56%|█████▌    | 2225/3968 [00:48<00:35, 48.65 examples/s]Map:  56%|█████▌    | 2231/3968 [00:48<00:35, 48.74 examples/s]Map:  56%|█████▋    | 2236/3968 [00:49<00:37, 46.35 examples/s]Map:  57%|█████▋    | 2242/3968 [00:49<00:37, 46.52 examples/s]Map:  57%|█████▋    | 2248/3968 [00:49<00:36, 47.63 examples/s]Map:  57%|█████▋    | 2254/3968 [00:49<00:35, 48.47 examples/s]Map:  57%|█████▋    | 2260/3968 [00:49<00:35, 48.20 examples/s]Map:  57%|█████▋    | 2266/3968 [00:49<00:35, 47.79 examples/s]Map:  57%|█████▋    | 2272/3968 [00:49<00:35, 47.34 examples/s]Map:  57%|█████▋    | 2278/3968 [00:49<00:36, 46.49 examples/s]Map:  58%|█████▊    | 2284/3968 [00:50<00:35, 47.29 examples/s]Map:  58%|█████▊    | 2290/3968 [00:50<00:35, 46.85 examples/s]Map:  58%|█████▊    | 2296/3968 [00:50<00:35, 47.61 examples/s]Map:  58%|█████▊    | 2302/3968 [00:50<00:34, 48.37 examples/s]Map:  58%|█████▊    | 2308/3968 [00:50<00:34, 48.48 examples/s]Map:  58%|█████▊    | 2314/3968 [00:50<00:33, 48.73 examples/s]Map:  58%|█████▊    | 2320/3968 [00:50<00:34, 48.46 examples/s]Map:  59%|█████▊    | 2326/3968 [00:50<00:34, 47.06 examples/s]Map:  59%|█████▉    | 2332/3968 [00:51<00:34, 47.85 examples/s]Map:  59%|█████▉    | 2338/3968 [00:51<00:34, 47.84 examples/s]Map:  59%|█████▉    | 2344/3968 [00:51<00:35, 46.31 examples/s]Map:  59%|█████▉    | 2350/3968 [00:51<00:34, 46.77 examples/s]Map:  59%|█████▉    | 2356/3968 [00:51<00:34, 47.34 examples/s]Map:  60%|█████▉    | 2362/3968 [00:51<00:33, 48.02 examples/s]Map:  60%|█████▉    | 2368/3968 [00:51<00:33, 47.49 examples/s]Map:  60%|█████▉    | 2374/3968 [00:51<00:33, 47.29 examples/s]Map:  60%|█████▉    | 2380/3968 [00:52<00:33, 47.22 examples/s]Map:  60%|██████    | 2386/3968 [00:52<00:32, 48.45 examples/s]Map:  60%|██████    | 2392/3968 [00:52<00:33, 47.45 examples/s]Map:  60%|██████    | 2398/3968 [00:52<00:32, 48.57 examples/s]Map:  61%|██████    | 2404/3968 [00:52<00:33, 47.26 examples/s]Map:  61%|██████    | 2410/3968 [00:52<00:32, 48.51 examples/s]Map:  61%|██████    | 2416/3968 [00:52<00:31, 48.79 examples/s]Map:  61%|██████    | 2422/3968 [00:52<00:31, 48.84 examples/s]Map:  61%|██████    | 2428/3968 [00:53<00:31, 49.19 examples/s]Map:  61%|██████▏   | 2434/3968 [00:53<00:32, 47.28 examples/s]Map:  61%|██████▏   | 2440/3968 [00:53<00:31, 47.95 examples/s]Map:  62%|██████▏   | 2446/3968 [00:53<00:31, 48.17 examples/s]Map:  62%|██████▏   | 2452/3968 [00:53<00:31, 48.29 examples/s]Map:  62%|██████▏   | 2458/3968 [00:53<00:31, 47.48 examples/s]Map:  62%|██████▏   | 2464/3968 [00:53<00:31, 47.48 examples/s]Map:  62%|██████▏   | 2470/3968 [00:53<00:31, 47.03 examples/s]Map:  62%|██████▏   | 2476/3968 [00:54<00:32, 46.53 examples/s]Map:  63%|██████▎   | 2482/3968 [00:54<00:31, 46.97 examples/s]Map:  63%|██████▎   | 2488/3968 [00:54<00:31, 47.18 examples/s]Map:  63%|██████▎   | 2494/3968 [00:54<00:30, 48.12 examples/s]Map:  63%|██████▎   | 2500/3968 [00:54<00:30, 47.78 examples/s]Map:  63%|██████▎   | 2506/3968 [00:54<00:30, 48.60 examples/s]Map:  63%|██████▎   | 2512/3968 [00:54<00:29, 49.08 examples/s]Map:  63%|██████▎   | 2519/3968 [00:55<00:32, 44.69 examples/s]Map:  64%|██████▎   | 2525/3968 [00:55<00:30, 46.60 examples/s]Map:  64%|██████▍   | 2531/3968 [00:55<00:30, 46.87 examples/s]Map:  64%|██████▍   | 2537/3968 [00:55<00:30, 46.84 examples/s]Map:  64%|██████▍   | 2543/3968 [00:55<00:29, 47.89 examples/s]Map:  64%|██████▍   | 2549/3968 [00:55<00:29, 48.70 examples/s]Map:  64%|██████▍   | 2555/3968 [00:55<00:28, 49.19 examples/s]Map:  65%|██████▍   | 2561/3968 [00:55<00:28, 49.63 examples/s]Map:  65%|██████▍   | 2567/3968 [00:55<00:28, 49.83 examples/s]Map:  65%|██████▍   | 2573/3968 [00:56<00:27, 49.83 examples/s]Map:  65%|██████▍   | 2579/3968 [00:56<00:28, 49.30 examples/s]Map:  65%|██████▌   | 2585/3968 [00:56<00:28, 48.73 examples/s]Map:  65%|██████▌   | 2591/3968 [00:56<00:28, 48.78 examples/s]Map:  65%|██████▌   | 2597/3968 [00:56<00:28, 48.09 examples/s]Map:  66%|██████▌   | 2602/3968 [00:56<00:29, 46.41 examples/s]Map:  66%|██████▌   | 2608/3968 [00:56<00:28, 47.52 examples/s]Map:  66%|██████▌   | 2614/3968 [00:56<00:28, 47.68 examples/s]Map:  66%|██████▌   | 2620/3968 [00:57<00:28, 47.56 examples/s]Map:  66%|██████▌   | 2626/3968 [00:57<00:28, 47.21 examples/s]Map:  66%|██████▋   | 2632/3968 [00:57<00:28, 47.63 examples/s]Map:  66%|██████▋   | 2638/3968 [00:57<00:27, 48.41 examples/s]Map:  67%|██████▋   | 2644/3968 [00:57<00:26, 49.22 examples/s]Map:  67%|██████▋   | 2650/3968 [00:57<00:27, 48.29 examples/s]Map:  67%|██████▋   | 2656/3968 [00:57<00:26, 49.02 examples/s]Map:  67%|██████▋   | 2662/3968 [00:57<00:26, 48.96 examples/s]Map:  67%|██████▋   | 2668/3968 [00:58<00:26, 48.48 examples/s]Map:  67%|██████▋   | 2674/3968 [00:58<00:27, 47.35 examples/s]Map:  68%|██████▊   | 2680/3968 [00:58<00:26, 48.21 examples/s]Map:  68%|██████▊   | 2686/3968 [00:58<00:26, 47.91 examples/s]Map:  68%|██████▊   | 2691/3968 [00:58<00:27, 46.61 examples/s]Map:  68%|██████▊   | 2697/3968 [00:58<00:26, 47.36 examples/s]Map:  68%|██████▊   | 2703/3968 [00:58<00:27, 46.10 examples/s]Map:  68%|██████▊   | 2709/3968 [00:58<00:26, 47.29 examples/s]Map:  68%|██████▊   | 2715/3968 [00:59<00:25, 48.35 examples/s]Map:  69%|██████▊   | 2721/3968 [00:59<00:25, 48.27 examples/s]Map:  69%|██████▊   | 2727/3968 [00:59<00:25, 48.12 examples/s]Map:  69%|██████▉   | 2733/3968 [00:59<00:25, 47.65 examples/s]Map:  69%|██████▉   | 2739/3968 [00:59<00:25, 48.61 examples/s]Map:  69%|██████▉   | 2744/3968 [00:59<00:25, 47.55 examples/s]Map:  69%|██████▉   | 2750/3968 [00:59<00:25, 47.81 examples/s]Map:  69%|██████▉   | 2756/3968 [00:59<00:25, 48.34 examples/s]Map:  70%|██████▉   | 2762/3968 [01:00<00:24, 49.42 examples/s]Map:  70%|██████▉   | 2768/3968 [01:00<00:24, 49.13 examples/s]Map:  70%|██████▉   | 2774/3968 [01:00<00:24, 48.54 examples/s]Map:  70%|███████   | 2780/3968 [01:00<00:24, 48.21 examples/s]Map:  70%|███████   | 2786/3968 [01:00<00:24, 48.65 examples/s]Map:  70%|███████   | 2792/3968 [01:00<00:23, 49.10 examples/s]Map:  71%|███████   | 2798/3968 [01:00<00:24, 48.05 examples/s]Map:  71%|███████   | 2804/3968 [01:00<00:24, 47.18 examples/s]Map:  71%|███████   | 2810/3968 [01:01<00:24, 47.90 examples/s]Map:  71%|███████   | 2816/3968 [01:01<00:24, 47.53 examples/s]Map:  71%|███████   | 2822/3968 [01:01<00:23, 48.33 examples/s]Map:  71%|███████▏  | 2828/3968 [01:01<00:22, 49.59 examples/s]Map:  71%|███████▏  | 2834/3968 [01:01<00:23, 47.83 examples/s]Map:  72%|███████▏  | 2839/3968 [01:01<00:24, 47.04 examples/s]Map:  72%|███████▏  | 2845/3968 [01:01<00:23, 48.21 examples/s]Map:  72%|███████▏  | 2851/3968 [01:01<00:22, 48.72 examples/s]Map:  72%|███████▏  | 2856/3968 [01:02<00:23, 46.86 examples/s]Map:  72%|███████▏  | 2862/3968 [01:02<00:23, 47.37 examples/s]Map:  72%|███████▏  | 2868/3968 [01:02<00:23, 47.26 examples/s]Map:  72%|███████▏  | 2874/3968 [01:02<00:23, 47.40 examples/s]Map:  73%|███████▎  | 2880/3968 [01:02<00:22, 47.93 examples/s]Map:  73%|███████▎  | 2886/3968 [01:02<00:22, 47.90 examples/s]Map:  73%|███████▎  | 2892/3968 [01:02<00:22, 48.16 examples/s]Map:  73%|███████▎  | 2898/3968 [01:02<00:22, 48.50 examples/s]Map:  73%|███████▎  | 2904/3968 [01:03<00:21, 48.91 examples/s]Map:  73%|███████▎  | 2910/3968 [01:03<00:21, 48.68 examples/s]Map:  73%|███████▎  | 2916/3968 [01:03<00:21, 48.15 examples/s]Map:  74%|███████▎  | 2922/3968 [01:03<00:21, 48.75 examples/s]Map:  74%|███████▍  | 2928/3968 [01:03<00:21, 47.57 examples/s]Map:  74%|███████▍  | 2934/3968 [01:03<00:21, 48.29 examples/s]Map:  74%|███████▍  | 2939/3968 [01:03<00:21, 47.73 examples/s]Map:  74%|███████▍  | 2945/3968 [01:03<00:21, 47.84 examples/s]Map:  74%|███████▍  | 2951/3968 [01:03<00:21, 47.88 examples/s]Map:  75%|███████▍  | 2957/3968 [01:04<00:21, 47.92 examples/s]Map:  75%|███████▍  | 2963/3968 [01:04<00:20, 49.19 examples/s]Map:  75%|███████▍  | 2969/3968 [01:04<00:20, 48.41 examples/s]Map:  75%|███████▍  | 2975/3968 [01:04<00:20, 48.11 examples/s]Map:  75%|███████▌  | 2981/3968 [01:04<00:20, 47.64 examples/s]Map:  75%|███████▌  | 2987/3968 [01:04<00:20, 48.28 examples/s]Map:  75%|███████▌  | 2993/3968 [01:04<00:20, 48.66 examples/s]Map:  76%|███████▌  | 2999/3968 [01:04<00:19, 48.50 examples/s]Map:  76%|███████▌  | 3005/3968 [01:05<00:46, 20.87 examples/s]Map:  76%|███████▌  | 3011/3968 [01:05<00:37, 25.27 examples/s]Map:  76%|███████▌  | 3017/3968 [01:05<00:32, 29.61 examples/s]Map:  76%|███████▌  | 3023/3968 [01:06<00:28, 33.50 examples/s]Map:  76%|███████▋  | 3029/3968 [01:06<00:25, 36.91 examples/s]Map:  76%|███████▋  | 3035/3968 [01:06<00:23, 39.62 examples/s]Map:  77%|███████▋  | 3041/3968 [01:06<00:21, 42.67 examples/s]Map:  77%|███████▋  | 3047/3968 [01:06<00:20, 44.66 examples/s]Map:  77%|███████▋  | 3053/3968 [01:06<00:19, 46.37 examples/s]Map:  77%|███████▋  | 3059/3968 [01:06<00:19, 46.40 examples/s]Map:  77%|███████▋  | 3065/3968 [01:06<00:19, 47.29 examples/s]Map:  77%|███████▋  | 3071/3968 [01:06<00:18, 48.15 examples/s]Map:  78%|███████▊  | 3077/3968 [01:07<00:18, 48.95 examples/s]Map:  78%|███████▊  | 3083/3968 [01:07<00:18, 49.00 examples/s]Map:  78%|███████▊  | 3089/3968 [01:07<00:17, 49.10 examples/s]Map:  78%|███████▊  | 3095/3968 [01:07<00:17, 49.47 examples/s]Map:  78%|███████▊  | 3101/3968 [01:07<00:17, 49.65 examples/s]Map:  78%|███████▊  | 3107/3968 [01:07<00:17, 49.67 examples/s]Map:  78%|███████▊  | 3113/3968 [01:07<00:17, 49.25 examples/s]Map:  79%|███████▊  | 3118/3968 [01:07<00:17, 47.78 examples/s]Map:  79%|███████▊  | 3124/3968 [01:08<00:17, 49.11 examples/s]Map:  79%|███████▉  | 3130/3968 [01:08<00:17, 49.15 examples/s]Map:  79%|███████▉  | 3136/3968 [01:08<00:16, 49.34 examples/s]Map:  79%|███████▉  | 3142/3968 [01:08<00:17, 48.37 examples/s]Map:  79%|███████▉  | 3148/3968 [01:08<00:16, 48.44 examples/s]Map:  79%|███████▉  | 3154/3968 [01:08<00:16, 49.21 examples/s]Map:  80%|███████▉  | 3160/3968 [01:08<00:16, 49.51 examples/s]Map:  80%|███████▉  | 3166/3968 [01:08<00:16, 49.17 examples/s]Map:  80%|███████▉  | 3172/3968 [01:09<00:17, 46.48 examples/s]Map:  80%|████████  | 3178/3968 [01:09<00:16, 47.39 examples/s]Map:  80%|████████  | 3184/3968 [01:09<00:16, 47.84 examples/s]Map:  80%|████████  | 3190/3968 [01:09<00:15, 48.67 examples/s]Map:  81%|████████  | 3196/3968 [01:09<00:15, 49.15 examples/s]Map:  81%|████████  | 3202/3968 [01:09<00:15, 49.24 examples/s]Map:  81%|████████  | 3208/3968 [01:09<00:15, 47.96 examples/s]Map:  81%|████████  | 3214/3968 [01:09<00:15, 48.28 examples/s]Map:  81%|████████  | 3220/3968 [01:10<00:15, 48.74 examples/s]Map:  81%|████████▏ | 3226/3968 [01:10<00:15, 48.98 examples/s]Map:  81%|████████▏ | 3232/3968 [01:10<00:15, 48.87 examples/s]Map:  82%|████████▏ | 3237/3968 [01:10<00:15, 47.27 examples/s]Map:  82%|████████▏ | 3243/3968 [01:10<00:15, 46.59 examples/s]Map:  82%|████████▏ | 3249/3968 [01:10<00:14, 48.29 examples/s]Map:  82%|████████▏ | 3255/3968 [01:10<00:14, 48.95 examples/s]Map:  82%|████████▏ | 3261/3968 [01:10<00:14, 47.91 examples/s]Map:  82%|████████▏ | 3267/3968 [01:11<00:14, 48.36 examples/s]Map:  82%|████████▏ | 3273/3968 [01:11<00:14, 47.23 examples/s]Map:  83%|████████▎ | 3279/3968 [01:11<00:14, 47.44 examples/s]Map:  83%|████████▎ | 3284/3968 [01:11<00:14, 46.19 examples/s]Map:  83%|████████▎ | 3290/3968 [01:11<00:14, 47.20 examples/s]Map:  83%|████████▎ | 3296/3968 [01:11<00:14, 46.99 examples/s]Map:  83%|████████▎ | 3302/3968 [01:11<00:14, 47.37 examples/s]Map:  83%|████████▎ | 3308/3968 [01:11<00:13, 47.97 examples/s]Map:  84%|████████▎ | 3314/3968 [01:12<00:13, 46.87 examples/s]Map:  84%|████████▎ | 3320/3968 [01:12<00:13, 47.22 examples/s]Map:  84%|████████▍ | 3326/3968 [01:12<00:13, 47.60 examples/s]Map:  84%|████████▍ | 3332/3968 [01:12<00:13, 48.34 examples/s]Map:  84%|████████▍ | 3338/3968 [01:12<00:12, 48.79 examples/s]Map:  84%|████████▍ | 3343/3968 [01:12<00:13, 47.70 examples/s]Map:  84%|████████▍ | 3349/3968 [01:12<00:12, 47.93 examples/s]Map:  85%|████████▍ | 3355/3968 [01:12<00:12, 47.90 examples/s]Map:  85%|████████▍ | 3361/3968 [01:12<00:12, 48.73 examples/s]Map:  85%|████████▍ | 3367/3968 [01:13<00:12, 48.10 examples/s]Map:  85%|████████▌ | 3373/3968 [01:13<00:12, 48.39 examples/s]Map:  85%|████████▌ | 3379/3968 [01:13<00:12, 47.57 examples/s]Map:  85%|████████▌ | 3384/3968 [01:13<00:12, 46.27 examples/s]Map:  85%|████████▌ | 3390/3968 [01:13<00:12, 46.92 examples/s]Map:  86%|████████▌ | 3396/3968 [01:13<00:12, 47.55 examples/s]Map:  86%|████████▌ | 3402/3968 [01:13<00:11, 48.26 examples/s]Map:  86%|████████▌ | 3407/3968 [01:13<00:11, 47.09 examples/s]Map:  86%|████████▌ | 3413/3968 [01:14<00:11, 47.06 examples/s]Map:  86%|████████▌ | 3419/3968 [01:14<00:11, 46.93 examples/s]Map:  86%|████████▋ | 3425/3968 [01:14<00:12, 45.14 examples/s]Map:  86%|████████▋ | 3431/3968 [01:14<00:11, 46.17 examples/s]Map:  87%|████████▋ | 3437/3968 [01:14<00:11, 46.44 examples/s]Map:  87%|████████▋ | 3443/3968 [01:14<00:11, 47.35 examples/s]Map:  87%|████████▋ | 3449/3968 [01:14<00:11, 46.94 examples/s]Map:  87%|████████▋ | 3454/3968 [01:14<00:11, 45.39 examples/s]Map:  87%|████████▋ | 3460/3968 [01:15<00:11, 45.49 examples/s]Map:  87%|████████▋ | 3466/3968 [01:15<00:10, 46.51 examples/s]Map:  88%|████████▊ | 3472/3968 [01:15<00:10, 47.20 examples/s]Map:  88%|████████▊ | 3478/3968 [01:15<00:10, 48.37 examples/s]Map:  88%|████████▊ | 3484/3968 [01:15<00:10, 47.98 examples/s]Map:  88%|████████▊ | 3490/3968 [01:15<00:09, 48.65 examples/s]Map:  88%|████████▊ | 3496/3968 [01:15<00:09, 48.42 examples/s]Map:  88%|████████▊ | 3502/3968 [01:15<00:09, 49.00 examples/s]Map:  88%|████████▊ | 3508/3968 [01:16<00:09, 49.29 examples/s]Map:  89%|████████▊ | 3514/3968 [01:16<00:09, 45.89 examples/s]Map:  89%|████████▊ | 3520/3968 [01:16<00:09, 47.29 examples/s]Map:  89%|████████▉ | 3526/3968 [01:16<00:09, 46.75 examples/s]Map:  89%|████████▉ | 3532/3968 [01:16<00:09, 47.49 examples/s]Map:  89%|████████▉ | 3538/3968 [01:16<00:08, 48.30 examples/s]Map:  89%|████████▉ | 3544/3968 [01:16<00:08, 48.54 examples/s]Map:  89%|████████▉ | 3550/3968 [01:16<00:08, 48.17 examples/s]Map:  90%|████████▉ | 3556/3968 [01:17<00:08, 49.53 examples/s]Map:  90%|████████▉ | 3562/3968 [01:17<00:08, 48.77 examples/s]Map:  90%|████████▉ | 3568/3968 [01:17<00:08, 49.00 examples/s]Map:  90%|█████████ | 3574/3968 [01:17<00:08, 48.47 examples/s]Map:  90%|█████████ | 3580/3968 [01:17<00:07, 48.96 examples/s]Map:  90%|█████████ | 3586/3968 [01:17<00:07, 49.01 examples/s]Map:  91%|█████████ | 3592/3968 [01:17<00:07, 49.82 examples/s]Map:  91%|█████████ | 3598/3968 [01:17<00:07, 50.00 examples/s]Map:  91%|█████████ | 3604/3968 [01:18<00:07, 49.66 examples/s]Map:  91%|█████████ | 3610/3968 [01:18<00:07, 49.55 examples/s]Map:  91%|█████████ | 3616/3968 [01:18<00:07, 49.80 examples/s]Map:  91%|█████████▏| 3622/3968 [01:18<00:06, 49.66 examples/s]Map:  91%|█████████▏| 3628/3968 [01:18<00:06, 49.16 examples/s]Map:  92%|█████████▏| 3634/3968 [01:18<00:06, 48.13 examples/s]Map:  92%|█████████▏| 3640/3968 [01:18<00:06, 47.51 examples/s]Map:  92%|█████████▏| 3646/3968 [01:18<00:06, 46.92 examples/s]Map:  92%|█████████▏| 3652/3968 [01:19<00:06, 47.63 examples/s]Map:  92%|█████████▏| 3658/3968 [01:19<00:06, 48.45 examples/s]Map:  92%|█████████▏| 3664/3968 [01:19<00:06, 48.80 examples/s]Map:  92%|█████████▏| 3670/3968 [01:19<00:06, 48.95 examples/s]Map:  93%|█████████▎| 3676/3968 [01:19<00:06, 47.42 examples/s]Map:  93%|█████████▎| 3681/3968 [01:19<00:06, 46.09 examples/s]Map:  93%|█████████▎| 3686/3968 [01:19<00:06, 45.30 examples/s]Map:  93%|█████████▎| 3692/3968 [01:19<00:05, 47.06 examples/s]Map:  93%|█████████▎| 3698/3968 [01:20<00:05, 47.55 examples/s]Map:  93%|█████████▎| 3704/3968 [01:20<00:05, 47.73 examples/s]Map:  93%|█████████▎| 3710/3968 [01:20<00:05, 48.67 examples/s]Map:  94%|█████████▎| 3716/3968 [01:20<00:05, 48.83 examples/s]Map:  94%|█████████▍| 3722/3968 [01:20<00:05, 48.82 examples/s]Map:  94%|█████████▍| 3728/3968 [01:20<00:04, 48.02 examples/s]Map:  94%|█████████▍| 3734/3968 [01:20<00:04, 48.11 examples/s]Map:  94%|█████████▍| 3740/3968 [01:20<00:04, 47.84 examples/s]Map:  94%|█████████▍| 3746/3968 [01:21<00:04, 47.93 examples/s]Map:  95%|█████████▍| 3752/3968 [01:21<00:04, 49.13 examples/s]Map:  95%|█████████▍| 3758/3968 [01:21<00:04, 47.92 examples/s]Map:  95%|█████████▍| 3764/3968 [01:21<00:04, 47.78 examples/s]Map:  95%|█████████▌| 3770/3968 [01:21<00:04, 48.34 examples/s]Map:  95%|█████████▌| 3776/3968 [01:21<00:03, 48.97 examples/s]Map:  95%|█████████▌| 3782/3968 [01:21<00:03, 49.39 examples/s]Map:  95%|█████████▌| 3788/3968 [01:21<00:03, 49.83 examples/s]Map:  96%|█████████▌| 3794/3968 [01:22<00:03, 47.86 examples/s]Map:  96%|█████████▌| 3800/3968 [01:22<00:03, 46.60 examples/s]Map:  96%|█████████▌| 3806/3968 [01:22<00:03, 47.07 examples/s]Map:  96%|█████████▌| 3812/3968 [01:22<00:03, 47.99 examples/s]Map:  96%|█████████▌| 3817/3968 [01:22<00:03, 46.84 examples/s]Map:  96%|█████████▋| 3823/3968 [01:22<00:02, 48.45 examples/s]Map:  96%|█████████▋| 3828/3968 [01:22<00:03, 46.62 examples/s]Map:  97%|█████████▋| 3833/3968 [01:22<00:02, 46.10 examples/s]Map:  97%|█████████▋| 3839/3968 [01:22<00:02, 47.31 examples/s]Map:  97%|█████████▋| 3845/3968 [01:23<00:02, 48.13 examples/s]Map:  97%|█████████▋| 3851/3968 [01:23<00:02, 47.37 examples/s]Map:  97%|█████████▋| 3857/3968 [01:23<00:02, 47.07 examples/s]Map:  97%|█████████▋| 3862/3968 [01:23<00:02, 45.65 examples/s]Map:  97%|█████████▋| 3868/3968 [01:23<00:02, 47.44 examples/s]Map:  98%|█████████▊| 3874/3968 [01:23<00:01, 47.08 examples/s]Map:  98%|█████████▊| 3880/3968 [01:23<00:01, 47.33 examples/s]Map:  98%|█████████▊| 3886/3968 [01:23<00:01, 46.89 examples/s]Map:  98%|█████████▊| 3892/3968 [01:24<00:01, 48.11 examples/s]Map:  98%|█████████▊| 3898/3968 [01:24<00:01, 47.77 examples/s]Map:  98%|█████████▊| 3904/3968 [01:24<00:01, 48.91 examples/s]Map:  99%|█████████▊| 3910/3968 [01:24<00:01, 49.33 examples/s]Map:  99%|█████████▊| 3916/3968 [01:24<00:01, 47.57 examples/s]Map:  99%|█████████▉| 3922/3968 [01:24<00:00, 47.56 examples/s]Map:  99%|█████████▉| 3928/3968 [01:24<00:00, 47.13 examples/s]Map:  99%|█████████▉| 3934/3968 [01:24<00:00, 48.16 examples/s]Map:  99%|█████████▉| 3940/3968 [01:25<00:00, 47.72 examples/s]Map:  99%|█████████▉| 3946/3968 [01:25<00:00, 48.91 examples/s]Map: 100%|█████████▉| 3952/3968 [01:25<00:00, 47.23 examples/s]Map: 100%|█████████▉| 3958/3968 [01:25<00:00, 47.52 examples/s]Map: 100%|█████████▉| 3964/3968 [01:25<00:00, 47.94 examples/s]                                                               Saved results to: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.csv
--> Getting baseline test results...
Baseline Test WER: 0.702
Baseline Test CER: 0.360


--> Getting baseline alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20230926_4_baseline_result.txt


--> Showing some baseline prediction errors...
   target_text      pred_str
0         NOSE          MARY
1  BELLYBUTTON  BELLY BUTTON
2         THAT           WHA
3         LEAF          LEAF
4        SWORD         SWORD
5  GRASSHOPPER    GRASSHOPER
6        SHORT            HU
7         NOSE          NOSE
8    CROCODILE  CLOKAGOT DIO
9         BIRD           DAD
--> Taking a deeper look...
<pad> <pad> <pad> <pad> B <pad> <pad> <pad> <pad> <pad> <pad> I R R R <pad> <pad> D D <pad> | | | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 11/10/2023 20:49:12
Wed Oct 11 20:52:10 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
Running:  /srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py
Started: 11/10/2023 20:52:10

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: hubert
dataset_name: AusKidTalk
experiment_id: hubert_eval_AusKidTalk_scripted_20231011
cache_name: AusKidTalk-eval
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
baseline_model: facebook/hubert-large-ls960-ft
eval_baseline: True

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.05
mask_time_prob: 0.065
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 4e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 22
max_steps: 35000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/scripted_new/AusKidTalk_scripted_test_dataframe_new_180speakers_shuffled_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/hubert/vocab/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/hubert/model/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011
--> baseline_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/hubert/model/CU/finetune_CU_20230909
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 530.69it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ed4c3c62259f8860.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6a742c374d450edc.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-2a8d149b1580a6d7_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-64124eb72cd7ef7c_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-fae4936ac3f472aa_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f8ae5a66baaae03c_*_of_00004.arrow
/srv/scratch/z5313567/thesis/hubert/code/hubert_eval_AusKidTalk.py:557: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/hubert/modeling_hubert.py:1125: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-564c8a88509f2834.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-33e0a1eb31d5c475/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-562ecbbdd49bc2cd.arrow
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 3968
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: BI BUBBLES BIG WHY ARE SOME SMALL
Input array shape: (46881,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.810
Fine-tuned Test CER: 0.402


--> Getting finetuned alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/hubert/finetuned_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011_finetuned_result.txt


--> Showing some fine-tuned prediction errors...
  target_text   pred_str
0     BREATHE    BREATHE
1      CARPET        OPA
2   AUSTRALIA  AUSTRALIA
3        PULL        PUL
4    CUCUMBER      TUCUM
5       SWING      SWING
6     FEATHER    FEATHER
7      GARDEN      GOTEN
8      CARPET    CARPRET
9       CHAIR           
--> Taking a deeper look...
<pad> <pad> <pad> B B <pad> I I <pad> <pad> <pad> <pad> <pad> <pad> R R <pad> <pad> <pad> <pad> D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> EVALUATING BASELINE MODEL... ------------------------------------------ 

Saved results to: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011_baseline_result.csv
--> Getting baseline test results...
Baseline Test WER: 0.702
Baseline Test CER: 0.360


--> Getting baseline alignment output...
Saved Alignment output to: /srv/scratch/z5313567/thesis/hubert/baseline_result/AusKidTalk/hubert_eval_AusKidTalk_scripted_20231011_baseline_result.txt


--> Showing some baseline prediction errors...
   target_text      pred_str
0         NOSE          MARY
1  BELLYBUTTON  BELLY BUTTON
2         THAT           WHA
3         LEAF          LEAF
4        SWORD         SWORD
5  GRASSHOPPER    GRASSHOPER
6        SHORT            HU
7         NOSE          NOSE
8    CROCODILE  CLOKAGOT DIO
9         BIRD           DAD
--> Taking a deeper look...
<pad> <pad> <pad> <pad> B <pad> <pad> <pad> <pad> <pad> <pad> I R R R <pad> <pad> D D <pad> | | | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 11/10/2023 20:52:29
