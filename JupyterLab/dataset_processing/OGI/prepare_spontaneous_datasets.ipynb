{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269368c-93a0-4fc6-a8a6-3ce37a732393",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22874e-610c-4697-9a7f-bac6706c0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee6ab7-a548-4590-b91d-aaa02282a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3dfa2a0-83ff-4a3a-9f67-b176fef8ab7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------> Importing libraries... ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Purpose: prepare datasets for OGI spontaneous datasets\n",
    "# Based on https://github.com/musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment/blob/master/2-%20Preparing%20the%20Dataset/prepare_dataset.py\n",
    "# Based on https://github.com/monomest/Thesis/blob/3a15f747dfd934535ffb7a02bf3fee97d9c546cb/s5/wav2vec_projects/OGI_prep.py#L40\n",
    "print(\"\\n------> Importing libraries... ------\\n\")\n",
    "\n",
    "import librosa\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8641cefa-b33c-46cf-a71f-f9e5df9e96c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------> Loading files... ------\n",
      "\n",
      "Transcription files are stored at: /srv/scratch/chacmod/OGI/trans/spontaneous\n",
      "Speech files are stored at: /srv/scratch/chacmod/OGI/speech/spontaneous\n",
      "OGI spontaneous dataframe is stored at: /srv/scratch/z5313567/thesis/OGI_local/OGI_spontaneous_dataframe.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------> Loading files... ------\\n\")\n",
    "\n",
    "# Path where the OGI datasets are stored\n",
    "dataset_transcription_fp = \"/srv/scratch/chacmod/OGI/trans/spontaneous\"\n",
    "dataset_speech_fp = \"/srv/scratch/chacmod/OGI/speech/spontaneous\"\n",
    "print(f'Transcription files are stored at: {dataset_transcription_fp}')\n",
    "print(f'Speech files are stored at: {dataset_speech_fp}')\n",
    "\n",
    "# Path to save OGI dataframe\n",
    "OGI_df_fp = '/srv/scratch/z5313567/thesis/OGI_local/OGI_spontaneous_dataframe.csv'\n",
    "print(f'OGI spontaneous dataframe is stored at: {OGI_df_fp}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d93be8-82e0-451a-b568-08059906f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------> Obtaining speech tags... ------\n",
      "\n",
      "[] includes ['[b]', '[oaches]', '[sure]', '[nhattan]', '[st]', '[gon]', '[ow]', '[elius]', '[cation]', '[ike]', '[ies]', '[attle]', '[end]', '[min]', '[ple]', '[tead]', '[nna]', '[n]', '[ster]', '[ead]', '[ther]', '[ght]', '[py]', '[ean]', '[na]', '[ell]', '[f]', '[unner]', '[ly]', '[bn]', '[corting]', '[day]', \"[dn't]\", '[uy]', '[me]', '[lack]', '[tling]', '[puter]', '[ge]', '[ke]', '[a]', '[aw]', '[ent]', '[retary]', '[la]', '[abet]', '[ndiana]', '[uch]', '[son]', '[sh]', '[sk]', '[thers]', '[ia]', '[c]', '[bs]', '[ver]', '[ahu]', '[cient]', '[tan]', '[eo]', '[x]', '[t]', '[peak]', '[wh]', '[em]', '[kes]', '[ll]', '[ck]', '[est]', '[nesday]', '[and]', '[ff]', '[ter]', '[gold]', '[amp]', '[tch]', '[zzle]', '[nk]', '[ting]', '[ack]', '[ward]', '[ah]', '[ers]', '[ifier]', '[id]', '[ide]', '[y]', '[ters]', '[tion]', '[dwiches]', '[th]', '[teal]', '[ve]', '[om]', '[ife]', '[seum]', '[ccer]', '[w]', '[mputer]', '[at]', '[us]', '[land]', '[ee]', '[arge]', '[ss]', '[eighborhood]', '[wimming]', '[enty]', '[other]', '[cl]', '[ix]', '[ause]', '[ater]', '[phabet]', '[uni]', '[ound]', '[xture]', '[hoven]', '[der]', '[ing]', '[as]', '[ears]', '[ate]', '[tle]', '[xed]', '[nnings]', '[lace]', '[brother]', '[arents]', '[ar]', '[aid]', '[ut]', '[no]', '[ents]', '[chool]', '[lock]', '[anding]', '[rses]', '[ord]', '[ures]', '[oke]', '[ramento]', '[week]', '[ued]', '[hristen]', '[ister]', '[le]', '[utation]', '[o]', '[ousins]', '[ould]', '[ned]', '[reographer]', '[ny]', '[ne]', '[ye]', '[de]', '[ill]', '[ay]', '[che]', '[loset]', '[geogra]', '[ok]', '[ange]', '[study]', '[mi]', '[tuff]', '[r]', '[ep]', \"[n't]\", '[sal]', '[ndoned]', '[chers]', '[les]', '[ssie]', '[alpha]', '[sterday]', '[ad]', '[ampions]', '[ld]', '[ernation]', '[er]', '[ves]', '[all]', '[ally]', '[erve]', '[fter]', '[se]', '[sed]', '[bee]', '[ln]', '[on]', '[s]', '[lled]', '[ip]', '[ore]', '[re]', '[un]', '[inosaur]', '[wer]', '[ry]', '[milies]', '[lay]', '[xophone]', '[cer]', '[chu]', '[ats]', '[teen]', '[en]', '[g]', '[ably]', '[d]', '[ily]', '[bin]', '[et]', \"[ne*'s]\", '[ce]', '[ty]', '[cess]'], the number is 219 \n",
      "\n",
      "<> includes ['<sing>', '<n>', '<sniff>', '<bs>', '<pf>', '<fp>', '<asp>', '<cough>', '<sneeze>', '<nitl>', '<blip>', '<lau>', '<pau>', '<beep>', '<ln>', '<br>', '<long>', '<ls>', '<pron>', '<uu>', '<yawn>', '<ct>', '<sp>', '<laugh>', '<ns>', '<tc>', '<whisper>', '<bn>'], the number is 28 \n",
      "\n",
      "() includes ['(bs)', '(bn)', '(ln)', '(pf)'], the number is 4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------> Obtaining speech tags... ------\\n\")\n",
    "\n",
    "trans = [];\n",
    "squ_brkt_tags = [] # []\n",
    "ang_brkt_tags = [] # <>\n",
    "rnd_brkt_tags = [] # ()\n",
    "\n",
    "# pattern to remove: [words], <words>, (words)\n",
    "pattern = r'\\[([^]]+)\\]|<([^>]+)>|\\(([^)]+)\\)'\n",
    "\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_transcription_fp)):\n",
    "    if dirpath is not dataset_transcription_fp:      \n",
    "        if filenames and any(filename.endswith(\".txt\") for filename in filenames):\n",
    "            trans_fp = os.path.join(dirpath, filenames[0])\n",
    "            with open(trans_fp, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                line = lines[0]\n",
    "                '''\n",
    "                if '<br. and maybe walk my dog maybe play with my cat <br>' in line:\n",
    "                    print(trans_fp)\n",
    "                    break\n",
    "                '''\n",
    "                matches = re.findall(pattern, line)\n",
    "                for match in matches:\n",
    "                    if match[0]: # []\n",
    "                        squ_brkt_tags.append('[{}]'.format(match[0]))\n",
    "                        squ_brkt_tags = list(set(squ_brkt_tags)) # use set function to remove repetitive patterns\n",
    "                    elif match[1]: # <>\n",
    "                        ang_brkt_tags.append('<{}>'.format(match[1]))\n",
    "                        ang_brkt_tags = list(set(ang_brkt_tags)) # use set function to remove repetitive patterns\n",
    "                    elif match[2]: #  ()\n",
    "                        rnd_brkt_tags.append('({})'.format(match[2]))\n",
    "                        rnd_brkt_tags = list(set(rnd_brkt_tags)) # use set function to remove repetitive patterns\n",
    "            f.close()\n",
    "\n",
    "ang_brkt_tags.remove('<bs: can you des*>')\n",
    "ang_brkt_tags.remove('<br. and maybe walk my dog maybe play with my cat <br>')\n",
    "print(f\"[] includes {squ_brkt_tags}, the number is {len(squ_brkt_tags)} \\n\")\n",
    "print(f\"<> includes {ang_brkt_tags}, the number is {len(ang_brkt_tags)} \\n\")\n",
    "print(f\"() includes {rnd_brkt_tags}, the number is {len(rnd_brkt_tags)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "739c34c4-a88b-4909-a9ba-1be0b68e9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotations = squ_brkt_tags + ang_brkt_tags \n",
    "#print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753274e6-29b9-4c65-ac24-75fc86641b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------> Obtaining transcriptions... ------\n",
      "\n",
      "1101\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------> Obtaining transcriptions... ------\\n\")\n",
    "\n",
    "trans = [];\n",
    "\n",
    "tags = ang_brkt_tags + squ_brkt_tags + rnd_brkt_tags\n",
    "\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_transcription_fp)):\n",
    "    if dirpath is not dataset_transcription_fp:\n",
    "        #print(dirpath, \"     \", dirnames, \"    \",  filenames)       \n",
    "        if filenames and (filename.endswith(\".txt\") for filename in filenames):\n",
    "            trans_fp = os.path.join(dirpath, filenames[0])\n",
    "            with open(trans_fp, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                # remove all speech tags from transcription\n",
    "                # <sing>, <br>, <bn>, <bs>, <ln>, <pau>, <long>, <laugh>, <pron>, <ls>, <ns>, <uu>, <whisper>, <fp>, <sniff>, <tc>, [gold]...\n",
    "                line = lines[0]\n",
    "                for tag in tags:\n",
    "                    line = line.replace(tag, '') \n",
    "                line = line.replace('<bs', '')\n",
    "                line = line.replace('<br', '')\n",
    "                line = line.replace(']', '')\n",
    "                line = line.replace('>', '')\n",
    "                # remove unnecessary symbols\n",
    "                chars_to_ignore = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\*]'\n",
    "                line = re.sub(chars_to_ignore, '', line).lower()\n",
    "                # remove extra whitespace between words\n",
    "                line = re.sub(r'\\s+', ' ', line)\n",
    "                # remove leading and trailing whitespaces\n",
    "                line = line.strip()\n",
    "                trans.append(line)\n",
    "            f.close()\n",
    "print(len(trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03720daa-8d13-48f1-84fb-c099c4ec51df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------> Obtaining .wav filepath, durations and speaker ID... ------\n",
      "\n",
      "1101 1101 1101\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------> Obtaining .wav filepath, durations and speaker ID... ------\\n\")\n",
    "\n",
    "speech_filepath = [];\n",
    "durations = [];\n",
    "speaker_ids = [];\n",
    "\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_speech_fp)):\n",
    "    if dirpath is not dataset_speech_fp:\n",
    "        #print(dirpath, \"     \", dirnames, \"    \",  filenames)    \n",
    "        # check if 'filenames' is empty and with 'wav' extension\n",
    "        if filenames and (filename.endswith(\".wav\") for filename in filenames):\n",
    "            # obtain each .wav filepath\n",
    "            speech_fp = os.path.join(dirpath, filenames[0])\n",
    "            speech_filepath.append(speech_fp)\n",
    "            \n",
    "            # obtain the signal, sampling rate, and hence the duration of each .wav file\n",
    "            signal, sample_rate = librosa.load(speech_fp)\n",
    "            dur = len(signal)/sample_rate\n",
    "            durations.append(dur)\n",
    "            \n",
    "            # obtain speaker id\n",
    "            # for example, /srv/scratch/chacmod/OGI/speech/spontaneous/00/0/ks001/ks001xx0, ks001 is extracted\n",
    "            directories =  speech_fp.split('/')\n",
    "            speaker_id = directories[-2]\n",
    "            speaker_ids.append(speaker_id)                               \n",
    "            \n",
    "print(len(speech_filepath), len(durations), len(speaker_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75cddb85-77fb-4e7a-8d21-e91d46f1d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine_trans_fp = {k: v for k, v in zip(trans, speech_filepath)}\n",
    "#print(combine_trans_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0322a036-6734-47e7-986a-492e8bc7ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OGI = pd.DataFrame(\n",
    "        {'filepath': speech_filepath,\n",
    "         'duration': durations,\n",
    "         'speaker_id': speaker_ids,\n",
    "         'transcription': trans\n",
    "         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6a779af-57b5-496a-91e1-77656e6af213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where there is no transcription\n",
    "# i.e. no spoken words, only silence or speech tags\n",
    "OGI = OGI[OGI.transcription != None]\n",
    "OGI = OGI[OGI.transcription != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db33a866-de87-4cc6-800c-530193e808b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------> Saving dataframe to csv file... ------\n",
      "\n",
      "Successfully saved dataframe to csv file at /srv/scratch/z5313567/thesis/OGI_local/OGI_spontaneous_dataframe.csv\n",
      "Total number of speakers: 1101\n",
      "Total hours: 30.5992863063744\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------> Saving dataframe to csv file... ------\\n\")\n",
    "#OGI_df_fp = '/srv/scratch/z5313567/thesis/OGI_local/OGI_dataframe.csv'\n",
    "OGI.to_csv(OGI_df_fp,index = False)\n",
    "print('Successfully saved dataframe to csv file at', OGI_df_fp)\n",
    "print(\"Total number of speakers:\", len(OGI))\n",
    "print(\"Total hours:\", OGI['duration'].sum()/(60*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26641e55-8be3-43d5-9f6e-c68cba94435c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (ipykernel)",
   "language": "python",
   "name": "python-3.10.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
