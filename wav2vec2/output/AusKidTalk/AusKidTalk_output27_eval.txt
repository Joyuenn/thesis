Fri Jul 28 00:41:50 AEST 2023
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py
Started: 28/07/2023 00:41:50

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230727_2
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718_with_lm_3
Language model 2: patrickvonplaten/wav2vec2-base-100h-with-lm
wright_model_1: 0.15
Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 149, in <module>
    weight_model_pretrained = 1-weight_model1;
NameError: name 'weight_model1' is not defined. Did you mean: 'weight_model_1'?
Fri Jul 28 00:57:42 AEST 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py
Started: 28/07/2023 00:57:43

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230727_2
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718_with_lm_3
Language model 2: patrickvonplaten/wav2vec2-base-100h-with-lm
wright_model_1: 0.15
wright_model_2: 0.85
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230727_2_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230727_2
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230727_2_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230727_2_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 171.92it/s]
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur tries to play with hulk but hulk ...
1  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                    the dinosaur poked out his head
2  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                  and he feed the dinosaur his milk
3  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                    and the dinosaur was lying down
4  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                           he was on the skateboard
5  /srv/scratch/chacmod/auskidtalk_spontaneous/81...            a dinosaur jumps out and hulk is scared
6  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk was riding backwards on a skateboard and ...
7  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                        he was listening to the egg
8  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk tries to hide from the dinosaur and is st...
9  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                               the dinosaur was sad
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------

Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]Downloading (â€¦)olve/main/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 291/291 [00:00<00:00, 2.51MB/s]
Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [00:00<00:00, 1.88MB/s]
Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]Downloading (â€¦)cial_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85.0/85.0 [00:00<00:00, 1.07MB/s]
Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.60k/1.60k [00:00<00:00, 19.7MB/s]

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=4):   4%|â–         | 1/24 [00:01<00:41,  1.79s/ examples]Map (num_proc=4):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 20/24 [00:01<00:00, 14.25 examples/s]                                                                        Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=4):   4%|â–         | 1/24 [00:01<00:23,  1.02s/ examples]                                                                       --> Verifying data with a random sample...
Target text: THE DINOSAUR POKED OUT HIS HEAD
Input array shape: (47658,)
Sampling rate: 16000
Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:00<00:00, 33.95 examples/s]                                                                       Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:00<00:00, 34.29 examples/s]                                                                       /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py:613: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Downloading (â€¦)rocessor_config.json:   0%|          | 0.00/263 [00:00<?, ?B/s]Downloading (â€¦)rocessor_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 263/263 [00:00<00:00, 1.35MB/s]
Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]Downloading (â€¦)olve/main/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 291/291 [00:00<00:00, 2.65MB/s]
Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/559 [00:00<?, ?B/s]Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 559/559 [00:00<00:00, 4.33MB/s]
Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]Downloading (â€¦)cial_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85.0/85.0 [00:00<00:00, 996kB/s]
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]
Downloading (â€¦)age_model/attrs.json:   0%|          | 0.00/78.0 [00:00<?, ?B/s][ADownloading (â€¦)age_model/attrs.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78.0/78.0 [00:00<00:00, 764kB/s]

Downloading (â€¦)e_model/unigrams.txt:   0%|          | 0.00/1.74M [00:00<?, ?B/s][A

Downloading (â€¦)59db4e/alphabet.json:   0%|          | 0.00/198 [00:00<?, ?B/s][A[ADownloading (â€¦)59db4e/alphabet.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [00:00<00:00, 2.36MB/s]
Fetching 4 files:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.30s/it]
Downloading (â€¦)e_model/unigrams.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.74M/1.74M [00:00<00:00, 1.77MB/s][ADownloading (â€¦)e_model/unigrams.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.74M/1.74M [00:00<00:00, 1.77MB/s]

Downloading 4-gram.bin:   0%|          | 0.00/3.12G [00:00<?, ?B/s][A
Downloading 4-gram.bin:   0%|          | 10.5M/3.12G [00:00<03:58, 13.1MB/s][A
Downloading 4-gram.bin:   1%|          | 21.0M/3.12G [00:01<02:16, 22.7MB/s][A
Downloading 4-gram.bin:   1%|          | 31.5M/3.12G [00:01<01:45, 29.4MB/s][A
Downloading 4-gram.bin:   1%|â–         | 41.9M/3.12G [00:01<01:29, 34.6MB/s][A
Downloading 4-gram.bin:   2%|â–         | 52.4M/3.12G [00:01<01:20, 38.2MB/s][A
Downloading 4-gram.bin:   2%|â–         | 62.9M/3.12G [00:01<01:15, 40.7MB/s][A
Downloading 4-gram.bin:   2%|â–         | 73.4M/3.12G [00:02<01:10, 43.3MB/s][A
Downloading 4-gram.bin:   3%|â–Ž         | 83.9M/3.12G [00:02<01:08, 44.7MB/s][A
Downloading 4-gram.bin:   3%|â–Ž         | 94.4M/3.12G [00:02<01:06, 45.8MB/s][A
Downloading 4-gram.bin:   3%|â–Ž         | 105M/3.12G [00:02<01:03, 47.3MB/s] [A
Downloading 4-gram.bin:   4%|â–Ž         | 115M/3.12G [00:02<01:02, 48.3MB/s][A
Downloading 4-gram.bin:   4%|â–         | 126M/3.12G [00:03<01:01, 48.8MB/s][A
Downloading 4-gram.bin:   4%|â–         | 136M/3.12G [00:03<01:00, 49.3MB/s][A
Downloading 4-gram.bin:   5%|â–         | 147M/3.12G [00:03<00:59, 50.0MB/s][A
Downloading 4-gram.bin:   5%|â–Œ         | 157M/3.12G [00:03<00:58, 50.7MB/s][A
Downloading 4-gram.bin:   5%|â–Œ         | 168M/3.12G [00:04<00:57, 51.4MB/s][A
Downloading 4-gram.bin:   6%|â–Œ         | 178M/3.12G [00:04<00:57, 51.3MB/s][A
Downloading 4-gram.bin:   6%|â–Œ         | 189M/3.12G [00:04<00:56, 51.9MB/s][A
Downloading 4-gram.bin:   6%|â–‹         | 199M/3.12G [00:04<00:56, 52.2MB/s][A
Downloading 4-gram.bin:   7%|â–‹         | 210M/3.12G [00:04<00:55, 52.8MB/s][A
Downloading 4-gram.bin:   7%|â–‹         | 220M/3.12G [00:04<00:54, 53.2MB/s][A
Downloading 4-gram.bin:   7%|â–‹         | 231M/3.12G [00:05<00:53, 54.0MB/s][A
Downloading 4-gram.bin:   8%|â–Š         | 241M/3.12G [00:05<00:52, 54.6MB/s][A
Downloading 4-gram.bin:   8%|â–Š         | 252M/3.12G [00:05<00:52, 55.1MB/s][A
Downloading 4-gram.bin:   8%|â–Š         | 262M/3.12G [00:05<00:51, 55.6MB/s][A
Downloading 4-gram.bin:   9%|â–Š         | 273M/3.12G [00:05<00:50, 56.1MB/s][A
Downloading 4-gram.bin:   9%|â–‰         | 283M/3.12G [00:06<00:50, 56.8MB/s][A
Downloading 4-gram.bin:   9%|â–‰         | 294M/3.12G [00:06<00:49, 57.4MB/s][A
Downloading 4-gram.bin:  10%|â–‰         | 304M/3.12G [00:06<00:48, 58.1MB/s][A
Downloading 4-gram.bin:  10%|â–ˆ         | 315M/3.12G [00:06<00:47, 58.8MB/s][A
Downloading 4-gram.bin:  10%|â–ˆ         | 325M/3.12G [00:06<00:46, 59.7MB/s][A
Downloading 4-gram.bin:  11%|â–ˆ         | 336M/3.12G [00:06<00:46, 60.6MB/s][A
Downloading 4-gram.bin:  11%|â–ˆ         | 346M/3.12G [00:07<00:45, 61.3MB/s][A
Downloading 4-gram.bin:  11%|â–ˆâ–        | 357M/3.12G [00:07<00:44, 62.3MB/s][A
Downloading 4-gram.bin:  12%|â–ˆâ–        | 367M/3.12G [00:07<00:43, 63.2MB/s][A
Downloading 4-gram.bin:  12%|â–ˆâ–        | 377M/3.12G [00:07<00:42, 64.0MB/s][A
Downloading 4-gram.bin:  12%|â–ˆâ–        | 388M/3.12G [00:07<00:42, 64.5MB/s][A
Downloading 4-gram.bin:  13%|â–ˆâ–Ž        | 398M/3.12G [00:07<00:41, 65.2MB/s][A
Downloading 4-gram.bin:  13%|â–ˆâ–Ž        | 409M/3.12G [00:08<00:41, 66.0MB/s][A
Downloading 4-gram.bin:  13%|â–ˆâ–Ž        | 419M/3.12G [00:08<00:40, 66.3MB/s][A
Downloading 4-gram.bin:  14%|â–ˆâ–        | 430M/3.12G [00:08<00:40, 67.0MB/s][A
Downloading 4-gram.bin:  14%|â–ˆâ–        | 440M/3.12G [00:08<00:39, 67.6MB/s][A
Downloading 4-gram.bin:  14%|â–ˆâ–        | 451M/3.12G [00:08<00:39, 68.0MB/s][A
Downloading 4-gram.bin:  15%|â–ˆâ–        | 461M/3.12G [00:08<00:38, 68.9MB/s][A
Downloading 4-gram.bin:  15%|â–ˆâ–Œ        | 472M/3.12G [00:08<00:38, 68.8MB/s][A
Downloading 4-gram.bin:  15%|â–ˆâ–Œ        | 482M/3.12G [00:09<00:37, 69.6MB/s][A
Downloading 4-gram.bin:  16%|â–ˆâ–Œ        | 493M/3.12G [00:09<00:37, 69.8MB/s][A
Downloading 4-gram.bin:  16%|â–ˆâ–Œ        | 503M/3.12G [00:09<00:37, 69.9MB/s][A
Downloading 4-gram.bin:  16%|â–ˆâ–‹        | 514M/3.12G [00:09<00:36, 70.8MB/s][A
Downloading 4-gram.bin:  17%|â–ˆâ–‹        | 524M/3.12G [00:09<00:36, 70.6MB/s][A
Downloading 4-gram.bin:  17%|â–ˆâ–‹        | 535M/3.12G [00:09<00:36, 71.3MB/s][A
Downloading 4-gram.bin:  17%|â–ˆâ–‹        | 545M/3.12G [00:10<00:36, 71.6MB/s][A
Downloading 4-gram.bin:  18%|â–ˆâ–Š        | 556M/3.12G [00:10<00:35, 72.3MB/s][A
Downloading 4-gram.bin:  18%|â–ˆâ–Š        | 566M/3.12G [00:10<00:35, 72.8MB/s][A
Downloading 4-gram.bin:  18%|â–ˆâ–Š        | 577M/3.12G [00:10<00:34, 73.1MB/s][A
Downloading 4-gram.bin:  19%|â–ˆâ–‰        | 587M/3.12G [00:10<00:34, 73.4MB/s][A
Downloading 4-gram.bin:  19%|â–ˆâ–‰        | 598M/3.12G [00:10<00:34, 74.0MB/s][A
Downloading 4-gram.bin:  19%|â–ˆâ–‰        | 608M/3.12G [00:10<00:33, 74.5MB/s][A
Downloading 4-gram.bin:  20%|â–ˆâ–‰        | 619M/3.12G [00:10<00:33, 75.6MB/s][A
Downloading 4-gram.bin:  20%|â–ˆâ–ˆ        | 629M/3.12G [00:11<00:32, 75.9MB/s][A
Downloading 4-gram.bin:  20%|â–ˆâ–ˆ        | 640M/3.12G [00:11<00:32, 76.8MB/s][A
Downloading 4-gram.bin:  21%|â–ˆâ–ˆ        | 650M/3.12G [00:11<00:32, 77.3MB/s][A
Downloading 4-gram.bin:  21%|â–ˆâ–ˆ        | 661M/3.12G [00:11<00:31, 78.0MB/s][A
Downloading 4-gram.bin:  21%|â–ˆâ–ˆâ–       | 671M/3.12G [00:11<00:31, 78.3MB/s][A
Downloading 4-gram.bin:  22%|â–ˆâ–ˆâ–       | 682M/3.12G [00:11<00:30, 79.4MB/s][A
Downloading 4-gram.bin:  22%|â–ˆâ–ˆâ–       | 692M/3.12G [00:11<00:30, 79.5MB/s][A
Downloading 4-gram.bin:  22%|â–ˆâ–ˆâ–       | 703M/3.12G [00:12<00:30, 79.9MB/s][A
Downloading 4-gram.bin:  23%|â–ˆâ–ˆâ–Ž       | 713M/3.12G [00:12<00:29, 80.5MB/s][A
Downloading 4-gram.bin:  23%|â–ˆâ–ˆâ–Ž       | 724M/3.12G [00:12<00:29, 80.9MB/s][A
Downloading 4-gram.bin:  23%|â–ˆâ–ˆâ–Ž       | 734M/3.12G [00:12<00:29, 81.5MB/s][A
Downloading 4-gram.bin:  24%|â–ˆâ–ˆâ–       | 744M/3.12G [00:12<00:29, 82.0MB/s][A
Downloading 4-gram.bin:  24%|â–ˆâ–ˆâ–       | 755M/3.12G [00:12<00:28, 82.2MB/s][A
Downloading 4-gram.bin:  24%|â–ˆâ–ˆâ–       | 765M/3.12G [00:12<00:28, 83.2MB/s][A
Downloading 4-gram.bin:  25%|â–ˆâ–ˆâ–       | 776M/3.12G [00:12<00:28, 83.5MB/s][A
Downloading 4-gram.bin:  25%|â–ˆâ–ˆâ–Œ       | 786M/3.12G [00:13<00:27, 83.7MB/s][A
Downloading 4-gram.bin:  26%|â–ˆâ–ˆâ–Œ       | 797M/3.12G [00:13<00:27, 84.5MB/s][A
Downloading 4-gram.bin:  26%|â–ˆâ–ˆâ–Œ       | 807M/3.12G [00:13<00:27, 85.0MB/s][A
Downloading 4-gram.bin:  26%|â–ˆâ–ˆâ–Œ       | 818M/3.12G [00:13<00:26, 85.5MB/s][A
Downloading 4-gram.bin:  27%|â–ˆâ–ˆâ–‹       | 828M/3.12G [00:13<00:26, 86.1MB/s][A
Downloading 4-gram.bin:  27%|â–ˆâ–ˆâ–‹       | 839M/3.12G [00:13<00:26, 86.3MB/s][A
Downloading 4-gram.bin:  27%|â–ˆâ–ˆâ–‹       | 849M/3.12G [00:13<00:26, 86.8MB/s][A
Downloading 4-gram.bin:  28%|â–ˆâ–ˆâ–Š       | 860M/3.12G [00:13<00:25, 87.2MB/s][A
Downloading 4-gram.bin:  28%|â–ˆâ–ˆâ–Š       | 870M/3.12G [00:14<00:25, 87.5MB/s][A
Downloading 4-gram.bin:  28%|â–ˆâ–ˆâ–Š       | 881M/3.12G [00:14<00:25, 87.7MB/s][A
Downloading 4-gram.bin:  29%|â–ˆâ–ˆâ–Š       | 891M/3.12G [00:14<00:48, 45.6MB/s][A
Downloading 4-gram.bin:  29%|â–ˆâ–ˆâ–‰       | 902M/3.12G [00:14<00:41, 53.0MB/s][A
Downloading 4-gram.bin:  29%|â–ˆâ–ˆâ–‰       | 912M/3.12G [00:14<00:36, 60.0MB/s][A
Downloading 4-gram.bin:  30%|â–ˆâ–ˆâ–‰       | 923M/3.12G [00:14<00:33, 66.5MB/s][A
Downloading 4-gram.bin:  30%|â–ˆâ–ˆâ–‰       | 933M/3.12G [00:15<00:30, 71.9MB/s][A
Downloading 4-gram.bin:  30%|â–ˆâ–ˆâ–ˆ       | 944M/3.12G [00:15<00:28, 76.1MB/s][A
Downloading 4-gram.bin:  31%|â–ˆâ–ˆâ–ˆ       | 954M/3.12G [00:15<00:27, 79.4MB/s][A
Downloading 4-gram.bin:  31%|â–ˆâ–ˆâ–ˆ       | 965M/3.12G [00:15<00:26, 81.9MB/s][A
Downloading 4-gram.bin:  31%|â–ˆâ–ˆâ–ˆ       | 975M/3.12G [00:15<00:25, 83.7MB/s][A
Downloading 4-gram.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 986M/3.12G [00:15<00:25, 85.0MB/s][A
Downloading 4-gram.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 996M/3.12G [00:15<00:24, 86.0MB/s][A
Downloading 4-gram.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 1.01G/3.12G [00:15<00:24, 86.7MB/s][A
Downloading 4-gram.bin:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.02G/3.12G [00:16<00:24, 87.2MB/s][A
Downloading 4-gram.bin:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.03G/3.12G [00:16<00:23, 87.6MB/s][A
Downloading 4-gram.bin:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.04G/3.12G [00:16<00:23, 87.8MB/s][A
Downloading 4-gram.bin:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.05G/3.12G [00:16<00:23, 87.9MB/s][A
Downloading 4-gram.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 1.06G/3.12G [00:16<00:23, 88.1MB/s][A
Downloading 4-gram.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 1.07G/3.12G [00:16<00:23, 88.2MB/s][A
Downloading 4-gram.bin:  35%|â–ˆâ–ˆâ–ˆâ–      | 1.08G/3.12G [00:16<00:23, 88.3MB/s][A
Downloading 4-gram.bin:  35%|â–ˆâ–ˆâ–ˆâ–      | 1.09G/3.12G [00:16<00:23, 88.3MB/s][A
Downloading 4-gram.bin:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.10G/3.12G [00:17<00:22, 88.3MB/s][A
Downloading 4-gram.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.11G/3.12G [00:17<00:22, 88.2MB/s][A
Downloading 4-gram.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.12G/3.12G [00:17<00:22, 88.3MB/s][A
Downloading 4-gram.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.13G/3.12G [00:17<00:22, 88.2MB/s][A
Downloading 4-gram.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.14G/3.12G [00:17<00:22, 88.2MB/s][A
Downloading 4-gram.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.15G/3.12G [00:17<00:22, 88.2MB/s][A
Downloading 4-gram.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.16G/3.12G [00:17<00:22, 88.4MB/s][A
Downloading 4-gram.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.17G/3.12G [00:17<00:22, 88.3MB/s][A
Downloading 4-gram.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.18G/3.12G [00:17<00:21, 88.4MB/s][A
Downloading 4-gram.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.20G/3.12G [00:18<00:21, 88.3MB/s][A
Downloading 4-gram.bin:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.21G/3.12G [00:18<00:21, 88.3MB/s][A
Downloading 4-gram.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.22G/3.12G [00:18<00:21, 88.4MB/s][A
Downloading 4-gram.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.23G/3.12G [00:18<00:21, 88.4MB/s][A
Downloading 4-gram.bin:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.24G/3.12G [00:18<00:21, 88.4MB/s][A
Downloading 4-gram.bin:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.25G/3.12G [00:18<00:21, 88.3MB/s][A
Downloading 4-gram.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.26G/3.12G [00:18<00:21, 88.3MB/s][A
Downloading 4-gram.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.27G/3.12G [00:18<00:21, 88.3MB/s][A
Downloading 4-gram.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.28G/3.12G [00:19<00:20, 88.4MB/s][A
Downloading 4-gram.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.29G/3.12G [00:19<00:20, 88.3MB/s][A
Downloading 4-gram.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.30G/3.12G [00:19<00:20, 88.3MB/s][A
Downloading 4-gram.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.31G/3.12G [00:19<00:20, 88.4MB/s][A
Downloading 4-gram.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.32G/3.12G [00:19<00:20, 88.5MB/s][A
Downloading 4-gram.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.33G/3.12G [00:19<00:20, 88.3MB/s][A
Downloading 4-gram.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.34G/3.12G [00:19<00:20, 88.3MB/s][A
Downloading 4-gram.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.35G/3.12G [00:19<00:20, 88.3MB/s][A
Downloading 4-gram.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.36G/3.12G [00:19<00:19, 88.3MB/s][A
Downloading 4-gram.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.37G/3.12G [00:20<00:19, 88.4MB/s][A
Downloading 4-gram.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.38G/3.12G [00:20<00:19, 88.3MB/s][A
Downloading 4-gram.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.39G/3.12G [00:20<00:19, 88.4MB/s][A
Downloading 4-gram.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.41G/3.12G [00:20<00:19, 88.3MB/s][A
Downloading 4-gram.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.42G/3.12G [00:20<00:19, 88.3MB/s][A
Downloading 4-gram.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.43G/3.12G [00:20<00:19, 88.2MB/s][A
Downloading 4-gram.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.44G/3.12G [00:20<00:19, 88.2MB/s][A
Downloading 4-gram.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.45G/3.12G [00:20<00:19, 88.2MB/s][A
Downloading 4-gram.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.46G/3.12G [00:21<00:18, 88.2MB/s][A
Downloading 4-gram.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.47G/3.12G [00:21<00:18, 88.3MB/s][A
Downloading 4-gram.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.48G/3.12G [00:21<00:18, 88.4MB/s][A
Downloading 4-gram.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.49G/3.12G [00:21<00:18, 88.3MB/s][A
Downloading 4-gram.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.50G/3.12G [00:21<00:18, 88.3MB/s][A
Downloading 4-gram.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.51G/3.12G [00:21<00:18, 88.4MB/s][A
Downloading 4-gram.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.52G/3.12G [00:21<00:18, 88.5MB/s][A
Downloading 4-gram.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.53G/3.12G [00:21<00:18, 88.4MB/s][A
Downloading 4-gram.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.54G/3.12G [00:21<00:17, 88.3MB/s][A
Downloading 4-gram.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.55G/3.12G [00:22<00:17, 88.3MB/s][A
Downloading 4-gram.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.56G/3.12G [00:22<00:17, 88.4MB/s][A
Downloading 4-gram.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.57G/3.12G [00:22<00:17, 88.2MB/s][A
Downloading 4-gram.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.58G/3.12G [00:22<00:17, 88.2MB/s][A
Downloading 4-gram.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.59G/3.12G [00:22<00:17, 88.3MB/s][A
Downloading 4-gram.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.60G/3.12G [00:22<00:17, 88.4MB/s][A
Downloading 4-gram.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.61G/3.12G [00:22<00:17, 88.3MB/s][A
Downloading 4-gram.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.63G/3.12G [00:22<00:16, 88.4MB/s][A
Downloading 4-gram.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.64G/3.12G [00:23<00:16, 88.1MB/s][A
Downloading 4-gram.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.65G/3.12G [00:23<00:16, 88.2MB/s][A
Downloading 4-gram.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.66G/3.12G [00:23<00:16, 88.3MB/s][A
Downloading 4-gram.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.67G/3.12G [00:23<00:16, 88.3MB/s][A
Downloading 4-gram.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.68G/3.12G [00:23<00:16, 88.2MB/s][A
Downloading 4-gram.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.69G/3.12G [00:23<00:16, 88.3MB/s][A
Downloading 4-gram.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.70G/3.12G [00:23<00:16, 88.3MB/s][A
Downloading 4-gram.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.71G/3.12G [00:23<00:16, 88.4MB/s][A
Downloading 4-gram.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.72G/3.12G [00:24<00:15, 88.3MB/s][A
Downloading 4-gram.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.73G/3.12G [00:24<00:15, 88.3MB/s][A
Downloading 4-gram.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.74G/3.12G [00:24<00:15, 88.3MB/s][A
Downloading 4-gram.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.75G/3.12G [00:24<00:15, 88.4MB/s][A
Downloading 4-gram.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.76G/3.12G [00:24<00:15, 88.3MB/s][A
Downloading 4-gram.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.77G/3.12G [00:24<00:15, 88.4MB/s][A
Downloading 4-gram.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.78G/3.12G [00:24<00:15, 88.2MB/s][A
Downloading 4-gram.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.79G/3.12G [00:24<00:15, 88.4MB/s][A
Downloading 4-gram.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.80G/3.12G [00:24<00:14, 88.3MB/s][A
Downloading 4-gram.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.81G/3.12G [00:25<00:14, 88.5MB/s][A
Downloading 4-gram.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.82G/3.12G [00:25<00:14, 88.2MB/s][A
Downloading 4-gram.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.84G/3.12G [00:25<00:14, 88.2MB/s][A
Downloading 4-gram.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.85G/3.12G [00:25<00:14, 88.4MB/s][A
Downloading 4-gram.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.86G/3.12G [00:25<00:14, 88.4MB/s][A
Downloading 4-gram.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.87G/3.12G [00:25<00:14, 88.1MB/s][A
Downloading 4-gram.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.88G/3.12G [00:25<00:14, 88.2MB/s][A
Downloading 4-gram.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.89G/3.12G [00:25<00:14, 88.3MB/s][A
Downloading 4-gram.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.90G/3.12G [00:26<00:13, 88.4MB/s][A
Downloading 4-gram.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.91G/3.12G [00:26<00:13, 88.2MB/s][A
Downloading 4-gram.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.92G/3.12G [00:26<00:13, 88.2MB/s][A
Downloading 4-gram.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.93G/3.12G [00:26<00:13, 88.2MB/s][A
Downloading 4-gram.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.94G/3.12G [00:26<00:13, 88.3MB/s][A
Downloading 4-gram.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.95G/3.12G [00:26<00:13, 88.3MB/s][A
Downloading 4-gram.bin:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.96G/3.12G [00:26<00:13, 88.4MB/s][A
Downloading 4-gram.bin:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.97G/3.12G [00:27<00:25, 45.5MB/s][A
Downloading 4-gram.bin:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1.98G/3.12G [00:27<00:21, 52.9MB/s][A
Downloading 4-gram.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.99G/3.12G [00:27<00:18, 59.7MB/s][A
Downloading 4-gram.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.00G/3.12G [00:27<00:16, 66.2MB/s][A
Downloading 4-gram.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.01G/3.12G [00:27<00:15, 71.6MB/s][A
Downloading 4-gram.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.02G/3.12G [00:27<00:14, 76.1MB/s][A
Downloading 4-gram.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.03G/3.12G [00:27<00:13, 79.1MB/s][A
Downloading 4-gram.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.04G/3.12G [00:28<00:13, 81.7MB/s][A
Downloading 4-gram.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.06G/3.12G [00:28<00:12, 83.7MB/s][A
Downloading 4-gram.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.07G/3.12G [00:28<00:12, 85.2MB/s][A
Downloading 4-gram.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.08G/3.12G [00:28<00:12, 85.6MB/s][A
Downloading 4-gram.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.09G/3.12G [00:28<00:11, 86.6MB/s][A
Downloading 4-gram.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.10G/3.12G [00:28<00:11, 87.1MB/s][A
Downloading 4-gram.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.11G/3.12G [00:28<00:11, 87.6MB/s][A
Downloading 4-gram.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.12G/3.12G [00:28<00:11, 87.5MB/s][A
Downloading 4-gram.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.13G/3.12G [00:29<00:11, 87.9MB/s][A
Downloading 4-gram.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.14G/3.12G [00:29<00:11, 88.0MB/s][A
Downloading 4-gram.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.15G/3.12G [00:29<00:11, 88.2MB/s][A
Downloading 4-gram.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.16G/3.12G [00:29<00:10, 88.1MB/s][A
Downloading 4-gram.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.17G/3.12G [00:29<00:10, 88.2MB/s][A
Downloading 4-gram.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.18G/3.12G [00:29<00:10, 88.3MB/s][A
Downloading 4-gram.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.19G/3.12G [00:29<00:10, 88.5MB/s][A
Downloading 4-gram.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.20G/3.12G [00:29<00:10, 88.2MB/s][A
Downloading 4-gram.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.21G/3.12G [00:29<00:10, 88.4MB/s][A
Downloading 4-gram.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.22G/3.12G [00:30<00:10, 88.4MB/s][A
Downloading 4-gram.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.23G/3.12G [00:30<00:10, 88.4MB/s][A
Downloading 4-gram.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.24G/3.12G [00:30<00:09, 88.3MB/s][A
Downloading 4-gram.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.25G/3.12G [00:30<00:09, 88.3MB/s][A
Downloading 4-gram.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.26G/3.12G [00:30<00:09, 88.2MB/s][A
Downloading 4-gram.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.28G/3.12G [00:30<00:09, 88.4MB/s][A
Downloading 4-gram.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.29G/3.12G [00:30<00:09, 88.4MB/s][A
Downloading 4-gram.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.30G/3.12G [00:30<00:09, 88.2MB/s][A
Downloading 4-gram.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.31G/3.12G [00:31<00:09, 85.4MB/s][A
Downloading 4-gram.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.32G/3.12G [00:31<00:09, 86.2MB/s][A
Downloading 4-gram.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.33G/3.12G [00:31<00:09, 86.8MB/s][A
Downloading 4-gram.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.34G/3.12G [00:31<00:09, 87.2MB/s][A
Downloading 4-gram.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.35G/3.12G [00:31<00:08, 87.0MB/s][A
Downloading 4-gram.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.36G/3.12G [00:31<00:08, 87.6MB/s][A
Downloading 4-gram.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.37G/3.12G [00:31<00:08, 87.8MB/s][A
Downloading 4-gram.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.38G/3.12G [00:31<00:08, 87.4MB/s][A
Downloading 4-gram.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.39G/3.12G [00:32<00:08, 87.3MB/s][A
Downloading 4-gram.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.40G/3.12G [00:32<00:08, 87.5MB/s][A
Downloading 4-gram.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.41G/3.12G [00:32<00:08, 87.7MB/s][A
Downloading 4-gram.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.42G/3.12G [00:32<00:07, 87.9MB/s][A
Downloading 4-gram.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.43G/3.12G [00:32<00:07, 87.8MB/s][A
Downloading 4-gram.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.44G/3.12G [00:32<00:07, 87.5MB/s][A
Downloading 4-gram.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.45G/3.12G [00:32<00:07, 87.7MB/s][A
Downloading 4-gram.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.46G/3.12G [00:32<00:07, 88.0MB/s][A
Downloading 4-gram.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.47G/3.12G [00:32<00:07, 88.0MB/s][A
Downloading 4-gram.bin:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.49G/3.12G [00:33<00:07, 88.2MB/s][A
Downloading 4-gram.bin:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.50G/3.12G [00:33<00:07, 88.2MB/s][A
Downloading 4-gram.bin:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2.51G/3.12G [00:33<00:07, 88.3MB/s][A
Downloading 4-gram.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2.52G/3.12G [00:33<00:06, 88.3MB/s][A
Downloading 4-gram.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2.53G/3.12G [00:33<00:06, 88.3MB/s][A
Downloading 4-gram.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2.54G/3.12G [00:33<00:06, 88.2MB/s][A
Downloading 4-gram.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.55G/3.12G [00:33<00:06, 88.3MB/s][A
Downloading 4-gram.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.56G/3.12G [00:33<00:06, 88.4MB/s][A
Downloading 4-gram.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.57G/3.12G [00:34<00:06, 88.4MB/s][A
Downloading 4-gram.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2.58G/3.12G [00:34<00:06, 88.2MB/s][A
Downloading 4-gram.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2.59G/3.12G [00:34<00:06, 88.2MB/s][A
Downloading 4-gram.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2.60G/3.12G [00:34<00:05, 88.2MB/s][A
Downloading 4-gram.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2.61G/3.12G [00:34<00:05, 88.3MB/s][A
Downloading 4-gram.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.62G/3.12G [00:34<00:05, 88.3MB/s][A
Downloading 4-gram.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.63G/3.12G [00:34<00:05, 88.4MB/s][A
Downloading 4-gram.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.64G/3.12G [00:34<00:05, 88.2MB/s][A
Downloading 4-gram.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.65G/3.12G [00:34<00:05, 88.3MB/s][A
Downloading 4-gram.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2.66G/3.12G [00:35<00:05, 88.4MB/s][A
Downloading 4-gram.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2.67G/3.12G [00:35<00:05, 88.4MB/s][A
Downloading 4-gram.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2.68G/3.12G [00:35<00:04, 88.3MB/s][A
Downloading 4-gram.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2.69G/3.12G [00:35<00:04, 88.3MB/s][A
Downloading 4-gram.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2.71G/3.12G [00:35<00:04, 88.3MB/s][A
Downloading 4-gram.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2.72G/3.12G [00:35<00:04, 88.3MB/s][A
Downloading 4-gram.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2.73G/3.12G [00:35<00:04, 88.3MB/s][A
Downloading 4-gram.bin:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2.74G/3.12G [00:35<00:04, 88.3MB/s][A
Downloading 4-gram.bin:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2.75G/3.12G [00:36<00:04, 88.3MB/s][A
Downloading 4-gram.bin:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2.76G/3.12G [00:36<00:04, 88.4MB/s][A
Downloading 4-gram.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2.77G/3.12G [00:36<00:04, 88.3MB/s][A
Downloading 4-gram.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2.78G/3.12G [00:36<00:03, 88.4MB/s][A
Downloading 4-gram.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2.79G/3.12G [00:36<00:03, 88.3MB/s][A
Downloading 4-gram.bin:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2.80G/3.12G [00:36<00:03, 88.2MB/s][A
Downloading 4-gram.bin:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2.81G/3.12G [00:36<00:03, 88.0MB/s][A
Downloading 4-gram.bin:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2.82G/3.12G [00:36<00:03, 87.9MB/s][A
Downloading 4-gram.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2.83G/3.12G [00:37<00:03, 88.1MB/s][A
Downloading 4-gram.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2.84G/3.12G [00:37<00:03, 88.2MB/s][A
Downloading 4-gram.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2.85G/3.12G [00:37<00:03, 88.1MB/s][A
Downloading 4-gram.bin:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2.86G/3.12G [00:37<00:02, 88.2MB/s][A
Downloading 4-gram.bin:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2.87G/3.12G [00:37<00:02, 88.3MB/s][A
Downloading 4-gram.bin:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2.88G/3.12G [00:37<00:02, 88.3MB/s][A
Downloading 4-gram.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2.89G/3.12G [00:37<00:02, 88.2MB/s][A
Downloading 4-gram.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2.90G/3.12G [00:37<00:02, 88.3MB/s][A
Downloading 4-gram.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2.92G/3.12G [00:37<00:02, 88.4MB/s][A
Downloading 4-gram.bin:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2.93G/3.12G [00:38<00:02, 88.3MB/s][A
Downloading 4-gram.bin:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2.94G/3.12G [00:38<00:02, 88.2MB/s][A
Downloading 4-gram.bin:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2.95G/3.12G [00:38<00:02, 88.3MB/s][A
Downloading 4-gram.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2.96G/3.12G [00:38<00:01, 88.3MB/s][A
Downloading 4-gram.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2.97G/3.12G [00:38<00:01, 88.3MB/s][A
Downloading 4-gram.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2.98G/3.12G [00:38<00:01, 88.2MB/s][A
Downloading 4-gram.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2.99G/3.12G [00:38<00:01, 88.3MB/s][A
Downloading 4-gram.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.00G/3.12G [00:38<00:01, 88.3MB/s][A
Downloading 4-gram.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.01G/3.12G [00:39<00:01, 88.3MB/s][A
Downloading 4-gram.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.02G/3.12G [00:39<00:01, 88.2MB/s][A
Downloading 4-gram.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.03G/3.12G [00:39<00:01, 88.4MB/s][A
Downloading 4-gram.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.04G/3.12G [00:39<00:00, 88.4MB/s][A
Downloading 4-gram.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.05G/3.12G [00:39<00:00, 88.4MB/s][A
Downloading 4-gram.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.06G/3.12G [00:39<00:00, 88.2MB/s][A
Downloading 4-gram.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.07G/3.12G [00:39<00:00, 88.3MB/s][A
Downloading 4-gram.bin:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.08G/3.12G [00:39<00:00, 88.4MB/s][A
Downloading 4-gram.bin:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.09G/3.12G [00:39<00:00, 88.2MB/s][A
Downloading 4-gram.bin:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.10G/3.12G [00:40<00:00, 88.3MB/s][A
Downloading 4-gram.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.11G/3.12G [00:40<00:00, 88.4MB/s][A
Downloading 4-gram.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.12G/3.12G [00:40<00:00, 88.4MB/s][ADownloading 4-gram.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.12G/3.12G [00:40<00:00, 77.5MB/s]
Fetching 4 files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:42<00:49, 24.88s/it]Fetching 4 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:42<00:00, 10.67s/it]
Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/2.35k [00:00<?, ?B/s]Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.35k/2.35k [00:00<00:00, 20.0MB/s]
Downloading pytorch_model.bin:   0%|          | 0.00/378M [00:00<?, ?B/s]Downloading pytorch_model.bin:   3%|â–Ž         | 10.5M/378M [00:00<00:28, 13.1MB/s]Downloading pytorch_model.bin:   6%|â–Œ         | 21.0M/378M [00:01<00:15, 23.1MB/s]Downloading pytorch_model.bin:   8%|â–Š         | 31.5M/378M [00:01<00:11, 30.8MB/s]Downloading pytorch_model.bin:  11%|â–ˆ         | 41.9M/378M [00:01<00:09, 36.4MB/s]Downloading pytorch_model.bin:  14%|â–ˆâ–        | 52.4M/378M [00:01<00:07, 40.9MB/s]Downloading pytorch_model.bin:  17%|â–ˆâ–‹        | 62.9M/378M [00:01<00:07, 44.7MB/s]Downloading pytorch_model.bin:  19%|â–ˆâ–‰        | 73.4M/378M [00:02<00:06, 47.9MB/s]Downloading pytorch_model.bin:  22%|â–ˆâ–ˆâ–       | 83.9M/378M [00:02<00:05, 50.8MB/s]Downloading pytorch_model.bin:  25%|â–ˆâ–ˆâ–       | 94.4M/378M [00:02<00:05, 53.2MB/s]Downloading pytorch_model.bin:  28%|â–ˆâ–ˆâ–Š       | 105M/378M [00:02<00:04, 55.9MB/s] Downloading pytorch_model.bin:  31%|â–ˆâ–ˆâ–ˆ       | 115M/378M [00:02<00:04, 58.3MB/s]Downloading pytorch_model.bin:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 126M/378M [00:02<00:04, 60.2MB/s]Downloading pytorch_model.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 136M/378M [00:03<00:03, 62.0MB/s]Downloading pytorch_model.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 147M/378M [00:03<00:03, 63.7MB/s]Downloading pytorch_model.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 157M/378M [00:03<00:03, 64.9MB/s]Downloading pytorch_model.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 168M/378M [00:03<00:03, 66.1MB/s]Downloading pytorch_model.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 178M/378M [00:03<00:02, 67.6MB/s]Downloading pytorch_model.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 189M/378M [00:03<00:02, 68.8MB/s]Downloading pytorch_model.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 199M/378M [00:03<00:02, 69.8MB/s]Downloading pytorch_model.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 210M/378M [00:04<00:02, 70.9MB/s]Downloading pytorch_model.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 220M/378M [00:04<00:02, 71.8MB/s]Downloading pytorch_model.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 231M/378M [00:04<00:02, 72.7MB/s]Downloading pytorch_model.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 241M/378M [00:04<00:01, 73.1MB/s]Downloading pytorch_model.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 252M/378M [00:04<00:01, 74.7MB/s]Downloading pytorch_model.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 262M/378M [00:04<00:01, 76.0MB/s]Downloading pytorch_model.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 273M/378M [00:04<00:01, 77.3MB/s]Downloading pytorch_model.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 283M/378M [00:04<00:01, 78.6MB/s]Downloading pytorch_model.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 294M/378M [00:05<00:01, 81.0MB/s]Downloading pytorch_model.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 304M/378M [00:05<00:00, 82.4MB/s]Downloading pytorch_model.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 315M/378M [00:05<00:00, 83.0MB/s]Downloading pytorch_model.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 325M/378M [00:05<00:00, 84.6MB/s]Downloading pytorch_model.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 336M/378M [00:05<00:00, 85.8MB/s]Downloading pytorch_model.bin:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 346M/378M [00:05<00:00, 86.8MB/s]Downloading pytorch_model.bin:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 357M/378M [00:05<00:00, 86.9MB/s]Downloading pytorch_model.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 367M/378M [00:05<00:00, 87.6MB/s]Downloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 377M/378M [00:06<00:00, 88.0MB/s]Downloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 378M/378M [00:06<00:00, 62.1MB/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:01<?, ? examples/s]                                                  Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 795, in <module>
    results = data["test"].map(map_to_result)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 781, in map_to_result
    logits_LM_1 = model_LM_1(input_values_LM_1).logits
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1684, in forward
    outputs = self.wav2vec2(
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1306, in forward
    extract_features = self.feature_extractor(input_values)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 453, in forward
    hidden_states = conv_layer(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 353, in forward
    hidden_states = self.conv(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
Fri Jul 28 01:07:50 AEST 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py
Started: 28/07/2023 01:07:50

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230727_2
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718_with_lm_3
Language model 2: patrickvonplaten/wav2vec2-base-100h-with-lm
wright_model_1: 0.15
wright_model_2: 0.85
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230727_2_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230727_2
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230727_2_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230727_2_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 495.05it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b37eb1ea19f9e255.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-45f3f0ec11a0e7da.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-38777acb7ebf1f80_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-4dee1081e471f7cd_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-52e325084870d91b_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-c603dc6577907dbb_*_of_00004.arrow
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py:613: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 and he was looking at the dinosaur
1  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  he's curious to see what's inside the egg and ...
2  /srv/scratch/chacmod/auskidtalk_spontaneous/81...                   hulk feeds the dinosaur the milk
3  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the egg starts cracking near the top and hulk ...
4  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                           he was on the skateboard
5  /srv/scratch/chacmod/auskidtalk_spontaneous/81...   laughing while the dinosuar is drinking the milk
6  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur tries to play with hulk but hulk ...
7  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                        he was listening to the egg
8  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                    and the dinosaur was lying down
9  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                  and he feed the dinosaur his milk
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: THE DINOSAUR WAS ABOUT TO LICK HIM
Input array shape: (51241,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 836.98it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:01<?, ? examples/s]                                                  Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 795, in <module>
    results = data["test"].map(map_to_result)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 781, in map_to_result
    logits_LM_1 = model_LM_1(input_values_LM_1).logits
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1684, in forward
    outputs = self.wav2vec2(
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1306, in forward
    extract_features = self.feature_extractor(input_values)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 453, in forward
    hidden_states = conv_layer(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 353, in forward
    hidden_states = self.conv(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
Fri Jul 28 01:15:25 AEST 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py
Started: 28/07/2023 01:15:25

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230727_2
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718_with_lm_3
Language model 2: patrickvonplaten/wav2vec2-base-100h-with-lm
wright_model_1: 0.15
wright_model_2: 0.85
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230727_2_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230727_2
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230727_2_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230727_2_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 557.35it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b37eb1ea19f9e255.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-45f3f0ec11a0e7da.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-38777acb7ebf1f80_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-4dee1081e471f7cd_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-52e325084870d91b_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-c603dc6577907dbb_*_of_00004.arrow
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py:613: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                                      he was hiding
1  /srv/scratch/chacmod/auskidtalk_spontaneous/81...                                the dinosaur is sad
2  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur tries to play with hulk but hulk ...
3  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                               there was a dinosaur
4  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                               the egg was cracking
5  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                               the dinosaur was sad
6  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                    the dinosaur poked out his head
7  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 the dinosaur was about to lick him
8  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                       he was touching the dinosaur
9  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                           he was on the skateboard
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: HE'S CURIOUS TO SEE WHAT'S INSIDE THE EGG AND LISTENS TO THE EGG
Input array shape: (61623,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 1650.16it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 795, in <module>
    results = data["test"].map(map_to_result)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 781, in map_to_result
    logits_LM_1 = model_LM_1(**input_values_LM_1).logits
TypeError: Wav2Vec2ForCTC(
  (wav2vec2): Wav2Vec2Model(
    (feature_extractor): Wav2Vec2FeatureEncoder(
      (conv_layers): ModuleList(
        (0): Wav2Vec2GroupNormConvLayer(
          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
          (activation): GELUActivation()
          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)
        )
        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(
          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
          (activation): GELUActivation()
        )
        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(
          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
          (activation): GELUActivation()
        )
      )
    )
    (feature_projection): Wav2Vec2FeatureProjection(
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (projection): Linear(in_features=512, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder): Wav2Vec2Encoder(
      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(
        (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
        (padding): Wav2Vec2SamePadLayer()
        (activation): GELUActivation()
      )
      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (layers): ModuleList(
        (0-11): 12 x Wav2Vec2EncoderLayer(
          (attention): Wav2Vec2Attention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (feed_forward): Wav2Vec2FeedForward(
            (intermediate_dropout): Dropout(p=0.1, inplace=False)
            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
            (output_dense): Linear(in_features=3072, out_features=768, bias=True)
            (output_dropout): Dropout(p=0.1, inplace=False)
          )
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (dropout): Dropout(p=0.0, inplace=False)
  (lm_head): Linear(in_features=768, out_features=32, bias=True)
) argument after ** must be a mapping, not Tensor
Fri Jul 28 01:19:55 AEST 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py
Started: 28/07/2023 01:19:55

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230727_2
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718_with_lm_3
Language model 2: patrickvonplaten/wav2vec2-base-100h-with-lm
wright_model_1: 0.15
wright_model_2: 0.85
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230727_2_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230727_2
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230727_2_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230727_2_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 413.46it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b37eb1ea19f9e255.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-45f3f0ec11a0e7da.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-38777acb7ebf1f80_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-4dee1081e471f7cd_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-52e325084870d91b_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-c603dc6577907dbb_*_of_00004.arrow
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py:613: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/81...                                the dinosaur is sad
1  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk was riding backwards on a skateboard and ...
2  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                               the dinosaur was sad
3  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                       he was touching the dinosaur
4  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur tries to play with hulk but hulk ...
5  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  he's curious to see what's inside the egg and ...
6  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                    the dinosaur poked out his head
7  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                    and the dinosaur was lying down
8  /srv/scratch/chacmod/auskidtalk_spontaneous/81...   laughing while the dinosuar is drinking the milk
9  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                                      he was hiding
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: HE WAS ON THE SKATEBOARD
Input array shape: (48233,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 1479.08it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 795, in <module>
    results = data["test"].map(map_to_result)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 781, in map_to_result
    logits_LM_1 = model_LM_1(input_values).logits
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1684, in forward
    outputs = self.wav2vec2(
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1306, in forward
    extract_features = self.feature_extractor(input_values)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 453, in forward
    hidden_states = conv_layer(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 353, in forward
    hidden_states = self.conv(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
Fri Jul 28 01:33:24 AEST 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py
Started: 28/07/2023 01:33:25

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230727_2
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718_with_lm_3
Language model 2: patrickvonplaten/wav2vec2-base-100h-with-lm
wright_model_1: 0.15
wright_model_2: 0.85
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230727_2_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230727_2
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230727_2_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230727_2_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 250.06it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b37eb1ea19f9e255.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-45f3f0ec11a0e7da.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-38777acb7ebf1f80_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-4dee1081e471f7cd_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-52e325084870d91b_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-c603dc6577907dbb_*_of_00004.arrow
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py:613: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                                  and then he laugh
1  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 the dinosaur was about to lick him
2  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                        he was listening to the egg
3  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk tries to hide from the dinosaur and is st...
4  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                  and he feed the dinosaur his milk
5  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 and he was looking at the dinosaur
6  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur is looking around for hulk and he...
7  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the egg starts cracking near the top and hulk ...
8  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                           he was on the skateboard
9  /srv/scratch/chacmod/auskidtalk_spontaneous/81...   laughing while the dinosuar is drinking the milk
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: AND THEN HE LAUGH
Input array shape: (27790,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 402.75it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:01<?, ? examples/s]                                                  Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 795, in <module>
    results = data["test"].map(map_to_result)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 781, in map_to_result
    logits_LM_1 = model_LM_1(input_values_LM_1).logits.to("cuda")
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1684, in forward
    outputs = self.wav2vec2(
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1306, in forward
    extract_features = self.feature_extractor(input_values)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 453, in forward
    hidden_states = conv_layer(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 353, in forward
    hidden_states = self.conv(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
Fri Jul 28 01:39:48 AEST 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py
Started: 28/07/2023 01:39:49

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230727_2
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718_with_lm_3
Language model 2: patrickvonplaten/wav2vec2-base-100h-with-lm
wright_model_1: 0.15
wright_model_2: 0.85
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230727_2_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230727_2
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230727_2_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230727_2_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 505.92it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b37eb1ea19f9e255.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-45f3f0ec11a0e7da.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-38777acb7ebf1f80_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-4dee1081e471f7cd_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-52e325084870d91b_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-c603dc6577907dbb_*_of_00004.arrow
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py:613: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur is looking around for hulk and he...
1  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                    the dinosaur poked out his head
2  /srv/scratch/chacmod/auskidtalk_spontaneous/81...                   hulk feeds the dinosaur the milk
3  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                                  and then he laugh
4  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                       he was touching the dinosaur
5  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 the dinosaur was about to lick him
6  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                                      he was hiding
7  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur tries to play with hulk but hulk ...
8  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk tries to hide from the dinosaur and is st...
9  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the egg starts cracking near the top and hulk ...
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: AND HE WAS LOOKING AT THE DINOSAUR
Input array shape: (56157,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.20it/s]Fetching 4 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.39it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 798, in <module>
    results = data["test"].map(map_to_result)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 781, in map_to_result
    logits_LM_1 = model_LM_1(input_values_LM_1).logits
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1684, in forward
    outputs = self.wav2vec2(
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1306, in forward
    extract_features = self.feature_extractor(input_values)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 453, in forward
    hidden_states = conv_layer(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 353, in forward
    hidden_states = self.conv(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
Fri Jul 28 01:51:08 AEST 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py
Started: 28/07/2023 01:51:08

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230727_2
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718_with_lm_3
Language model 2: patrickvonplaten/wav2vec2-base-100h-with-lm
wright_model_1: 0.15
wright_model_2: 0.85
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230727_2_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230727_2
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230727_2_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230727_2_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 447.03it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b37eb1ea19f9e255.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-45f3f0ec11a0e7da.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-38777acb7ebf1f80_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-4dee1081e471f7cd_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-52e325084870d91b_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-c603dc6577907dbb_*_of_00004.arrow
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py:613: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                               the dinosaur was sad
1  /srv/scratch/chacmod/auskidtalk_spontaneous/81...            a dinosaur jumps out and hulk is scared
2  /srv/scratch/chacmod/auskidtalk_spontaneous/81...   laughing while the dinosuar is drinking the milk
3  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 the dinosaur was about to lick him
4  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk looks at the dinosaur and feels bad about...
5  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                                      he was hiding
6  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                  and he feed the dinosaur his milk
7  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                           he was on the skateboard
8  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur is looking around for hulk and he...
9  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk tries to hide from the dinosaur and is st...
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: THE DINOSAUR IS SAD
Input array shape: (26798,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 175.39it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 798, in <module>
    results = data["test"].map(map_to_result)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py", line 781, in map_to_result
    logits_LM_1 = model_LM_1(input_values_LM_1).logits
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1684, in forward
    outputs = self.wav2vec2(
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1306, in forward
    extract_features = self.feature_extractor(input_values)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 453, in forward
    hidden_states = conv_layer(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 353, in forward
    hidden_states = self.conv(hidden_states)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/z5313567/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
Fri Jul 28 01:52:07 AEST 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py
Started: 28/07/2023 01:52:07

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230727_2
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718_with_lm_3
Language model 2: patrickvonplaten/wav2vec2-base-100h-with-lm
wright_model_1: 0.15
wright_model_2: 0.85
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230727_2_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230727_2
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230727_2_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230727_2_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 253.75it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b37eb1ea19f9e255.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-45f3f0ec11a0e7da.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-38777acb7ebf1f80_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-4dee1081e471f7cd_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-52e325084870d91b_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-c29da4653c6396a5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-c603dc6577907dbb_*_of_00004.arrow
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_2.py:613: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the egg starts cracking near the top and hulk ...
1  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                                      he was hiding
2  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk was riding backwards on a skateboard and ...
3  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  he's curious to see what's inside the egg and ...
4  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                  and he feed the dinosaur his milk
5  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 the dinosaur was about to lick him
6  /srv/scratch/chacmod/auskidtalk_spontaneous/81...   laughing while the dinosuar is drinking the milk
7  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur tries to play with hulk but hulk ...
8  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                       he was touching the dinosaur
9  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur is looking around for hulk and he...
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: THE DINOSAUR WAS SAD
Input array shape: (59403,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 694.85it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   4%|â–         | 1/24 [00:01<00:31,  1.39s/ examples]Map:   8%|â–Š         | 2/24 [00:01<00:14,  1.57 examples/s]Map:  12%|â–ˆâ–Ž        | 3/24 [00:01<00:08,  2.51 examples/s]Map:  21%|â–ˆâ–ˆ        | 5/24 [00:01<00:04,  4.75 examples/s]Map:  29%|â–ˆâ–ˆâ–‰       | 7/24 [00:01<00:02,  6.56 examples/s]Map:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:02<00:01,  8.27 examples/s]Map:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:02<00:01, 10.58 examples/s]Map:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:02<00:00, 10.89 examples/s]Map:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:02<00:00, 12.22 examples/s]Map:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:02<00:00, 12.81 examples/s]Map:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:02<00:00, 13.40 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00, 13.96 examples/s]                                                           Saved results to: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230727_2_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER Without Language Model: 0.691
Fine-tuned Test WER With Language Model: 0.590
--> Showing some fine-tuned prediction errors...
                                         target_text  ...                                   pred_str_with_LM
0                    AND THE DINOSAUR WAS LYING DOWN  ...                          AND THE DASA WA FRAN DOWN
1                               THERE WAS A DINOSAUR  ...                                THE HA WAT AT DISTO
2                           HE WAS ON THE SKATEBOARD  ...                                 WUFN THE GATE BOET
3  HULK WAS RIDING BACKWARDS ON A SKATEBOARD AND ...  ...  HOK WAS RIDING BACKWARDS ON THE SCAEBORD AND H...
4                 AND HE WAS LOOKING AT THE DINOSAUR  ...               AD HE WAS FLOOKING AT THE DYN IS SOP
5                  AND HE FEED THE DINOSAUR HIS MILK  ...                         UNHAFAT THE DIN FELLI S OK
6   LAUGHING WHILE THE DINOSUAR IS DRINKING THE MILK  ...   LAUGHING WHILE THE DINASOUR IS DRINKING THE MILK
7                 THE DINOSAUR WAS ABOUT TO LICK HIM  ...                        TO DIN SO WAV ABOT O LAK IM
8                   HULK FEEDS THE DINOSAUR THE MILK  ...                  HOWFEETS THO DINAS SWORD THE MILK
9            A DINOSAUR JUMPS OUT AND HULK IS SCARED  ...                I DIN SOR DRUMPS OUT AND HALIS SKID

[10 rows x 3 columns]
--> Taking a deeper look...
<pad> <pad> P <pad> <pad> <pad> <pad> <pad> <pad> E E <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> Y Y <pad> K K <pad> <pad> <pad> <pad> W W W <pad> <pad> A <pad> <pad> <pad> <pad> <pad> S S S | | | | O O O <pad> <pad> <pad> N N N | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> T T H H E O S S S S <pad> <pad> <pad> <pad> <pad> <pad> <pad> K K <pad> A A <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> T T E E E | B B <pad> <pad> <pad> O O O A A R R R R <pad> <pad> <pad> <pad> <pad> <pad> D D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 