Wed Jul 12 01:22:46 AEST 2023
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_AusKidTalk_spontaneous.py
Started: 12/07/2023 01:22:46

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: False
base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230711_4
cache_name: AusKidTalk-eval
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/finetune_20230708_2
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/finetune_20230708_2
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_spontaneous_1050_1150_1075_228_task3_test.csv
--> data_test_fp: //srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_spontaneous_1050_1150_1075_228_task3_test.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230711_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230711_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230711_4_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230711_4_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/finetune_20230708_2
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

Downloading and preparing dataset csv/default to /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-b0d4d13add1e6583/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...
Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 14027.77it/s]
Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 49.22it/s]
Generating train split: 0 examples [00:00, ? examples/s]                                                        Generating test split: 0 examples [00:00, ? examples/s]                                                       Dataset csv downloaded and prepared to /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-b0d4d13add1e6583/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 292.10it/s]
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 61
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 61
    })
})
--> Printing some random samples...
                                            filepath                          transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/11...   and went up to baby hawk but he was scared
1  /srv/scratch/chacmod/auskidtalk_spontaneous/10...      the boy is pet the dinosaur on the head
2  /srv/scratch/chacmod/auskidtalk_spontaneous/22...  and so he went over and petted the dinosaur
3  /srv/scratch/chacmod/auskidtalk_spontaneous/11...                          and then he was sad
4  /srv/scratch/chacmod/auskidtalk_spontaneous/10...          the boy touches in the dinosaur egg
5  /srv/scratch/chacmod/auskidtalk_spontaneous/22...                 and the egg started hatching
6  /srv/scratch/chacmod/auskidtalk_spontaneous/10...   the boy give his bottle of tea to dinosaur
7  /srv/scratch/chacmod/auskidtalk_spontaneous/22...         and he ran and hid from the dinosaur
8  /srv/scratch/chacmod/auskidtalk_spontaneous/22...                               he was shocked
9  /srv/scratch/chacmod/auskidtalk_spontaneous/11...                     the egg started cracking
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------

Map:   0%|          | 0/61 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/61 [00:00<?, ? examples/s]                                                  
------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Map (num_proc=4):   0%|          | 0/61 [00:00<?, ? examples/s]/srv/scratch/z5313567/thesis/wav2vec2/code/eval_AusKidTalk_spontaneous.py:470: UserWarning: PySoundFile failed. Trying audioread instead.
  speech_array, sampling_rate = librosa.load(batch['filepath'], sr=feature_extractor.sampling_rate)
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_AusKidTalk_spontaneous.py:470: UserWarning: PySoundFile failed. Trying audioread instead.
  speech_array, sampling_rate = librosa.load(batch['filepath'], sr=feature_extractor.sampling_rate)
/home/z5313567/.local/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load
	Deprecated as of librosa version 0.10.0.
	It will be removed in librosa version 1.0.
  y, sr_native = __audioread_load(path, offset, duration, dtype)
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_AusKidTalk_spontaneous.py:470: UserWarning: PySoundFile failed. Trying audioread instead.
  speech_array, sampling_rate = librosa.load(batch['filepath'], sr=feature_extractor.sampling_rate)
/home/z5313567/.local/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load
	Deprecated as of librosa version 0.10.0.
	It will be removed in librosa version 1.0.
  y, sr_native = __audioread_load(path, offset, duration, dtype)
/home/z5313567/.local/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load
	Deprecated as of librosa version 0.10.0.
	It will be removed in librosa version 1.0.
  y, sr_native = __audioread_load(path, offset, duration, dtype)
Map (num_proc=4):   0%|          | 0/61 [00:01<?, ? examples/s]Map (num_proc=4):   2%|▏         | 1/61 [00:01<00:15,  3.92 examples/s]Map (num_proc=4):  10%|▉         | 6/61 [00:01<00:03, 17.70 examples/s]Map (num_proc=4):  21%|██▏       | 13/61 [00:01<00:01, 32.84 examples/s]/srv/scratch/z5313567/thesis/wav2vec2/code/eval_AusKidTalk_spontaneous.py:470: UserWarning: PySoundFile failed. Trying audioread instead.
  speech_array, sampling_rate = librosa.load(batch['filepath'], sr=feature_extractor.sampling_rate)
/home/z5313567/.local/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load
	Deprecated as of librosa version 0.10.0.
	It will be removed in librosa version 1.0.
  y, sr_native = __audioread_load(path, offset, duration, dtype)
                                                                        multiprocess.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/z5313567/.local/lib/python3.10/site-packages/librosa/core/audio.py", line 176, in load
    y, sr_native = __soundfile_load(path, offset, duration, dtype)
  File "/home/z5313567/.local/lib/python3.10/site-packages/librosa/core/audio.py", line 209, in __soundfile_load
    context = sf.SoundFile(path)
  File "/home/z5313567/.local/lib/python3.10/site-packages/soundfile.py", line 658, in __init__
    self._file = self._open(file, mode_int, closefd)
  File "/home/z5313567/.local/lib/python3.10/site-packages/soundfile.py", line 1216, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening '/srv/scratch/chacmod/auskidtalk_spontaneous/1075_task3_1.wav': System error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/z5313567/.local/lib/python3.10/site-packages/multiprocess/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 1353, in _write_generator_to_queue
    for i, result in enumerate(func(**kwargs)):
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3427, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3330, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_AusKidTalk_spontaneous.py", line 470, in speech_file_to_array_fn
    speech_array, sampling_rate = librosa.load(batch['filepath'], sr=feature_extractor.sampling_rate)
  File "/home/z5313567/.local/lib/python3.10/site-packages/librosa/core/audio.py", line 184, in load
    y, sr_native = __audioread_load(path, offset, duration, dtype)
  File "/home/z5313567/anaconda3/envs/py3.10/lib/python3.10/site-packages/decorator.py", line 232, in fun
    return caller(func, *(extras + args), **kw)
  File "/home/z5313567/.local/lib/python3.10/site-packages/librosa/util/decorators.py", line 60, in __wrapper
    return func(*args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/librosa/core/audio.py", line 241, in __audioread_load
    reader = audioread.audio_open(path)
  File "/home/z5313567/.local/lib/python3.10/site-packages/audioread/__init__.py", line 127, in audio_open
    return BackendClass(path)
  File "/home/z5313567/.local/lib/python3.10/site-packages/audioread/rawread.py", line 59, in __init__
    self._fh = open(filename, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: '/srv/scratch/chacmod/auskidtalk_spontaneous/1075_task3_1.wav'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/srv/scratch/z5313567/thesis/wav2vec2/code/eval_AusKidTalk_spontaneous.py", line 477, in <module>
    data = data.map(speech_file_to_array_fn, remove_columns=data.column_names["train"], num_proc=4)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/dataset_dict.py", line 851, in map
    {
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/dataset_dict.py", line 852, in <dictcomp>
    k: dataset.map(
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 578, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 543, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3166, in map
    for rank, done, content in iflatmap_unordered(
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 1379, in iflatmap_unordered
    [async_result.get(timeout=0.05) for async_result in async_results]
  File "/home/z5313567/.local/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 1379, in <listcomp>
    [async_result.get(timeout=0.05) for async_result in async_results]
  File "/home/z5313567/.local/lib/python3.10/site-packages/multiprocess/pool.py", line 774, in get
    raise self._value
FileNotFoundError: [Errno 2] No such file or directory: '/srv/scratch/chacmod/auskidtalk_spontaneous/1075_task3_1.wav'
Wed Jul 12 02:09:18 AEST 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-b0d4d13add1e6583/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_AusKidTalk_spontaneous.py
Started: 12/07/2023 02:09:18

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

training: False
base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_20230711_4
cache_name: AusKidTalk-eval
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/finetune_20230708_2
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/finetune_20230708_2
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_spontaneous_1050_1150_1075_228_task3_test.csv
--> data_test_fp: //srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_spontaneous_1050_1150_1075_228_task3_test.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_20230711_4_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_20230711_4
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_20230711_4_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230711_4_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/finetune_20230708_2
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 347.51it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-b0d4d13add1e6583/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-8617649bcd0f4fe4.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-b0d4d13add1e6583/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-2fb515bfc6d6c152.arrow
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 61
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 61
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/10...  the green baby stuffs his bowl of milk into th...
1  /srv/scratch/chacmod/auskidtalk_spontaneous/22...  but the dinosaur looked around and then he got...
2  /srv/scratch/chacmod/auskidtalk_spontaneous/11...         and went up to baby hawk but he was scared
3  /srv/scratch/chacmod/auskidtalk_spontaneous/22...                        and then the boy felt sorry
4  /srv/scratch/chacmod/auskidtalk_spontaneous/10...  bouncing off the dinosaur egg holding the bott...
5  /srv/scratch/chacmod/auskidtalk_spontaneous/22...       then he listened to the egg when he fell off
6  /srv/scratch/chacmod/auskidtalk_spontaneous/22...  and then the dinosaur just were hopped out of ...
7  /srv/scratch/chacmod/auskidtalk_spontaneous/22...  so the dinosaur cuz he thought the dinosaur wo...
8  /srv/scratch/chacmod/auskidtalk_spontaneous/22...                  because the dinosaur looked funny
9  /srv/scratch/chacmod/auskidtalk_spontaneous/10...  the green baby is holding the bottle of milk w...
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Map (num_proc=4):   0%|          | 0/61 [00:00<?, ? examples/s]Map (num_proc=4):   2%|▏         | 1/61 [00:01<01:05,  1.10s/ examples]Map (num_proc=4):  28%|██▊       | 17/61 [00:01<00:02, 18.52 examples/s]Map (num_proc=4):  62%|██████▏   | 38/61 [00:01<00:00, 43.91 examples/s]                                                                        Map (num_proc=4):   0%|          | 0/61 [00:00<?, ? examples/s]Map (num_proc=4):   2%|▏         | 1/61 [00:00<00:49,  1.21 examples/s]Map (num_proc=4): 100%|██████████| 61/61 [00:00<00:00, 86.87 examples/s]                                                                        --> Verifying data with a random sample...
Target text: BUT THE DINOSAUR LOOKED AROUND AND THEN HE GOT SAD THAT THE GUY LEFT
Input array shape: (69951,)
Sampling rate: 16000
Map (num_proc=4):   0%|          | 0/61 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  13%|█▎        | 8/61 [00:00<00:01, 49.37 examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  51%|█████     | 31/61 [00:00<00:00, 130.53 examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  87%|████████▋ | 53/61 [00:00<00:00, 165.76 examples/s]                                                                         Map (num_proc=4):   0%|          | 0/61 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  13%|█▎        | 8/61 [00:00<00:01, 49.25 examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  51%|█████     | 31/61 [00:00<00:00, 129.79 examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  87%|████████▋ | 53/61 [00:00<00:00, 151.06 examples/s]                                                                         /srv/scratch/z5313567/thesis/wav2vec2/code/eval_AusKidTalk_spontaneous.py:599: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Map:   0%|          | 0/61 [00:00<?, ? examples/s]Map:   2%|▏         | 1/61 [00:01<01:21,  1.36s/ examples]Map:   7%|▋         | 4/61 [00:01<00:16,  3.37 examples/s]Map:  10%|▉         | 6/61 [00:01<00:10,  5.07 examples/s]Map:  15%|█▍        | 9/61 [00:01<00:06,  7.86 examples/s]Map:  21%|██▏       | 13/61 [00:01<00:04, 11.30 examples/s]Map:  28%|██▊       | 17/61 [00:02<00:03, 14.28 examples/s]Map:  34%|███▍      | 21/61 [00:02<00:02, 15.62 examples/s]Map:  41%|████      | 25/61 [00:02<00:02, 17.63 examples/s]Map:  48%|████▊     | 29/61 [00:02<00:01, 19.99 examples/s]Map:  54%|█████▍    | 33/61 [00:02<00:01, 21.42 examples/s]Map:  61%|██████    | 37/61 [00:03<00:01, 22.66 examples/s]Map:  67%|██████▋   | 41/61 [00:03<00:00, 24.48 examples/s]Map:  74%|███████▍  | 45/61 [00:03<00:00, 26.31 examples/s]Map:  80%|████████  | 49/61 [00:03<00:00, 23.51 examples/s]Map:  87%|████████▋ | 53/61 [00:03<00:00, 23.56 examples/s]Map:  92%|█████████▏| 56/61 [00:03<00:00, 24.60 examples/s]Map:  98%|█████████▊| 60/61 [00:03<00:00, 26.35 examples/s]                                                           Saved results to: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_20230711_4_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER: 0.945
--> Showing some fine-tuned prediction errors...
                                         target_text                                           pred_str
0          HE CRASHES INTO THE EGG, THE DINOSAUR EGG                        HILCARTO TWO THE EGGSTETUMO
1  THE GREEN BABY IS HOLDING THE BOTTLE OF MILK A...       GREEN BEBE OBALLMELKOHIDEHNOTRY FROMDINOSAUR
2                           THE GREEN SKINED BABY IS                               THEGRHANSCUBETE EARS
3             SCARED AND WORRIED AND HE WAS CONFUSED                                    SKERTBHIPCOCUSE
4                  THE DINOSAUR EGG IS CRACKING OPEN                              THEDINOSAUREGISCROPEN
5                       THE BOY SNARE A DINOSAUR EGG                                 BOY ERODONOSAR EGG
6                           THE BOY IS ON SKATEBOARD                                        HBOYSC CORD
7   THE GREEN DINOSAUR IS LOOKING FOR THE GREEN BABY                        GRENDINOSAUROSLOCINGFOGETTI
8  THE GREEN BABY IS HOLDING THE BOTTLE OF MILK W...  TH GREENE BEY HOONGBALLLERGREEN DINOSAUR OOTOE...
9                       AND THE EGG STARTED HATCHING                                    ETHEEGGSATOMATO
--> Taking a deeper look...
<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> T T H H <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> E E E E <pad> | | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> G <pad> <pad> <pad> R R <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> E <pad> N N <pad> <pad> | | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> S <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> A <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> B <pad> <pad> <pad> <pad> <pad> <pad> <pad> A A <pad> <pad> <pad> B B <pad> <pad> <pad> <pad> I Y <pad> | | | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> E E E E E R R R <pad> <pad> <pad> S S S <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> R R <pad> <pad> <pad> <pad> <pad> <pad> I I I <pad> D <pad> <pad> <pad> I N G | | <pad> <pad> <pad> O <pad> <pad> <pad> <pad> <pad> <pad> <pad> S <pad> <pad> <pad> <pad> <pad> C <pad> <pad> <pad> O <pad> P P E <pad> <pad> <pad> <pad> <pad> <pad> B <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> O O R R <pad> <pad> <pad> <pad> <pad> <pad> <pad> H H H <pad> <pad> <pad> <pad> O <pad> <pad> L L <pad> <pad> <pad> <pad> N <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> B <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> M M <pad> I I L L L K <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 12/07/2023 02:09:42
