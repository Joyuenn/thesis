Thu Oct 19 06:29:44 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-02e670ef97401bb4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_lowercase_4.py
Started: 19/10/2023 06:29:44

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing jiwer...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_AusKidTalk_spontaneous_full_20231019_5
cache_name: AusKidTalk-eval
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/CU/finetune_CU_lowercase_20230914_with_lm_AusKidTalk_LM_combined_lowercase_v1
Language model 1: /srv/scratch/z5313567/thesis/wav2vec2/model/CU/finetune_CU_lowercase_20230914_with_lm_AusKidTalk_LM_combined_lowercase_v2
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/finetune_AusKidTalk_scripted_lowercase_freeze_base_model_20231017
use_pretrained_tokenizer: True
pretrained_tokenizer: /srv/scratch/z5313567/thesis/wav2vec2/model/OGI_American/full/full_model_OGI_American_20230702
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/finetune_AusKidTalk_scripted_lowercase_freeze_base_model_20231017
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/AusKidTalk_test.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous_v2/AusKidTalk_spontaneous_dataframe_combined_only_transcription_filepath_v2.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> model_cache_fp: /srv/scratch/z5313567/thesis/cache
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_AusKidTalk_spontaneous_full_20231019_5_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_AusKidTalk_spontaneous_full_20231019_5
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_AusKidTalk_spontaneous_full_20231019_5_baseline_result.csv
--> baseline_alignment_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_AusKidTalk_spontaneous_full_20231019_5_baseline_result.txt
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_full_20231019_5_finetuned_result.csv
--> finetuned_alignment_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_full_20231019_5_finetuned_result.txt
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/finetune_AusKidTalk_scripted_lowercase_freeze_base_model_20231017
--> pretrained_tokenizer: /srv/scratch/z5313567/thesis/wav2vec2/model/OGI_American/full/full_model_OGI_American_20230702

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 222.46it/s]
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 10
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 152
    })
})
--> Printing some random samples...
                                            filepath                transcription_clean
0  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
1  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
2  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
3  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
4  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
5  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
6  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
7  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
8  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
9  /srv/scratch/chacmod/CU_2/corpus/data/train-pa...  BI BUBBLES BIG WHY ARE SOME SMALL
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------

Map:   0%|          | 0/10 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/152 [00:00<?, ? examples/s]                                                   Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Map (num_proc=4):   0%|          | 0/10 [00:00<?, ? examples/s]Map (num_proc=4):  10%|█         | 1/10 [00:01<00:15,  1.69s/ examples]                                                                       Map (num_proc=4):   0%|          | 0/152 [00:00<?, ? examples/s]Map (num_proc=4):   1%|          | 1/152 [00:00<02:29,  1.01 examples/s]Map (num_proc=4):  30%|███       | 46/152 [00:01<00:01, 57.64 examples/s]Map (num_proc=4):  73%|███████▎  | 111/152 [00:01<00:00, 146.19 examples/s]                                                                           --> Verifying data with a random sample...
Target text: bi bubbles big why are some small
Input array shape: (46881,)
Sampling rate: 16000
Map (num_proc=4):   0%|          | 0/10 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4): 100%|██████████| 10/10 [00:00<00:00, 85.39 examples/s]                                                                        Map (num_proc=4):   0%|          | 0/152 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):   5%|▌         | 8/152 [00:00<00:02, 59.67 examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  16%|█▌        | 24/152 [00:00<00:01, 106.06 examples/s]Map (num_proc=4):  26%|██▋       | 40/152 [00:00<00:00, 127.09 examples/s]Map (num_proc=4):  37%|███▋      | 56/152 [00:00<00:00, 133.90 examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  58%|█████▊    | 88/152 [00:00<00:00, 153.85 examples/s]Map (num_proc=4):  72%|███████▏  | 110/152 [00:00<00:00, 165.46 examples/s]Map (num_proc=4):  87%|████████▋ | 132/152 [00:00<00:00, 158.12 examples/s]Map (num_proc=4): 100%|██████████| 152/152 [00:01<00:00, 101.82 examples/s]                                                                           /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM_lowercase_4.py:556: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Map:   0%|          | 0/152 [00:00<?, ? examples/s]Map:   1%|          | 1/152 [00:57<2:25:18, 57.74s/ examples]Map:   1%|▏         | 2/152 [01:00<1:03:35, 25.44s/ examples]Map:   2%|▏         | 3/152 [01:02<36:02, 14.51s/ examples]  Map:   3%|▎         | 4/152 [01:03<23:11,  9.40s/ examples]Map:   3%|▎         | 5/152 [01:05<16:00,  6.54s/ examples]Map:   4%|▍         | 6/152 [01:06<11:46,  4.84s/ examples]Map:   5%|▍         | 7/152 [01:08<09:13,  3.82s/ examples]Map:   5%|▌         | 8/152 [01:10<07:38,  3.18s/ examples]Map:   6%|▌         | 9/152 [01:11<06:23,  2.68s/ examples]Map:   7%|▋         | 10/152 [01:13<05:31,  2.34s/ examples]Map:   7%|▋         | 11/152 [01:15<05:04,  2.16s/ examples]Map:   8%|▊         | 12/152 [01:16<04:46,  2.05s/ examples]Map:   9%|▊         | 13/152 [01:18<04:43,  2.04s/ examples]Map:   9%|▉         | 14/152 [01:20<04:27,  1.94s/ examples]Map:  10%|▉         | 15/152 [01:22<04:20,  1.90s/ examples]Map:  11%|█         | 16/152 [01:25<04:50,  2.14s/ examples]Map:  11%|█         | 17/152 [01:27<04:54,  2.18s/ examples]Map:  12%|█▏        | 18/152 [01:29<04:56,  2.21s/ examples]Map:  12%|█▎        | 19/152 [01:32<05:01,  2.27s/ examples]Map:  13%|█▎        | 20/152 [01:37<06:57,  3.17s/ examples]Map:  14%|█▍        | 21/152 [01:39<06:06,  2.80s/ examples]Map:  14%|█▍        | 22/152 [01:41<05:41,  2.62s/ examples]Map:  15%|█▌        | 23/152 [01:43<05:14,  2.43s/ examples]Map:  16%|█▌        | 24/152 [01:45<04:49,  2.27s/ examples]Map:  16%|█▋        | 25/152 [01:47<04:28,  2.11s/ examples]Map:  17%|█▋        | 26/152 [01:48<04:10,  1.99s/ examples]Map:  18%|█▊        | 27/152 [01:50<04:07,  1.98s/ examples]Map:  18%|█▊        | 28/152 [01:57<06:58,  3.37s/ examples]Map:  19%|█▉        | 29/152 [01:59<06:19,  3.08s/ examples]Map:  20%|█▉        | 30/152 [02:02<05:45,  2.83s/ examples]Map:  20%|██        | 31/152 [02:04<05:16,  2.61s/ examples]Map:  21%|██        | 32/152 [02:06<05:02,  2.52s/ examples]Map:  22%|██▏       | 33/152 [02:08<04:52,  2.46s/ examples]Map:  22%|██▏       | 34/152 [02:10<04:31,  2.30s/ examples]Map:  23%|██▎       | 35/152 [02:17<07:08,  3.66s/ examples]Map:  24%|██▎       | 36/152 [02:20<06:40,  3.45s/ examples]Map:  24%|██▍       | 37/152 [02:22<05:38,  2.94s/ examples]Map:  25%|██▌       | 38/152 [02:24<05:26,  2.87s/ examples]Map:  26%|██▌       | 39/152 [02:26<04:53,  2.60s/ examples]Map:  26%|██▋       | 40/152 [02:29<04:56,  2.65s/ examples]Map:  27%|██▋       | 41/152 [02:31<04:40,  2.53s/ examples]Map:  28%|██▊       | 42/152 [02:34<04:37,  2.52s/ examples]Map:  28%|██▊       | 43/152 [02:39<06:08,  3.38s/ examples]Map:  29%|██▉       | 44/152 [02:42<05:42,  3.17s/ examples]Map:  30%|██▉       | 45/152 [02:48<07:15,  4.07s/ examples]Map:  30%|███       | 46/152 [02:50<06:15,  3.55s/ examples]Map:  31%|███       | 47/152 [02:57<07:36,  4.34s/ examples]Map:  32%|███▏      | 48/152 [03:00<06:51,  3.96s/ examples]Map:  32%|███▏      | 49/152 [03:02<06:00,  3.50s/ examples]Map:  33%|███▎      | 50/152 [03:04<05:13,  3.08s/ examples]Map:  34%|███▎      | 51/152 [03:07<05:09,  3.07s/ examples]Map:  34%|███▍      | 52/152 [03:10<04:58,  2.99s/ examples]Map:  35%|███▍      | 53/152 [03:13<04:53,  2.96s/ examples]Map:  36%|███▌      | 54/152 [03:19<06:06,  3.73s/ examples]Map:  36%|███▌      | 55/152 [03:27<08:16,  5.12s/ examples]Map:  37%|███▋      | 56/152 [03:30<07:05,  4.43s/ examples]Map:  38%|███▊      | 57/152 [03:33<06:16,  3.96s/ examples]Map:  38%|███▊      | 58/152 [03:39<07:19,  4.67s/ examples]Map:  39%|███▉      | 59/152 [03:44<07:31,  4.86s/ examples]Map:  39%|███▉      | 60/152 [03:47<06:30,  4.24s/ examples]Map:  40%|████      | 61/152 [03:49<05:31,  3.64s/ examples]Map:  41%|████      | 62/152 [03:52<05:01,  3.35s/ examples]Map:  41%|████▏     | 63/152 [03:55<04:43,  3.19s/ examples]Map:  42%|████▏     | 64/152 [03:57<04:26,  3.03s/ examples]Map:  43%|████▎     | 65/152 [04:00<04:12,  2.90s/ examples]Map:  43%|████▎     | 66/152 [04:03<04:02,  2.83s/ examples]Map:  44%|████▍     | 67/152 [04:05<03:44,  2.64s/ examples]Map:  45%|████▍     | 68/152 [04:07<03:30,  2.51s/ examples]Map:  45%|████▌     | 69/152 [04:09<03:22,  2.43s/ examples]Map:  46%|████▌     | 70/152 [04:11<03:13,  2.36s/ examples]Map:  47%|████▋     | 71/152 [04:14<03:06,  2.31s/ examples]Map:  47%|████▋     | 72/152 [04:16<03:05,  2.32s/ examples]Map:  48%|████▊     | 73/152 [04:18<03:02,  2.31s/ examples]Map:  49%|████▊     | 74/152 [04:20<02:56,  2.26s/ examples]Map:  49%|████▉     | 75/152 [04:23<03:00,  2.34s/ examples]Map:  50%|█████     | 76/152 [04:25<02:56,  2.32s/ examples]Map:  51%|█████     | 77/152 [04:27<02:51,  2.28s/ examples]Map:  51%|█████▏    | 78/152 [04:30<02:45,  2.24s/ examples]Map:  52%|█████▏    | 79/152 [04:32<02:46,  2.28s/ examples]Map:  53%|█████▎    | 80/152 [04:34<02:38,  2.20s/ examples]Map:  53%|█████▎    | 81/152 [04:36<02:42,  2.28s/ examples]Map:  54%|█████▍    | 82/152 [04:39<02:39,  2.27s/ examples]Map:  55%|█████▍    | 83/152 [04:41<02:33,  2.22s/ examples]Map:  55%|█████▌    | 84/152 [04:43<02:30,  2.21s/ examples]Map:  56%|█████▌    | 85/152 [04:45<02:33,  2.29s/ examples]Map:  57%|█████▋    | 86/152 [04:48<02:27,  2.24s/ examples]Map:  57%|█████▋    | 87/152 [04:50<02:26,  2.25s/ examples]Map:  58%|█████▊    | 88/152 [04:52<02:21,  2.21s/ examples]Map:  59%|█████▊    | 89/152 [04:54<02:17,  2.18s/ examples]Map:  59%|█████▉    | 90/152 [04:57<02:29,  2.41s/ examples]Map:  60%|█████▉    | 91/152 [05:00<02:36,  2.56s/ examples]Map:  61%|██████    | 92/152 [05:02<02:32,  2.55s/ examples]Map:  61%|██████    | 93/152 [05:05<02:32,  2.59s/ examples]Map:  62%|██████▏   | 94/152 [05:08<02:26,  2.53s/ examples]Map:  62%|██████▎   | 95/152 [05:10<02:23,  2.52s/ examples]Map:  63%|██████▎   | 96/152 [05:13<02:22,  2.54s/ examples]Map:  64%|██████▍   | 97/152 [05:15<02:14,  2.44s/ examples]Map:  64%|██████▍   | 98/152 [05:17<02:14,  2.49s/ examples]Map:  65%|██████▌   | 99/152 [05:20<02:13,  2.52s/ examples]Map:  66%|██████▌   | 100/152 [05:22<02:06,  2.43s/ examples]Map:  66%|██████▋   | 101/152 [05:25<02:08,  2.53s/ examples]Map:  67%|██████▋   | 102/152 [05:28<02:09,  2.59s/ examples]Map:  68%|██████▊   | 103/152 [05:30<02:06,  2.58s/ examples]Map:  68%|██████▊   | 104/152 [05:33<02:04,  2.60s/ examples]Map:  69%|██████▉   | 105/152 [05:36<02:04,  2.64s/ examples]Map:  70%|██████▉   | 106/152 [05:38<01:55,  2.51s/ examples]Map:  70%|███████   | 107/152 [05:40<01:52,  2.51s/ examples]Map:  71%|███████   | 108/152 [05:43<01:53,  2.59s/ examples]Map:  72%|███████▏  | 109/152 [05:46<01:50,  2.57s/ examples]Map:  72%|███████▏  | 110/152 [05:48<01:49,  2.60s/ examples]Map:  73%|███████▎  | 111/152 [05:51<01:47,  2.61s/ examples]Map:  74%|███████▎  | 112/152 [05:54<01:43,  2.60s/ examples]Map:  74%|███████▍  | 113/152 [05:56<01:40,  2.57s/ examples]Map:  75%|███████▌  | 114/152 [05:59<01:46,  2.82s/ examples]Map:  76%|███████▌  | 115/152 [06:02<01:46,  2.87s/ examples]Map:  76%|███████▋  | 116/152 [06:06<01:51,  3.08s/ examples]Map:  77%|███████▋  | 117/152 [06:09<01:46,  3.03s/ examples]Map:  78%|███████▊  | 118/152 [06:12<01:41,  2.98s/ examples]Map:  78%|███████▊  | 119/152 [06:14<01:31,  2.79s/ examples]Map:  79%|███████▉  | 120/152 [06:17<01:31,  2.87s/ examples]Map:  80%|███████▉  | 121/152 [06:21<01:36,  3.12s/ examples]Map:  80%|████████  | 122/152 [06:23<01:27,  2.91s/ examples]Map:  81%|████████  | 123/152 [06:26<01:19,  2.74s/ examples]Map:  82%|████████▏ | 124/152 [06:28<01:16,  2.74s/ examples]Map:  82%|████████▏ | 125/152 [06:31<01:12,  2.70s/ examples]Map:  83%|████████▎ | 126/152 [06:34<01:09,  2.66s/ examples]Map:  84%|████████▎ | 127/152 [06:36<01:04,  2.60s/ examples]Map:  84%|████████▍ | 128/152 [06:39<01:03,  2.66s/ examples]Map:  85%|████████▍ | 129/152 [06:42<01:05,  2.83s/ examples]Map:  86%|████████▌ | 130/152 [06:45<01:01,  2.78s/ examples]Map:  86%|████████▌ | 131/152 [06:47<00:55,  2.63s/ examples]Map:  87%|████████▋ | 132/152 [06:49<00:51,  2.59s/ examples]Map:  88%|████████▊ | 133/152 [06:53<00:51,  2.73s/ examples]Map:  88%|████████▊ | 134/152 [06:55<00:48,  2.71s/ examples]Map:  89%|████████▉ | 135/152 [06:58<00:45,  2.68s/ examples]Map:  89%|████████▉ | 136/152 [07:00<00:42,  2.67s/ examples]Map:  90%|█████████ | 137/152 [07:03<00:39,  2.65s/ examples]Map:  91%|█████████ | 138/152 [07:06<00:36,  2.59s/ examples]Map:  91%|█████████▏| 139/152 [07:09<00:36,  2.78s/ examples]Map:  92%|█████████▏| 140/152 [07:12<00:34,  2.88s/ examples]Map:  93%|█████████▎| 141/152 [07:14<00:30,  2.75s/ examples]Map:  93%|█████████▎| 142/152 [07:17<00:26,  2.67s/ examples]Map:  94%|█████████▍| 143/152 [07:19<00:23,  2.63s/ examples]Map:  95%|█████████▍| 144/152 [07:22<00:21,  2.65s/ examples]Map:  95%|█████████▌| 145/152 [07:25<00:19,  2.73s/ examples]Map:  96%|█████████▌| 146/152 [07:28<00:16,  2.73s/ examples]Map:  97%|█████████▋| 147/152 [07:31<00:13,  2.77s/ examples]Map:  97%|█████████▋| 148/152 [07:34<00:11,  2.85s/ examples]Map:  98%|█████████▊| 149/152 [07:39<00:11,  3.75s/ examples]Map:  99%|█████████▊| 150/152 [07:43<00:07,  3.61s/ examples]Map:  99%|█████████▉| 151/152 [07:46<00:03,  3.39s/ examples]Map: 100%|██████████| 152/152 [07:49<00:00,  3.30s/ examples]                                                             Saved results to: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_full_20231019_5_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER Without Language Model: 1.000
Fine-tuned Test WER With Language Model v1: 1.000
Fine-tuned Test WER With Language Model v2: 1.000


Fine-tuned Test CER Without Language Model: 0.975
Fine-tuned Test CER With Language Model v1: 0.974
Fine-tuned Test CER With Language Model v2: 0.974


--> Getting fine-tuned alignment output without LM...
--> Getting fine-tuned alignment output with LM v1...
--> Getting fine-tuned alignment output with LM v2...
Saved Alignment output to: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_full_20231019_5_finetuned_result.txt


--> Showing some fine-tuned prediction errors...
                                         target_text  ... pred_str_with_LM_2
0                    the the boy bumped into the egg  ...                  e
1                   the dinosaur was licking the boy  ...                  e
2                               the egg was cracking  ...                  e
3  the green baby has second thoughts about playi...  ...                  e
4  the green baby is holding the bottle of milk w...  ...                  e
5  the the  the dinosaur is really sad and is lyi...  ...                  e
6             and they stop laughing at the dinosaur  ...                  e
7  so he went up to the dinosaur and petted him o...  ...                  e
8  and then got sad because he couldn't find the boy  ...                  e
9            the boy is pet the dinosaur on the head  ...                  e

[10 rows x 4 columns]
--> Taking a deeper look...
e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 19/10/2023 06:38:01
