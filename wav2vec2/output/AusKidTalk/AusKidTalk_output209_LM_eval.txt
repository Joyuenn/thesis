Sat Oct 14 11:33:44 AEDT 2023
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM.py
Started: 14/10/2023 11:33:46

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_AusKidTalk_spontaneous_20231014
cache_name: AusKidTalk-eval
Language model: patrickvonplaten/wav2vec2-base-100h-with-lm
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_AusKidTalk_spontaneous_20231014
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk_scripted_spontaneous_combined/finetune_20230718
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

Downloading and preparing dataset csv/default to /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...
Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 13934.56it/s]
Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 25.47it/s]
Generating train split: 0 examples [00:00, ? examples/s]                                                        Generating test split: 0 examples [00:00, ? examples/s]                                                       Dataset csv downloaded and prepared to /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 229.75it/s]
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                               there was a dinosaur
1  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the egg starts cracking near the top and hulk ...
2  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur tries to play with hulk but hulk ...
3  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk looks at the dinosaur and feels bad about...
4  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur is looking around for hulk and he...
5  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk tries to hide from the dinosaur and is st...
6  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 and he was looking at the dinosaur
7  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk was riding backwards on a skateboard and ...
8  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 the dinosaur was about to lick him
9  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                                      he was hiding
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------

Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  
------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=4):   4%|▍         | 1/24 [00:02<00:55,  2.41s/ examples]Map (num_proc=4):  50%|█████     | 12/24 [00:02<00:01,  6.52 examples/s]Map (num_proc=4):  96%|█████████▌| 23/24 [00:02<00:00, 13.86 examples/s]                                                                        Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=4):   4%|▍         | 1/24 [00:00<00:21,  1.07 examples/s]                                                                       --> Verifying data with a random sample...
Target text: LAUGHING WHILE THE DINOSUAR IS DRINKING THE MILK
Input array shape: (45707,)
Sampling rate: 16000
Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  25%|██▌       | 6/24 [00:00<00:00, 35.44 examples/s]                                                                       Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  25%|██▌       | 6/24 [00:00<00:00, 36.41 examples/s]                                                                       /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM.py:567: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 125.80it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   4%|▍         | 1/24 [00:01<00:43,  1.88s/ examples]Map:   8%|▊         | 2/24 [00:02<00:25,  1.18s/ examples]Map:  12%|█▎        | 3/24 [00:03<00:19,  1.06 examples/s]Map:  17%|█▋        | 4/24 [00:03<00:16,  1.21 examples/s]Map:  21%|██        | 5/24 [00:04<00:14,  1.28 examples/s]Map:  25%|██▌       | 6/24 [00:05<00:13,  1.35 examples/s]Map:  29%|██▉       | 7/24 [00:05<00:12,  1.36 examples/s]Map:  33%|███▎      | 8/24 [00:06<00:11,  1.39 examples/s]Map:  38%|███▊      | 9/24 [00:07<00:10,  1.42 examples/s]Map:  42%|████▏     | 10/24 [00:08<00:09,  1.43 examples/s]Map:  46%|████▌     | 11/24 [00:08<00:08,  1.45 examples/s]Map:  50%|█████     | 12/24 [00:09<00:08,  1.41 examples/s]Map:  54%|█████▍    | 13/24 [00:10<00:08,  1.37 examples/s]Map:  58%|█████▊    | 14/24 [00:10<00:07,  1.38 examples/s]Map:  62%|██████▎   | 15/24 [00:11<00:06,  1.40 examples/s]Map:  67%|██████▋   | 16/24 [00:12<00:05,  1.41 examples/s]Map:  71%|███████   | 17/24 [00:13<00:05,  1.39 examples/s]Map:  75%|███████▌  | 18/24 [00:13<00:04,  1.39 examples/s]Map:  79%|███████▉  | 19/24 [00:14<00:03,  1.39 examples/s]Map:  83%|████████▎ | 20/24 [00:15<00:02,  1.40 examples/s]Map:  88%|████████▊ | 21/24 [00:15<00:02,  1.40 examples/s]Map:  92%|█████████▏| 22/24 [00:16<00:01,  1.40 examples/s]Map:  96%|█████████▌| 23/24 [00:17<00:00,  1.41 examples/s]Map: 100%|██████████| 24/24 [00:18<00:00,  1.38 examples/s]                                                           Saved results to: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER Without Language Model: 0.691
Fine-tuned Test WER With Language Model: 0.461


Fine-tuned Test CER Without Language Model: 0.217
Fine-tuned Test CER With Language Model: 0.176


--> Showing some fine-tuned prediction errors...
                                         target_text  ...                                   pred_str_with_LM
0                    AND THE DINOSAUR WAS LYING DOWN  ...                        AND THE DINOSAURAS RENE OUT
1                               THERE WAS A DINOSAUR  ...                            THE HAIRWAS AT DINOSAUR
2                           HE WAS ON THE SKATEBOARD  ...                         PEG WAS ON THE SKATE BOARD
3  HULK WAS RIDING BACKWARDS ON A SKATEBOARD AND ...  ...  HO WAS HIDING BACKWARDS ON THE SKATE BOARD AND...
4                 AND HE WAS LOOKING AT THE DINOSAUR  ...                 AND HE WAS LOCKING AT THE DINOSAUR
5                  AND HE FEED THE DINOSAUR HIS MILK  ...                       AN HE FED THE DINOSAURS MILK
6   LAUGHING WHILE THE DINOSUAR IS DRINKING THE MILK  ...    LAUFHINGWAULE THE DINOSAUR IS DRINKING THE MILK
7                 THE DINOSAUR WAS ABOUT TO LICK HIM  ...                      THE DINOSAUR WAS ABOUTOLIKHIM
8                   HULK FEEDS THE DINOSAUR THE MILK  ...                    HO CREEDS THE DINOSAUR THE MILK
9            A DINOSAUR JUMPS OUT AND HULK IS SCARED  ...               THE DINOSAUR DUMPS OUT AND COCOSKERD

[10 rows x 3 columns]
--> Taking a deeper look...
<pad> <pad> P <pad> <pad> <pad> <pad> <pad> <pad> E E <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> Y Y <pad> K K <pad> <pad> <pad> <pad> W W W <pad> <pad> A <pad> <pad> <pad> <pad> <pad> S S S | | | | O O O <pad> <pad> <pad> N N N | | <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> T T H H E O S S S S <pad> <pad> <pad> <pad> <pad> <pad> <pad> K K <pad> A A <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> T T E E E | B B <pad> <pad> <pad> O O O A A R R R R <pad> <pad> <pad> <pad> <pad> <pad> D D <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 14/10/2023 11:34:44
Sat Oct 14 11:38:04 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM.py
Started: 14/10/2023 11:38:04

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_AusKidTalk_spontaneous_20231014
cache_name: AusKidTalk-eval
Language model: patrickvonplaten/wav2vec2-base-100h-with-lm
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/CU/finetune_CU_lowercase_20231005
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/CU/finetune_CU_lowercase_20231005
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_AusKidTalk_spontaneous_20231014
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/CU/finetune_CU_lowercase_20231005
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 486.75it/s]
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e87d0d079e901a1a.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-5f33e51bda666f6f.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e9e8d956c11484ec_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a738248ba1057089_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-0976e2ae80d1612b_*_of_00004.arrow
Loading cached processed dataset at /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-6b01efa10005e34b_*_of_00004.arrow
/srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM.py:567: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                           he was on the skateboard
1  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk tries to hide from the dinosaur and is st...
2  /srv/scratch/chacmod/auskidtalk_spontaneous/81...                   hulk feeds the dinosaur the milk
3  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  he's curious to see what's inside the egg and ...
4  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 and he was looking at the dinosaur
5  /srv/scratch/chacmod/auskidtalk_spontaneous/81...                                the dinosaur is sad
6  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                        he was listening to the egg
7  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                     the dinosaur poke out his head
8  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 the dinosaur was about to lick him
9  /srv/scratch/chacmod/auskidtalk_spontaneous/81...            a dinosaur jumps out and hulk is scared
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------


------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

--> Verifying data with a random sample...
Target text: A DINOSAUR JUMPS OUT AND HULK IS SCARED
Input array shape: (44162,)
Sampling rate: 16000
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 337.47it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   4%|▍         | 1/24 [00:01<00:26,  1.14s/ examples]Map:   8%|▊         | 2/24 [00:01<00:20,  1.09 examples/s]Map:  12%|█▎        | 3/24 [00:02<00:17,  1.20 examples/s]Map:  17%|█▋        | 4/24 [00:03<00:15,  1.31 examples/s]Map:  21%|██        | 5/24 [00:04<00:14,  1.31 examples/s]Map:  25%|██▌       | 6/24 [00:04<00:13,  1.34 examples/s]Map:  29%|██▉       | 7/24 [00:05<00:13,  1.29 examples/s]Map:  33%|███▎      | 8/24 [00:06<00:12,  1.33 examples/s]Map:  38%|███▊      | 9/24 [00:06<00:10,  1.37 examples/s]Map:  42%|████▏     | 10/24 [00:07<00:10,  1.38 examples/s]Map:  46%|████▌     | 11/24 [00:08<00:09,  1.43 examples/s]Map:  50%|█████     | 12/24 [00:09<00:08,  1.35 examples/s]Map:  54%|█████▍    | 13/24 [00:10<00:08,  1.27 examples/s]Map:  58%|█████▊    | 14/24 [00:10<00:08,  1.22 examples/s]Map:  62%|██████▎   | 15/24 [00:11<00:06,  1.29 examples/s]Map:  67%|██████▋   | 16/24 [00:12<00:06,  1.32 examples/s]Map:  71%|███████   | 17/24 [00:13<00:05,  1.23 examples/s]Map:  75%|███████▌  | 18/24 [00:14<00:04,  1.27 examples/s]Map:  79%|███████▉  | 19/24 [00:14<00:03,  1.30 examples/s]Map:  83%|████████▎ | 20/24 [00:15<00:03,  1.33 examples/s]Map:  88%|████████▊ | 21/24 [00:16<00:02,  1.33 examples/s]Map:  92%|█████████▏| 22/24 [00:16<00:01,  1.35 examples/s]Map:  96%|█████████▌| 23/24 [00:17<00:00,  1.38 examples/s]Map: 100%|██████████| 24/24 [00:18<00:00,  1.29 examples/s]                                                           Saved results to: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER Without Language Model: 1.000
Fine-tuned Test WER With Language Model: 1.000


Fine-tuned Test CER Without Language Model: 0.997
Fine-tuned Test CER With Language Model: 0.985


--> Showing some fine-tuned prediction errors...
                                         target_text  ... pred_str_with_LM
0                    AND THE DINOSAUR WAS LYING DOWN  ...                J
1                               THERE WAS A DINOSAUR  ...                J
2                           HE WAS ON THE SKATEBOARD  ...                J
3  HULK WAS RIDING BACKWARDS ON A SKATEBOARD AND ...  ...     JEFJEJGJGJPJ
4                 AND HE WAS LOOKING AT THE DINOSAUR  ...                J
5                  AND HE FEED THE DINOSAUR HIS MILK  ...                J
6   LAUGHING WHILE THE DINOSUAR IS DRINKING THE MILK  ...                J
7                 THE DINOSAUR WAS ABOUT TO LICK HIM  ...                J
8                   HULK FEEDS THE DINOSAUR THE MILK  ...                J
9            A DINOSAUR JUMPS OUT AND HULK IS SCARED  ...        JPJGJPJGJ

[10 rows x 3 columns]
--> Taking a deeper look...
[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] n n [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 14/10/2023 11:38:40
Sat Oct 14 11:40:29 AEDT 2023
Found cached dataset csv (/srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval/csv/default-f00e5d99dcfcccbc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)
------------------------------------------------------------------------
                 run_finetune_kids.py                                   
------------------------------------------------------------------------
Running:  /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM.py
Started: 14/10/2023 11:40:29

------> IMPORTING PACKAGES.... ---------------------------------------

-->Importing datasets...
-->Importing random...
-->Importing pandas & numpy...
-->Importing re...
-->Importing json...
-->Importing Wav2VecCTC...
-->Importing soundfile...
-->Importing librosa...
-->Importing torch, dataclasses & typing...
-->Importing from transformers for training...
-->Importing pyarrow for loading dataset...
-->SUCCESS! All packages imported.

------> EXPERIMENT ARGUMENTS ----------------------------------------- 

base_fp: /srv/scratch/z5313567/thesis/
model: wav2vec2
dataset_name: AusKidTalk
experiment_id: eval_AusKidTalk_spontaneous_20231014
cache_name: AusKidTalk-eval
Language model: patrickvonplaten/wav2vec2-base-100h-with-lm
training: False
use_checkpoint: True
checkpoint: /srv/scratch/z5313567/thesis/wav2vec2/model/CU/finetune_CU_lowercase_20231005
use_pretrained_tokenizer: True
pretrained_tokenizer: facebook/wav2vec2-base-960h
eval_pretrained: True
eval_model: /srv/scratch/z5313567/thesis/wav2vec2/model/CU/finetune_CU_lowercase_20231005
baseline_model: facebook/wav2vec2-base-960h
eval_baseline: False

------> MODEL ARGUMENTS... -------------------------------------------

hidden_dropout: 0.1
activation_dropout: 0.1
attention_dropoutput: 0.1
feat_proj_dropout: 0.0
layerdrop: 0.1
mask_time_prob: 0.05
mask_time_length: 10
ctc_loss_reduction: mean
ctc_zero_infinity: True
gradient_checkpointing: True

------> TRAINING ARGUMENTS... ----------------------------------------

evaluation strategy: steps
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 3e-05
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.98
adam_epsilon: 1e-08
num_train_epochs: 14
max_steps: 60000
lr_scheduler_type: linear
warmup_ratio: 0.1
logging_strategy: steps
logging_steps: 1000
save_strategy: steps
save_steps: 1000
save_total_limit: 3
fp16: True
eval_steps: 1000
load_best_model_at_end: True
metric_for_best_model: wer
greater_is_better: False
group_by_length: True

------> GENERATING FILEPATHS... --------------------------------------

--> data_train_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_test_fp: /srv/scratch/z5313567/thesis/AusKidTalk_local/spontaneous/AusKidTalk_spontaneous_test_only_transcription_filepath.csv
--> data_cache_fp: /srv/scratch/chacmod/.cache/huggingface/datasets/AusKidTalk-eval
--> vocab_fp: /srv/scratch/z5313567/thesis/wav2vec2/vocab/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_vocab.json
--> model_fp: /srv/scratch/z5313567/thesis/wav2vec2/model/AusKidTalk/eval_AusKidTalk_spontaneous_20231014
--> baseline_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/baseline_result/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_baseline_result.csv
--> finetuned_results_fp: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_finetuned_result.csv
--> pretrained_mod: /srv/scratch/z5313567/thesis/wav2vec2/model/CU/finetune_CU_lowercase_20231005
--> pretrained_tokenizer: facebook/wav2vec2-base-960h

------> PREPARING DATASET... ------------------------------------

  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 514.83it/s]
--> dataset...
DatasetDict({
    train: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
    test: Dataset({
        features: ['filepath', 'transcription_clean'],
        num_rows: 24
    })
})
--> Printing some random samples...
                                            filepath                                transcription_clean
0  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk was riding backwards on a skateboard and ...
1  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur is looking around for hulk and he...
2  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  hulk tries to hide from the dinosaur and is st...
3  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                               the dinosaur was sad
4  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                 and he was looking at the dinosaur
5  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the dinosaur tries to play with hulk but hulk ...
6  /srv/scratch/chacmod/auskidtalk_spontaneous/81...  the egg starts cracking near the top and hulk ...
7  /srv/scratch/chacmod/auskidtalk_spontaneous/81...                                the dinosaur is sad
8  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                                      he was hiding
9  /srv/scratch/chacmod/auskidtalk_spontaneous/51...                    and the dinosaur was lying down
SUCCESS: Prepared dataset.

------> PROCESSING TRANSCRIPTION... ---------------------------------------

Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/24 [00:00<?, ? examples/s]                                                  
------> CREATING WAV2VEC2 FEATURE EXTRACTOR... -----------------------

SUCCESS: Created feature extractor.

------> PRE-PROCESSING DATA... ----------------------------------------- 

Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=4):   4%|▍         | 1/24 [00:01<00:24,  1.06s/ examples]                                                                       Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=4):   4%|▍         | 1/24 [00:00<00:21,  1.09 examples/s]                                                                       --> Verifying data with a random sample...
Target text: the dinosaur tries to play with hulk but hulk is very scared
Input array shape: (98810,)
Sampling rate: 16000
Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
Map (num_proc=4):  25%|██▌       | 6/24 [00:00<00:00, 41.00 examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
                                                                       Map (num_proc=4):   0%|          | 0/24 [00:00<?, ? examples/s]/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/z5313567/.local/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:166: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Map (num_proc=4):  25%|██▌       | 6/24 [00:00<00:00, 39.15 examples/s]                                                                       /srv/scratch/z5313567/thesis/wav2vec2/code/eval_LM.py:567: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
/home/z5313567/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1643: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
SUCCESS: Data ready for training and evaluation.

------> PREPARING FOR TRAINING & EVALUATION... ----------------------- 

--> Defining data collator...
SUCCESS: Data collator defined.
--> Defining evaluation metric...
SUCCESS: Defined WER evaluation metric.
--> Loading pre-trained checkpoint...
SUCCESS: Pre-trained checkpoint loaded.

------> EVALUATING MODEL... ------------------------------------------ 

Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 1730.68it/s]
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   4%|▍         | 1/24 [00:01<00:28,  1.24s/ examples]Map:   8%|▊         | 2/24 [00:02<00:22,  1.03s/ examples]Map:  12%|█▎        | 3/24 [00:02<00:20,  1.05 examples/s]Map:  17%|█▋        | 4/24 [00:03<00:17,  1.13 examples/s]Map:  21%|██        | 5/24 [00:04<00:16,  1.14 examples/s]Map:  25%|██▌       | 6/24 [00:05<00:15,  1.17 examples/s]Map:  29%|██▉       | 7/24 [00:06<00:14,  1.13 examples/s]Map:  33%|███▎      | 8/24 [00:07<00:13,  1.16 examples/s]Map:  38%|███▊      | 9/24 [00:08<00:12,  1.18 examples/s]Map:  42%|████▏     | 10/24 [00:08<00:11,  1.20 examples/s]Map:  46%|████▌     | 11/24 [00:09<00:10,  1.22 examples/s]Map:  50%|█████     | 12/24 [00:10<00:10,  1.15 examples/s]Map:  54%|█████▍    | 13/24 [00:11<00:10,  1.10 examples/s]Map:  58%|█████▊    | 14/24 [00:12<00:09,  1.07 examples/s]Map:  62%|██████▎   | 15/24 [00:13<00:08,  1.12 examples/s]Map:  67%|██████▋   | 16/24 [00:14<00:06,  1.16 examples/s]Map:  71%|███████   | 17/24 [00:15<00:06,  1.08 examples/s]Map:  75%|███████▌  | 18/24 [00:16<00:05,  1.10 examples/s]Map:  79%|███████▉  | 19/24 [00:16<00:04,  1.13 examples/s]Map:  83%|████████▎ | 20/24 [00:17<00:03,  1.15 examples/s]Map:  88%|████████▊ | 21/24 [00:18<00:02,  1.15 examples/s]Map:  92%|█████████▏| 22/24 [00:19<00:01,  1.16 examples/s]Map:  96%|█████████▌| 23/24 [00:20<00:00,  1.19 examples/s]Map: 100%|██████████| 24/24 [00:21<00:00,  1.12 examples/s]                                                           Saved results to: /srv/scratch/z5313567/thesis/wav2vec2/finetuned_result/AusKidTalk/eval_AusKidTalk_spontaneous_20231014_finetuned_result.csv
--> Getting fine-tuned test results...
Fine-tuned Test WER Without Language Model: 1.000
Fine-tuned Test WER With Language Model: 1.000


Fine-tuned Test CER Without Language Model: 0.920
Fine-tuned Test CER With Language Model: 1.000


--> Showing some fine-tuned prediction errors...
                                         target_text  ... pred_str_with_LM
0                    and the dinosaur was lying down  ...                J
1                               there was a dinosaur  ...                J
2                           he was on the skateboard  ...                J
3  hulk was riding backwards on a skateboard and ...  ...     JEFJEJGJGJPJ
4                 and he was looking at the dinosaur  ...                J
5                  and he feed the dinosaur his milk  ...                J
6   laughing while the dinosuar is drinking the milk  ...                J
7                 the dinosaur was about to lick him  ...                J
8                   hulk feeds the dinosaur the milk  ...                J
9            a dinosaur jumps out and hulk is scared  ...        JPJGJPJGJ

[10 rows x 3 columns]
--> Taking a deeper look...
[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] n n [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

------> SUCCESSFULLY FINISHED ---------------------------------------- 

Finished: 14/10/2023 11:41:08
